{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AyXkqz3XduFc"
   },
   "source": [
    "# AM216 Final Project  \n",
    "Wen Rui Liau  \n",
    "David Zheng\n",
    "\n",
    "\n",
    "## Objective:\n",
    "\n",
    "To disambiguate an entity through its relationship with its neighboring entities utilizing graph embeddings. \n",
    "\n",
    "*Imagine the statement:* **Paris** is the capital of **France**.  \n",
    "*In this context, does* Paris = (Paris Hilton), (Paris, France), (Paris, Arkansas)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4o_kwcvQeL2M"
   },
   "source": [
    "## Abstract\n",
    "Entity-linking is a process of assigning a unique identity to entities in a text. In our project, we seek to disambiguate an entity through its relationship with its neighboring entities utilizing graph embeddings. Entity-linking is important as it allows researchers to extract abstract representations from text as well as seperate relevant concepts from non-meaningful text. We present our method of performing entity linking using the shortest cosine distance. We compare our embedding model with a naive baseline model that selects the entity with the highest view-count. After tuning our embedding model, it outperforms the baseline by achieving superior accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sARroLoDf0uK"
   },
   "source": [
    "## Motivation\n",
    "\n",
    "In natural language processing, entity linking is the task of assigning a unique identifier to entities mentioned in a corpus of text. Entities can refer to famous individuals, locations or companies etc. A classical example is as follows: Given the sentence \"Paris is the capital of France\", we want to determine that \"Paris\" refers to the city of Paris and not to Paris Hilton or any other entity that could be referred to as \"Paris\"  (Paris Hilton), (Paris, France), (Paris, Arkansas).\n",
    "\n",
    "![entity-linking](https://drive.google.com/uc?id=1MlbsdkzUzFonPb_VIgcnwyCGJHCpYjgk)\n",
    "\n",
    "In our project, we will be exploring the use of graph embeddings to generate a model which can accurately and efficiently execute these named entity linking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nY3X81Zsh0Uc"
   },
   "source": [
    "## Methodology\n",
    "We will be using the Kensho-Derived Wikimedia Dataset (KDWD) to answer this question. The KDWD is built upon the Wikipedia-Wikidata combination and consists of three different layers as described in this blog post: The base layer is the English Wikipedia corpus, the middle layer labels the corpus by indicating which text spans are URL links to other entries, and the top layer (knowledge layer) connects the Wikipedia links to items in the Wikidata knowledge graph.\n",
    "\n",
    "In our dataset, the top layer is crucial to our application. It provides statements as triples in the form of (item_id, property_id, item_id). The dataset is large as well, containing information about 51M items and 141M statements. We grouped each property_id into 5 weight categories. Due to the immense size of the graph we had to condense the graph to around 18M statements for our embedding conversion to run on a system with 128GB of ram. Our methodology for condensing the graph is explained furthur in the \"generate_graph_embeddings\" notebook.\n",
    "\n",
    "The fundamental mathematical model we will be using are graph embeddings. We use Node2Vec to convert our condensed, weighted statements graph into a set of 128 length vectors. In an ideal conversion, these embeddings capture the topology of the graph. We will use the cosine distance between the embeddings of two items to represent the strength of their relationship to each other.\n",
    "\n",
    "Our project aims to find out of the relationship between an enitity and its neighboring entities in the same sentence can identify the true identity of the root entity. Using our previous example \"Paris is the capital of France\", can France help identiy what Paris is?\n",
    "\n",
    "Throughout the rest of the notebook we will cover:\n",
    "1. Import Files\n",
    "2. Dataset\n",
    "3. Models\n",
    "4. Initial Test/Results\n",
    "5. Model Analysis\n",
    "6. Model Tuning\n",
    "7. Final Model\n",
    "8. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TxlHvBgvduFe"
   },
   "source": [
    "# Import Files\n",
    "### Read in and format all the neccesary files to run our model.\n",
    "\n",
    "#### NOTE: This requires a system with at least 64GB of ram\n",
    "\n",
    "#### Download the files from:\n",
    "https://drive.google.com/drive/folders/1kzuzzlCMw7mATR6rRe4fKIpdgImrchKD?usp=sharing  \n",
    "Place them in a data/ folder\n",
    "\n",
    "The files are generated from the following notebooks:  \n",
    "generate_data.ipynb  \n",
    "generate_items.ipynb  \n",
    "generate_properties.ipynb  \n",
    "generate_graph.ipynb\n",
    "\n",
    "We created those notebooks to extract and manipulate the raw data from the Kensho Derived Wikimedia Dataset:  \n",
    "https://www.kaggle.com/kenshoresearch/kensho-derived-wikimedia-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eC1RQ7f_duFf",
    "outputId": "0f48e799-0db1-4f92-f82b-dbc1618f16ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>Anarchism is an anti-authoritarian political a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>Autism is a developmental disorder characteriz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>Albedo () (, meaning 'whiteness') is the measu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290</td>\n",
       "      <td>A or a is the first letter and the first vowel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>303</td>\n",
       "      <td>Alabama () is a state in the southeastern regi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5343560</th>\n",
       "      <td>62470350</td>\n",
       "      <td>Daming Zhu is an Assistant Dean for Continuing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5343561</th>\n",
       "      <td>62470423</td>\n",
       "      <td>Tony Oshey Dews (born June 6, 1973) is an Amer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5343562</th>\n",
       "      <td>62470432</td>\n",
       "      <td>(EC-PL20ZZBPRUS) is an sleek design digital co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5343563</th>\n",
       "      <td>62470465</td>\n",
       "      <td>Major General Nils-Fredrik Palmstierna (8 Marc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5343564</th>\n",
       "      <td>62473330</td>\n",
       "      <td>Shibuya Crossing is a popular scramble crossin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5343565 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          text_id                                               text\n",
       "0              12  Anarchism is an anti-authoritarian political a...\n",
       "1              25  Autism is a developmental disorder characteriz...\n",
       "2              39  Albedo () (, meaning 'whiteness') is the measu...\n",
       "3             290  A or a is the first letter and the first vowel...\n",
       "4             303  Alabama () is a state in the southeastern regi...\n",
       "...           ...                                                ...\n",
       "5343560  62470350  Daming Zhu is an Assistant Dean for Continuing...\n",
       "5343561  62470423  Tony Oshey Dews (born June 6, 1973) is an Amer...\n",
       "5343562  62470432  (EC-PL20ZZBPRUS) is an sleek design digital co...\n",
       "5343563  62470465  Major General Nils-Fredrik Palmstierna (8 Marc...\n",
       "5343564  62473330  Shibuya Crossing is a popular scramble crossin...\n",
       "\n",
       "[5343565 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load wikipedia intro text\n",
    "text_df = pd.read_csv('data/intro_text.csv', dtype={'text':str, 'text_id':'int32'})\n",
    "display(text_df)\n",
    "# convert to dictionary for faster access\n",
    "text_dict = text_df.set_index('text_id').text.to_dict()\n",
    "del(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "agpKRUxCduGK",
    "outputId": "25e751a9-2645-4084-db31-10a051cdd88e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>page_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anti-authoritarian</td>\n",
       "      <td>867979</td>\n",
       "      <td>1030234</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>political</td>\n",
       "      <td>23040</td>\n",
       "      <td>179805</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>social philosophy</td>\n",
       "      <td>586276</td>\n",
       "      <td>180592</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hierarchies</td>\n",
       "      <td>13998</td>\n",
       "      <td>188619</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>self-managed</td>\n",
       "      <td>40949353</td>\n",
       "      <td>15981562</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35840002</th>\n",
       "      <td>Carl Randall</td>\n",
       "      <td>40277554</td>\n",
       "      <td>16215506</td>\n",
       "      <td>62473330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35840003</th>\n",
       "      <td>The World Ends With You</td>\n",
       "      <td>6987282</td>\n",
       "      <td>1416303</td>\n",
       "      <td>62473330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35840004</th>\n",
       "      <td>2016 Summer Olympics closing ceremony</td>\n",
       "      <td>44593137</td>\n",
       "      <td>18741083</td>\n",
       "      <td>62473330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35840005</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>1610886</td>\n",
       "      <td>181278</td>\n",
       "      <td>62473330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35840006</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>30057</td>\n",
       "      <td>1490</td>\n",
       "      <td>62473330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35840007 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         entity   page_id   item_id   text_id\n",
       "0                            anti-authoritarian    867979   1030234        12\n",
       "1                                     political     23040    179805        12\n",
       "2                             social philosophy    586276    180592        12\n",
       "3                                   hierarchies     13998    188619        12\n",
       "4                                  self-managed  40949353  15981562        12\n",
       "...                                         ...       ...       ...       ...\n",
       "35840002                           Carl Randall  40277554  16215506  62473330\n",
       "35840003                The World Ends With You   6987282   1416303  62473330\n",
       "35840004  2016 Summer Olympics closing ceremony  44593137  18741083  62473330\n",
       "35840005                   2020 Summer Olympics   1610886    181278  62473330\n",
       "35840006                                  Tokyo     30057      1490  62473330\n",
       "\n",
       "[35840007 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load our labeled dataset of entities\n",
    "entity_df = pd.read_csv('data/intro_entity.csv', \n",
    "                        dtype={'entity':str, 'page_id':'int32', 'item_id':'int32', 'text_id':'int32'})\n",
    "entity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I3fw7VvAduGV",
    "outputId": "25ff3b7f-0f0a-41cd-ab02-23763e2743bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>6199</td>\n",
       "      <td>Anarchism</td>\n",
       "      <td>31335</td>\n",
       "      <td>3540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>38404</td>\n",
       "      <td>Autism</td>\n",
       "      <td>49693</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>101038</td>\n",
       "      <td>Albedo</td>\n",
       "      <td>14573</td>\n",
       "      <td>2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290</td>\n",
       "      <td>9659</td>\n",
       "      <td>A</td>\n",
       "      <td>25859</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>303</td>\n",
       "      <td>173</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>52765</td>\n",
       "      <td>11125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5362169</th>\n",
       "      <td>62470350</td>\n",
       "      <td>76894635</td>\n",
       "      <td>Daming Zhu</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5362170</th>\n",
       "      <td>62470423</td>\n",
       "      <td>76894633</td>\n",
       "      <td>Tony Dews</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5362171</th>\n",
       "      <td>62470432</td>\n",
       "      <td>76896959</td>\n",
       "      <td>Samsung PL20</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5362172</th>\n",
       "      <td>62470465</td>\n",
       "      <td>6034153</td>\n",
       "      <td>Nils-Fredrik Palmstierna</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5362173</th>\n",
       "      <td>62473330</td>\n",
       "      <td>21083961</td>\n",
       "      <td>Shibuya Crossing</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5362174 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          page_id   item_id                     title  views  counts\n",
       "0              12      6199                 Anarchism  31335    3540\n",
       "1              25     38404                    Autism  49693    2114\n",
       "2              39    101038                    Albedo  14573    2825\n",
       "3             290      9659                         A  25859     175\n",
       "4             303       173                   Alabama  52765   11125\n",
       "...           ...       ...                       ...    ...     ...\n",
       "5362169  62470350  76894635                Daming Zhu     16       0\n",
       "5362170  62470423  76894633                 Tony Dews      7       2\n",
       "5362171  62470432  76896959              Samsung PL20      9       0\n",
       "5362172  62470465   6034153  Nils-Fredrik Palmstierna      8       3\n",
       "5362173  62473330  21083961          Shibuya Crossing     68       1\n",
       "\n",
       "[5362174 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in csv with popularity metrics for each item\n",
    "id_pop_df = pd.read_csv(\"data/id_counts.csv\")\n",
    "display(id_pop_df)\n",
    "item_pop_dict = id_pop_df.set_index('item_id').views.to_dict()\n",
    "del(id_pop_df)\n",
    "\n",
    "# sort list of ids by popularity\n",
    "def sort_ids(ids):\n",
    "    if len(ids)==1: return ids\n",
    "    tie_break_list = [item_pop_dict.get(i, -1) for i in ids]\n",
    "    return ids[np.argsort(tie_break_list)[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2uI32HxUduGi",
    "outputId": "67a04101-54a9-4dea-af22-32e6df728f6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_label</th>\n",
       "      <th>item_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "      <td>[120976, 166764, 4540205, 66092288]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>! -attention-</td>\n",
       "      <td>[8290256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>! that bastard is trying to steal our gold !</td>\n",
       "      <td>[60669584]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>! that dick trying to steal our gold !</td>\n",
       "      <td>[60669584]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!</td>\n",
       "      <td>[12366011]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43616080</th>\n",
       "      <td>🧺</td>\n",
       "      <td>[201097]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43616081</th>\n",
       "      <td>🧿</td>\n",
       "      <td>[582742]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43616082</th>\n",
       "      <td>𠃍</td>\n",
       "      <td>[55900012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43616083</th>\n",
       "      <td>𥫗</td>\n",
       "      <td>[55885207]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43616084</th>\n",
       "      <td>𪜈</td>\n",
       "      <td>[11273367]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43616085 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              en_label  \\\n",
       "0                                                    !   \n",
       "1                                        ! -attention-   \n",
       "2         ! that bastard is trying to steal our gold !   \n",
       "3               ! that dick trying to steal our gold !   \n",
       "4                                                   !!   \n",
       "...                                                ...   \n",
       "43616080                                             🧺   \n",
       "43616081                                             🧿   \n",
       "43616082                                             𠃍   \n",
       "43616083                                             𥫗   \n",
       "43616084                                             𪜈   \n",
       "\n",
       "                                     item_ids  \n",
       "0         [120976, 166764, 4540205, 66092288]  \n",
       "1                                   [8290256]  \n",
       "2                                  [60669584]  \n",
       "3                                  [60669584]  \n",
       "4                                  [12366011]  \n",
       "...                                       ...  \n",
       "43616080                             [201097]  \n",
       "43616081                             [582742]  \n",
       "43616082                           [55900012]  \n",
       "43616083                           [55885207]  \n",
       "43616084                           [11273367]  \n",
       "\n",
       "[43616085 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in our list of item labels and their possible item ids\n",
    "item_df = pd.read_feather('data/item_dict.ftr', use_threads=True)\n",
    "display(item_df)\n",
    "# Sort the items in the dictionary\n",
    "item_df['item_ids'] = [sort_ids(i) for i in item_df.item_ids]\n",
    "# convert to dictionary for faster access\n",
    "item_dict = item_df.set_index('en_label').item_ids.to_dict()\n",
    "del(item_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwvf1w57duGv",
    "outputId": "2c732454-bcbd-435b-f942-2237e52e5f31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7774116</td>\n",
       "      <td>[-0.0269857, 0.03867380000000001, -0.039145099...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15416</td>\n",
       "      <td>[-0.276007, 0.89081, -1.00547, 2.28976, 2.8597...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[-1.0528899999999999, 3.5590699999999997, -4.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68389768</td>\n",
       "      <td>[-0.0128303, 0.0387821, -0.04544430000000001, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8054</td>\n",
       "      <td>[-0.72868, 2.38955, -2.61038, 5.9627, 7.37511,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511823</th>\n",
       "      <td>14030900</td>\n",
       "      <td>[-0.0396873, 0.04081219999999999, -0.0306113, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511824</th>\n",
       "      <td>558391</td>\n",
       "      <td>[-0.038532800000000006, 0.042486199999999995, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511825</th>\n",
       "      <td>6949086</td>\n",
       "      <td>[-0.0422871, 0.0415966, -0.0293755, 0.149361, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511826</th>\n",
       "      <td>4063902</td>\n",
       "      <td>[-0.0440098, 0.044141, -0.0252104, 0.13985, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511827</th>\n",
       "      <td>4783196</td>\n",
       "      <td>[-0.0402763, 0.0416551, -0.0318493, 0.142287, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5511828 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          item_id                                             vector\n",
       "0         7774116  [-0.0269857, 0.03867380000000001, -0.039145099...\n",
       "1           15416  [-0.276007, 0.89081, -1.00547, 2.28976, 2.8597...\n",
       "2               0  [-1.0528899999999999, 3.5590699999999997, -4.0...\n",
       "3        68389768  [-0.0128303, 0.0387821, -0.04544430000000001, ...\n",
       "4            8054  [-0.72868, 2.38955, -2.61038, 5.9627, 7.37511,...\n",
       "...           ...                                                ...\n",
       "5511823  14030900  [-0.0396873, 0.04081219999999999, -0.0306113, ...\n",
       "5511824    558391  [-0.038532800000000006, 0.042486199999999995, ...\n",
       "5511825   6949086  [-0.0422871, 0.0415966, -0.0293755, 0.149361, ...\n",
       "5511826   4063902  [-0.0440098, 0.044141, -0.0252104, 0.13985, 0....\n",
       "5511827   4783196  [-0.0402763, 0.0416551, -0.0318493, 0.142287, ...\n",
       "\n",
       "[5511828 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Length: 128\n"
     ]
    }
   ],
   "source": [
    "# Read in item embeddings\n",
    "emb_df = pd.read_feather('data/embeddings_large.ftr', use_threads=True)\n",
    "display(emb_df)\n",
    "print(f'Vector Length: {len(emb_df.vector[0])}')\n",
    "\n",
    "# convert to dictionary for faster access\n",
    "emb_dict = emb_df.set_index('item_id')['vector'].to_dict()\n",
    "del(emb_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtl21OPEduHA"
   },
   "source": [
    "# Dataset\n",
    "We created our dataset from the introductions of articles in Wikipedia. We focused on introductions because they contain the highest density of links compared to other sections of Wikipedia and it is the links that allow us to create a labelled dataset. The **text** of the link is the **label** of an entity and the **page number** the link points to is the **id** of that entity. Now we have the ground truth of any particular entity in question for our dataset.\n",
    "\n",
    "Additionally, we generated an *item_dict* of the different ids a text label can have. I.e. many entity's have identical text labels but different ids. For instance does the word **Paris** refer to the city of **Paris, France** or the person **Paris Hilton**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJHL6Z_PduHC",
    "outputId": "fc828ed2-019b-48ed-f52a-b29e9fdeb49c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entity        Tokyo\n",
       "page_id       30057\n",
       "item_id        1490\n",
       "text_id    62473330\n",
       "Name: 35840006, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([    1490, 65120889,  7813799,  7813795,  2040983,  1065186,\n",
       "       22043894, 48765289,  7813796,  7813794, 10382938,  7473516,\n",
       "        7813792, 66771764, 11235155, 15663789, 60386831, 64156563,\n",
       "       64156564, 64156566, 64156567, 64158463, 64563341, 11249668])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Shibuya Crossing is a popular scramble crossing in Shibuya, Tokyo, Japan. It is located in front of the Shibuya Station Hachikō exit and stops vehicles in all directions to allow pedestrians to inundate the entire intersection. The statue of Hachikō, a dog, between the station and the intersection, is a common meeting place and almost always crowded. Three large TV screens mounted on nearby buildings overlook the crossing, as well as many advertising signs. The Starbucks store overlooking the crossing is also one of the busiest in the world. Its heavy traffic and inundation of advertising have led to it being compared to the Times Square intersection in New York City and Dundas Square intersection in Toronto. Tokyo-based architecture professor Julian Worrall has said Shibuya Crossing is \"a great example of what Tokyo does best when it\\'s not trying.\" Shibuya Crossing is often featured in movies and television shows which take place in Tokyo, such as Lost in Translation, The Fast and the Furious: Tokyo Drift, and Resident Evil: Afterlife and Retribution, as well as on domestic and international news broadcasts. The iconic video screen featured in the above movies, in particular Lost in Translation with its \\'walking dinosaur\\' scene, was taken down for a period of time and replaced with static advertising, although it resumed operation in July 2013. Contemporary British painter Carl Randall (who spent 10 years living in Tokyo as an artist) depicted the area in his large artwork \\'Shibuya\\', exhibited at the National Portrait Gallery in London 2013., Scramble Crossing is a major location in the video game The World Ends With You, which is set entirely in the neighbourhood of Shibuya. The crossing was featured in the 2016 Summer Olympics closing ceremony to promote the 2020 Summer Olympics in Tokyo.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(entity_df.loc[35840006], item_dict['tokyo'], text_dict[62473330])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_yetEjg7duHY"
   },
   "source": [
    "### Example\n",
    "Here is an example of the problem using an entity with the text label **Tokyo**. However there are **24 possible ids** for that text label. How can we determine that **1490** is the correct id from that list?\n",
    "\n",
    "In this case **Tokyo** comes for text #**62473330**, which we can see from the text above has the neighboring entities **Shibuya** and **Japan**.\n",
    "\n",
    "Thus our **hypothesis** is: Can the neighboring entities around an entity in question help disambiguate it?\n",
    "\n",
    "To approximate the relationship between two entities we generated **128 dimension embeddings** for each entity from the Wikidata graph provided by the Kensho Derived Wikimedia Dataset. First, we **weighted** the graph by **property** and then used **node2vec** to create the embeddings.\n",
    "\n",
    "We also had to condense the graph due to memory constraints. The original graph with **141,206,853** links would crash on systems with 128 GB of ram. We **condensed the graph** into two smaller versions with **18,162,857** and **9,252,546** links. We **prioritized links** with the **highest weightings** and entities that were **more probable to appear** within our sampleset. These larger of these two graphs still took ~18 hours to run on a 16 core 128 GB memory EC2 instance.The generate_graph_embeddings notebook has this process in more detail.\n",
    "\n",
    "<img src=\"https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F4301984%2F19663d43bade0e92f578255f6e0d9dcd%2Fkensho_wiki_triple_layer.svg?generation=1580347573004185&alt=media\" alt=\"KDWD Graph\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNNNAa7vduHc",
    "outputId": "6ead4d52-a025-4d8b-8ddf-406b0f3464e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France <-> Paris, France\t 9.533161910768584e-06\n",
      "France <-> Paris Hilton\t\t 0.001471110338591708\n",
      "France <-> Paris, Arkansas\t 0.00018422952880658983\n",
      "\n",
      "Japan <-> Tokyo (capital of Japan)\t 1.1072205153617176e-05\n",
      "Japan <-> Tokyo (song by Athlete)\t 0.01536490586364192\n",
      "Japan <-> Tokyo (novel by Mo Hayder)\t 0.013198088596884872\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "# cutoff of 1 returns the true cosine distance\n",
    "# cutoff < 1 will prioritize lower distances\n",
    "def get_cos(item1, item2, cutoff=1):\n",
    "    try:\n",
    "        dist = spatial.distance.cosine(emb_dict[item1], emb_dict[item2])\n",
    "        # cut\n",
    "        if dist < cutoff:\n",
    "            return dist\n",
    "        else:\n",
    "            return 1\n",
    "    except KeyError:\n",
    "        return 1\n",
    "\n",
    "print(\"France <-> Paris, France\\t\", get_cos(142, 90))\n",
    "print(\"France <-> Paris Hilton\\t\\t\", get_cos(142, 47899))\n",
    "print(\"France <-> Paris, Arkansas\\t\", get_cos(142, 79917))\n",
    "\n",
    "print(\"\\nJapan <-> Tokyo (capital of Japan)\\t\", get_cos(17, 1490))\n",
    "print(\"Japan <-> Tokyo (song by Athlete)\\t\", get_cos(17, 7813794))\n",
    "print(\"Japan <-> Tokyo (novel by Mo Hayder)\\t\", get_cos(17, 7813799))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1zYKm4IduHo"
   },
   "source": [
    "### Calculate cosine distance between the embeddings of two entities.\n",
    "\n",
    "The preliminary results of our embeddings look optimistic. The distance between France and Japan with their respective capital cities are lower than the other possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zcb0FrhaduHr"
   },
   "source": [
    "## Dataset: Functions to generate and format the test samples\n",
    "1. Select a random entity from the entity_df (our labeled dataset)  \n",
    "2. Get the introduction text that entity was extracted from\n",
    "3. Use nltk to extract the sentance the entity is in from the introduction text\n",
    "4. Use spacy to find all neighboring entities within that sentence\n",
    "5. Get the item ids associated with each neighboring entity\n",
    "    - (optional) Constrain the number candidate ids\n",
    "    - (optional) Constrain the number of neighbors\n",
    "    - (optional) Constrain the number of ids per neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfezp6nEduHt",
    "outputId": "fb7e96f9-d7a2-46bd-b0d3-fdb7030d1884"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import chain\n",
    "from collections import OrderedDict \n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import spacy\n",
    "\n",
    "\"\"\"IMPORTANT\"\"\"\n",
    "# Run the cmd below if this is your first run\n",
    "# You will need to restart the kernel after you the run the cmd\n",
    "# !python -m spacy download en_core_web_lg\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4MjtRGhVduH4"
   },
   "outputs": [],
   "source": [
    "# Find the sentence in the text the entity is in\n",
    "# Extract all the entities in that sentence\n",
    "def get_neighbors(entity, text):\n",
    "    if text.find(entity) == -1:\n",
    "        raise Exception(f'[{entity}] was not found in text:\\n {text}')\n",
    "    \n",
    "    entity_start = text.find(entity)\n",
    "    entity_end = entity_start + len(entity)\n",
    "    sentence_start = 0\n",
    "    sentence_end = len(text)\n",
    "    \n",
    "    # Find the sentence the entity is in within the text\n",
    "    splits = [s for s, e in sent_detector.span_tokenize(text)]\n",
    "    \n",
    "    for i, j in enumerate(splits):\n",
    "        if j <= entity_start:\n",
    "            sentence_start = j\n",
    "        elif j >= entity_end:\n",
    "            sentence_end = j\n",
    "            break\n",
    "    \n",
    "    ents_before = nlp(text[sentence_start:entity_start]).ents\n",
    "    ents_after = nlp(text[entity_end:sentence_end]).ents\n",
    "    \n",
    "    #return the neighbors before and after our entity\n",
    "    return ents_before, ents_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-2IKJ0pduIC"
   },
   "outputs": [],
   "source": [
    "# get the ids for a given entity's text label\n",
    "# truncate list of ids to length n\n",
    "def get_id(entity):\n",
    "    try:\n",
    "        return entity, item_dict[entity]\n",
    "    except:\n",
    "        # catch some edge cases from spacy entities\n",
    "        if len(entity.strip('\\'\" ')) < len(entity):\n",
    "            return get_id(entity.strip('\\'\" '))\n",
    "        elif entity[:4] == 'the ':\n",
    "            return get_id(entity[4:])\n",
    "        else:\n",
    "            return entity, None\n",
    "        \n",
    "# get all the ids for the neighbors previously identified\n",
    "# truncate those ids to to the set max length\n",
    "# drop all the neighbors that do not return ids\n",
    "def get_neighbor_ids(entity, ents_before, ents_after, max_neighbors_ids):\n",
    "    entity_dict = OrderedDict()\n",
    "    # add the original entity to avoid neighbors with the same name\n",
    "    entity_dict[entity] = None\n",
    "    \n",
    "    for ent in ents_before+(None,)+ents_after:\n",
    "        # None is just a placeholder to identify where the original identity was\n",
    "        if ent is None:\n",
    "            entity_dict[None] = None\n",
    "            continue\n",
    "        # Ignore any neighboring entities that are dates\n",
    "        # Wikipedia doesn't list dates as entities\n",
    "        elif ent.label_ == 'DATE':\n",
    "            continue\n",
    "            \n",
    "        ent_text = ent.text.strip().casefold()\n",
    "\n",
    "        if ent_text not in entity_dict:\n",
    "            ent_text, ids = get_id(ent_text)\n",
    "            if ids is not None:\n",
    "                # truncate list of ids to the max length\n",
    "                entity_dict[ent_text] = ids[:max_neighbors_ids]\n",
    "        \n",
    "    #pop off the placeholder entity\n",
    "    #print(entity_dict)\n",
    "    entity_dict.pop(entity)\n",
    "    return entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XjrCtaBdduIN"
   },
   "outputs": [],
   "source": [
    "# return our desired number of neighbors ordered by proximity to our target entity in the sentence\n",
    "def reduce_neighbors(neighbor_dict, max_neighbors):\n",
    "    neighbors = list(neighbor_dict.keys())\n",
    "    if len(neighbors) == 1:\n",
    "        if neighbors[0] != None:\n",
    "            raise Exception(\"Error in sort_reduce_neighbors, {neighbor_dict}\")\n",
    "        return None, None\n",
    "    \n",
    "    split_loc = neighbors.index(None)\n",
    "    \n",
    "    # only sort the neighbors by proximity to entity if there there are more neighbors than we want\n",
    "    if len(neighbors) > max_neighbors+1:\n",
    "        neighbors = list(chain.from_iterable(itertools.zip_longest(neighbors[:split_loc], neighbors[split_loc+1:])))\n",
    "    neighbors = [i for i in neighbors if i is not None][:max_neighbors]\n",
    "\n",
    "    return neighbors, [neighbor_dict[i] for i in neighbors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NND9TJUAduIX",
    "outputId": "61c02b00-eaa0-483e-fa54-33da55517563"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('family', 56276, 35409),\n",
       "  array([    8436,    83306,    35409,  3061609,  1277124,  1395369,\n",
       "         65083385,  5433024,  7733289,   846671]),\n",
       "  ['buteogallus anthracinus', 'south', 'central america'],\n",
       "  [array([1267120]),\n",
       "   array([     667,  4254113,  7565338,  2304261,   857122,  3492216,\n",
       "          60284880,  7565339,  7565340, 30669474]),\n",
       "   array([   27611,  5060313, 60114794,  5060312])]),\n",
       " (('kuhdasht-e shomali rural district', 34558901, 6442083),\n",
       "  array([6442083]),\n",
       "  None,\n",
       "  None),\n",
       " (('australia', 4689264, 408),\n",
       "  array([     408,     3960,   275180,  4823546, 16746529, 16835533,\n",
       "           205546,  4823544, 17299849,  4823543]),\n",
       "  ['sri lanka', 'india', 'fiji'],\n",
       "  [array([    854, 4526612]),\n",
       "   array([     668,   129286,  1775277,  2060630,   274592, 16429066,\n",
       "          17055962,  1936198,  6019237,  1496030]),\n",
       "   array([     712,  2085573,  5425748,  1281259,  3809954, 74043358,\n",
       "          71872706, 56340704, 42375871])]),\n",
       " (('grande prairie', 329344, 642900),\n",
       "  array([  642900, 16982509,  5595329, 61212350]),\n",
       "  ['highway 2'],\n",
       "  [array([ 2072859, 47089722, 47089733,  5759830,   798571])]),\n",
       " (('world war ii', 32927, 362),\n",
       "  array([     362, 15053459, 15053456]),\n",
       "  ['first', 'england'],\n",
       "  [array([  444353, 20925558,  5452238,   154898,  8563335,  5452240,\n",
       "           3746013, 28084844,  5452237, 19320946]),\n",
       "   array([      21,    47762,   179876,    79282,  2131751, 11111401,\n",
       "           5377957,  5377960, 20870342,   257294])])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "# get an entity's candidate ids, its neighbors and its neighbor's ids\n",
    "def format_sample(row, max_candidate_ids, max_neighbors, max_neighbors_ids):\n",
    "    entity, page_id, item_id, text_id = row\n",
    "    entity = entity.strip().casefold()\n",
    "    \n",
    "    # return None is the item is not within our dictionary \n",
    "    try:\n",
    "        entity_ids = item_dict[entity][:max_candidate_ids]\n",
    "    except KeyError:\n",
    "        return (entity, page_id, item_id), None, None, None \n",
    "    \n",
    "    # Skip finding all the neighbors if there is only one possible id\n",
    "    if len(entity_ids) <= 1:\n",
    "        return (entity, page_id, item_id), entity_ids, None, None\n",
    "    text = text_dict[text_id]\n",
    "        \n",
    "    ents_before, ents_after = get_neighbors(row[0], text)\n",
    "    neighbor_dict = get_neighbor_ids(entity, ents_before, ents_after, max_neighbors_ids)\n",
    "    neighbors, neighbor_ids = reduce_neighbors(neighbor_dict, max_neighbors)\n",
    "\n",
    "    return (entity, page_id, item_id), entity_ids, neighbors, neighbor_ids\n",
    "\n",
    "[format_sample(i, 10, 4, 10) for i in entity_df.sample(5, random_state=100).to_numpy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rn5GdkogduIo"
   },
   "source": [
    "# Models\n",
    "Create our baseline and embedding model to disambiguate the entity\n",
    "### Baseline Model:\n",
    "1. Check the **most popular** candidate_id against the true_id. We pre-sorted all the candidate_ids by view-count for each entity in the dictionary in the first section of this notebook. \n",
    "\n",
    "### Embedding Model\n",
    "\n",
    "#### Default cases:\n",
    "1. Entity does not exist in our dictionary.\n",
    "    - Return False\n",
    "2. Entity only has one possible candidate_id.\n",
    "    - Check the one candidate_id against the true_id\n",
    "3. Entity has no neighbors.\n",
    "    - Check the most popular candidate_id against the true_id (Same as the baseline model)\n",
    "        \n",
    "#### If all the default cases are False:\n",
    "1. Generate the **cartesian product** of all the candidate_ids and neighbor_ids.\n",
    "2. Calculate the **distance** of each product:\n",
    "    1. Iterate through all the **pair combinations** for a product.\n",
    "    2. Calculate the **cosine distances** between each pair.\n",
    "    3. Use one of these three methods to calculate the product's distance.\n",
    "        1. **Avg** - Average all the pair distances.\n",
    "        2. **2 min** - Average the two lowest pair distances.\n",
    "        3. **min** - Take the min of the pair distances.\n",
    "    4. Repeat for each product.\n",
    "3. Extract the candidate_id from the product with the **lowest distance**.\n",
    "4. Check that candidate_id against the true_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDZ5mOYyduIr",
    "outputId": "1233411a-7ac2-4b02-f010-b803d9859b50",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, False, True, False, True, True, True]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def disambiguate(sample, num_distances=None, cutoff=1, tune=0, skip_nonroot=False, baseline=False, verbose=False):\n",
    "    # num_distances: how many pair distances to average for each product\n",
    "    # cutoff: consine distances above this this threshold will return 1\n",
    "    # tune: will return candidate 0 if the distance percentile difference with the chosen candidate is greater than tune\n",
    "    # skip_nonroot: only get the distances for pairs that contain a candidate id\n",
    "    # verbose: use this to return results where the chosen candidate and candidate 0 do not match\n",
    "    \n",
    "    # if num_distances is set then we should only concern ourselves with distances involving the root entity\n",
    "    if num_distances is not None:\n",
    "        skip_nonroot == True\n",
    "        \n",
    "    # set our local variables\n",
    "    true_id = sample[0][2]\n",
    "    candidate_ids = sample[1]\n",
    "    neighbor_ids = sample[3]\n",
    "    \n",
    "    # default cases\n",
    "    if candidate_ids is None:\n",
    "        return False\n",
    "    if len(candidate_ids) == 1 or neighbor_ids is None or baseline:\n",
    "        return candidate_ids[0] == true_id\n",
    "    \n",
    "    # generate the cartesian product\n",
    "    prod_ids = [candidate_ids]+neighbor_ids\n",
    "    product_list = list(itertools.product(*prod_ids))\n",
    "    \n",
    "    # if product and pair combinations is too large reduce the number of neighbors until it is under 1000000\n",
    "    # skip finding cosine distance of pairs that don't include candidate ids\n",
    "    num_neighbors = len(neighbor_ids)\n",
    "    while len(product_list) * len(list(itertools.combinations(product_list[0], 2))) > 1000000:\n",
    "        num_neighbors -= 1\n",
    "        prod_ids = [candidate_ids]+neighbor_ids[:num_neighbors]\n",
    "        product_list = list(itertools.product(*prod_ids))\n",
    "    if skip_nonroot:\n",
    "        # making a dict because it's much faster to check a key than it is to check if an element is in a list\n",
    "        candidate_dict = dict.fromkeys(candidate_ids, None)\n",
    "        \n",
    "    shortest_dist = np.inf\n",
    "    candidate_0_dist = np.inf\n",
    "    pair_dict = {}\n",
    "    for idx, product in enumerate(product_list):\n",
    "        pairs = list(itertools.combinations(product, 2))\n",
    "        # Skip any pairs within a product that do not contain the root entity\n",
    "        if skip_nonroot:\n",
    "            pairs = [(i,j) for i,j in pairs if i in candidate_dict or j in candidate_dict]\n",
    "        \n",
    "        # get the cosine distance for pairs\n",
    "        distance = []\n",
    "        for pair in pairs:\n",
    "            if pair in pair_dict:\n",
    "                pass\n",
    "            else:\n",
    "                # use the cutoff the prioritize closer distances and penalize farther distance.\n",
    "                # don't use cutoff for pairs containing the most popular candidate\n",
    "                if candidate_ids[0] in pair:\n",
    "                    pair_dict[pair] = get_cos(pair[0], pair[1])\n",
    "                else:\n",
    "                    pair_dict[pair] = get_cos(pair[0], pair[1], cutoff)\n",
    "                # flip pair, cosine distance is the same regardless of order.\n",
    "                pair_dict[(pair[1], pair[0])] = pair_dict[pair]\n",
    "            \n",
    "            distance.append(pair_dict[pair])\n",
    "        \n",
    "        # normalize distance\n",
    "        if num_distances is not None:\n",
    "            distance = np.sort(distance)[:num_distances]\n",
    "        distance = np.average(distance)\n",
    "        \n",
    "        # set the new shortest distance and candidate id\n",
    "        if distance < shortest_dist:\n",
    "            shortest_dist = distance\n",
    "            candidate_id = product[0]\n",
    "            if candidate_id == candidate_ids[0]:\n",
    "                candidate_0_dist = shortest_dist\n",
    "    \n",
    "    # prioritize the most popular id if the difference in the distance between the shortest candidate id and\n",
    "    # most popular id is less than the 'tune' parameter\n",
    "    if (candidate_0_dist-shortest_dist) < tune*candidate_0_dist:\n",
    "        candidate_id = candidate_ids[0]\n",
    "    \n",
    "    if verbose == False:\n",
    "        return candidate_id == true_id\n",
    "    # this section helps tune the model\n",
    "    # allows us to identify which identies the embedding model identifies correctly that\n",
    "    # the baseline model identifies incorrectly and vice versa\n",
    "    elif candidate_id != candidate_ids[0]:\n",
    "        if candidate_id == true_id:\n",
    "            return 'Model Correct', shortest_dist, candidate_0_dist\n",
    "        elif candidate_ids[0] == true_id:\n",
    "            return 'Baseline Correct', shortest_dist, candidate_0_dist\n",
    "        else:\n",
    "            return 'Both Incorrect', shortest_dist, candidate_0_dist\n",
    "\n",
    "test_samples = [format_sample(i, 10, 8, 10) for i in entity_df.sample(10, random_state=3).to_numpy()]\n",
    "[disambiguate(i) for i in test_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vL2ntZgeduI4",
    "outputId": "b1eae6bd-6b72-4a6b-96a7-930b3d8cf5f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This system has 16\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "n_cores = mp.cpu_count()\n",
    "print(f'This system has {n_cores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYnBP9F_duJS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## function to parellize our test\n",
    "def run_model(samples_per_iter, iterations, seed,\\\n",
    "              max_candidate_ids, max_neighbors, max_neighbor_ids, \\\n",
    "              num_distances=None, cutoff=1, tune=0, skip_nonroot=False, verbose=False, \\\n",
    "              samples_only=False, provided_samples=None, compare=False):\n",
    "    \n",
    "    # create partial functions for multiprocessing\n",
    "    if provided_samples is None:\n",
    "        format_sample_part = partial(format_sample, max_candidate_ids=max_candidate_ids, \\\n",
    "                                     max_neighbors=max_neighbors, max_neighbors_ids=max_neighbor_ids)\n",
    "\n",
    "    disambiguate_part = partial(disambiguate, num_distances=num_distances, cutoff=cutoff, \\\n",
    "                                tune=tune, skip_nonroot=skip_nonroot, verbose=verbose)\n",
    "    \n",
    "    # create pool\n",
    "    p = mp.Pool(n_cores-1)\n",
    "    \n",
    "    samples_list = []\n",
    "    scores = []\n",
    "    tune_list = []\n",
    "    for i in range(iterations):\n",
    "        st = time.time()\n",
    "        \n",
    "        # create the samples or use the provided samples\n",
    "        if provided_samples is None:\n",
    "            if seed is not None:\n",
    "                samples = entity_df.sample(samples_per_iter, random_state=seed+i).to_numpy()\n",
    "            else:\n",
    "                samples = entity_df.sample(samples_per_iter).to_numpy()\n",
    "            formatted_samples = p.map(format_sample_part, samples)\n",
    "        else:\n",
    "            if len(provided_samples) < iterations:\n",
    "                raise Exception(f'Length of provided samples is less than the number of iterations')\n",
    "            formatted_samples = provided_samples[i]\n",
    "        \n",
    "        # if you only want to get formatted sample and not run the model\n",
    "        if samples_only:\n",
    "            if provided_samples is not None:\n",
    "                raise Exception(f'provided samples should be None if samples only is True')\n",
    "            samples_list.append(formatted_samples)\n",
    "            continue\n",
    "        \n",
    "        # run the model\n",
    "        emb_results = p.map(disambiguate_part, formatted_samples)\n",
    "        \n",
    "        # return results if verbose is false\n",
    "        if verbose == False:\n",
    "            emb_score = sum(emb_results)/len(emb_results)\n",
    "            # campares with the baseline result\n",
    "            if compare:\n",
    "                baseline_results = [disambiguate(i, baseline=True) for i in formatted_samples]\n",
    "                base_score = sum(baseline_results)/len(baseline_results)\n",
    "\n",
    "                print(f'Run: {i}\\tembedding model results: {emb_score}\\tbaseline results: {base_score}\\ttime:{time.time()-st}')\n",
    "                scores.append([emb_score, base_score])\n",
    "            else:\n",
    "                print(f'Run: {i}\\tembedding model results: {emb_score}\\ttime:{time.time()-st}')\n",
    "                scores.append(emb_score)\n",
    "        # display a summary of cases where the model candidate differs from the baseline candidate\n",
    "        else:\n",
    "            print(f'Run: {i}\\tsamples: {samples_per_iter}\\tTime:{time.time()-st}')\n",
    "            tune_result = [j for j in emb_results if type(j)==tuple]\n",
    "            tune_df = pd.DataFrame(tune_result, columns=['result', 'model_dist', 'cand_0_dist'])\n",
    "            tune_df['diff'] = tune_df.cand_0_dist-tune_df.model_dist\n",
    "            tune_df['diff_pct'] = tune_df['diff']/tune_df['cand_0_dist']\n",
    "            tune_list.append(tune_df.groupby('result').describe().T.round(6))\n",
    "                \n",
    "    p.close()\n",
    "    p.join()\n",
    "    \n",
    "    if samples_only:\n",
    "        return samples_list\n",
    "    if verbose:\n",
    "        return tune_list\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Testing\n",
    "- 12 tests\n",
    "    - Varying the number of neighbors: 2, 4, 6 or 8\n",
    "    - Varying how we calculate a product's distance:\n",
    "        - avg\n",
    "        - min2\n",
    "        - min\n",
    "    - Compare with baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FnTcnY5TduJi",
    "outputId": "45930ce6-a185-47b9-d637-b2469976ef35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\tembedding model results: 0.6214\tbaseline results: 0.6976\ttime:14.280253887176514\n",
      "Run: 1\tembedding model results: 0.619\tbaseline results: 0.7018\ttime:14.17073392868042\n",
      "Run: 2\tembedding model results: 0.6142\tbaseline results: 0.7072\ttime:13.32659363746643\n",
      "Run: 3\tembedding model results: 0.6122\tbaseline results: 0.7008\ttime:12.951019763946533\n",
      "Run: 4\tembedding model results: 0.6186\tbaseline results: 0.7036\ttime:13.036087036132812\n",
      "Run: 0\tembedding model results: 0.6572\ttime:14.748671531677246\n",
      "Run: 1\tembedding model results: 0.6586\ttime:14.451686382293701\n",
      "Run: 2\tembedding model results: 0.657\ttime:13.32590937614441\n",
      "Run: 3\tembedding model results: 0.6576\ttime:13.298765420913696\n",
      "Run: 4\tembedding model results: 0.6578\ttime:13.504654884338379\n",
      "Run: 0\tembedding model results: 0.6418\ttime:14.809544086456299\n",
      "Run: 1\tembedding model results: 0.6404\ttime:14.535355806350708\n",
      "Run: 2\tembedding model results: 0.6416\ttime:13.64183259010315\n",
      "Run: 3\tembedding model results: 0.6376\ttime:13.093144178390503\n",
      "Run: 4\tembedding model results: 0.6368\ttime:13.099617719650269\n",
      "CPU times: user 24 s, sys: 13.7 s, total: 37.7 s\n",
      "Wall time: 3min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test with 8 neighbors\n",
    "# This run averages all the pair distances\n",
    "avg_results_5_8_5 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                              max_candidate_ids=5, max_neighbors=8, max_neighbor_ids=5, \\\n",
    "                              num_distances=None, cutoff=1, tune=0, skip_nonroot=False, verbose=False, compare=True)\n",
    "# This run takes the minimum of the pair distances\n",
    "min_results_5_8_5 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                              max_candidate_ids=5, max_neighbors=8, max_neighbor_ids=5, \\\n",
    "                              num_distances=1, cutoff=1, tune=0, skip_nonroot=True, verbose=False)\n",
    "# This run takes the avg of the two lowest pair distances\n",
    "min2_results_5_8_5 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                               max_candidate_ids=5, max_neighbors=8, max_neighbor_ids=5, \\\n",
    "                               num_distances=2, cutoff=1, tune=0, skip_nonroot=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ghZpXEhRduJ6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\tembedding model results: 0.6214\tbaseline results: 0.6976\ttime:11.8698251247406\n",
      "Run: 1\tembedding model results: 0.6184\tbaseline results: 0.7018\ttime:11.645723581314087\n",
      "Run: 2\tembedding model results: 0.6148\tbaseline results: 0.7072\ttime:11.041461706161499\n",
      "Run: 3\tembedding model results: 0.6116\tbaseline results: 0.7008\ttime:10.430354833602905\n",
      "Run: 4\tembedding model results: 0.6188\tbaseline results: 0.7036\ttime:11.102979898452759\n",
      "Run: 0\tembedding model results: 0.6572\ttime:12.427226305007935\n",
      "Run: 1\tembedding model results: 0.6582\ttime:12.090217351913452\n",
      "Run: 2\tembedding model results: 0.657\ttime:11.28080677986145\n",
      "Run: 3\tembedding model results: 0.6576\ttime:10.709951639175415\n",
      "Run: 4\tembedding model results: 0.6574\ttime:11.689359903335571\n",
      "Run: 0\tembedding model results: 0.6416\ttime:12.377830028533936\n",
      "Run: 1\tembedding model results: 0.64\ttime:11.965390682220459\n",
      "Run: 2\tembedding model results: 0.6408\ttime:11.384879112243652\n",
      "Run: 3\tembedding model results: 0.6378\ttime:10.65871000289917\n",
      "Run: 4\tembedding model results: 0.6354\ttime:11.456873655319214\n",
      "CPU times: user 24 s, sys: 13.4 s, total: 37.4 s\n",
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test with 6 neighbors\n",
    "# This run averages all the pair distances\n",
    "avg_results_5_6_5 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                              max_candidate_ids=5, max_neighbors=6, max_neighbor_ids=5, \\\n",
    "                              num_distances=None, cutoff=1, tune=0, skip_nonroot=False, verbose=False, compare=True)\n",
    "# This run takes the minimum of the pair distances\n",
    "min_results_5_6_5 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                              max_candidate_ids=5, max_neighbors=6, max_neighbor_ids=5, \\\n",
    "                              num_distances=1, cutoff=1, tune=0, skip_nonroot=True, verbose=False)\n",
    "# This run takes the avg of the two lowest pair distances\n",
    "min2_results_5_6_5 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                                max_candidate_ids=5, max_neighbors=6, max_neighbor_ids=5, \\\n",
    "                                num_distances=2, cutoff=1, tune=0, skip_nonroot=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLFkiO36duKH",
    "outputId": "e1833171-50da-4b37-9632-a56b6627f52b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\tembedding model results: 0.6194\tbaseline results: 0.6976\ttime:7.18010139465332\n",
      "Run: 1\tembedding model results: 0.6174\tbaseline results: 0.7018\ttime:7.505652904510498\n",
      "Run: 2\tembedding model results: 0.6122\tbaseline results: 0.7072\ttime:7.122723817825317\n",
      "Run: 3\tembedding model results: 0.609\tbaseline results: 0.7008\ttime:7.195120334625244\n",
      "Run: 4\tembedding model results: 0.6174\tbaseline results: 0.7036\ttime:7.023998498916626\n",
      "Run: 0\tembedding model results: 0.6572\ttime:7.270432472229004\n",
      "Run: 1\tembedding model results: 0.6566\ttime:7.444277048110962\n",
      "Run: 2\tembedding model results: 0.657\ttime:7.131660461425781\n",
      "Run: 3\tembedding model results: 0.6556\ttime:7.175067663192749\n",
      "Run: 4\tembedding model results: 0.6548\ttime:7.091807126998901\n",
      "Run: 0\tembedding model results: 0.6402\ttime:7.29192852973938\n",
      "Run: 1\tembedding model results: 0.6368\ttime:7.5221545696258545\n",
      "Run: 2\tembedding model results: 0.6386\ttime:7.222554445266724\n",
      "Run: 3\tembedding model results: 0.6352\ttime:7.222391128540039\n",
      "Run: 4\tembedding model results: 0.6346\ttime:7.115509271621704\n",
      "CPU times: user 24 s, sys: 13.6 s, total: 37.6 s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test with 4 neighbors\n",
    "# This run averages all the pair distances\n",
    "avg_results_5_4_5 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                              max_candidate_ids=5, max_neighbors=4, max_neighbor_ids=5, \\\n",
    "                              num_distances=None, cutoff=1, tune=0, skip_nonroot=False, verbose=False, compare=True)\n",
    "# This run takes the minimum of the pair distances\n",
    "min_results_5_4_5 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                              max_candidate_ids=5, max_neighbors=4, max_neighbor_ids=5, \\\n",
    "                              num_distances=1, cutoff=1, tune=0, skip_nonroot=True, verbose=False)\n",
    "# This run takes the avg of the two lowest pair distances\n",
    "min2_results_5_4_5 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                               max_candidate_ids=5, max_neighbors=4, max_neighbor_ids=5, \\\n",
    "                               num_distances=2, cutoff=1, tune=0, skip_nonroot=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6eyhh6iFduKS",
    "outputId": "2f910e4e-f707-46f1-d84b-e0ef1a45e0c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\tembedding model results: 0.6134\tbaseline results: 0.6976\ttime:6.148474931716919\n",
      "Run: 1\tembedding model results: 0.613\tbaseline results: 0.7018\ttime:6.42002272605896\n",
      "Run: 2\tembedding model results: 0.6068\tbaseline results: 0.7072\ttime:6.083094596862793\n",
      "Run: 3\tembedding model results: 0.6062\tbaseline results: 0.7008\ttime:6.220197439193726\n",
      "Run: 4\tembedding model results: 0.613\tbaseline results: 0.7036\ttime:6.074277400970459\n",
      "Run: 0\tembedding model results: 0.6468\ttime:6.1206700801849365\n",
      "Run: 1\tembedding model results: 0.6438\ttime:6.344019889831543\n",
      "Run: 2\tembedding model results: 0.6452\ttime:6.0582497119903564\n",
      "Run: 3\tembedding model results: 0.6426\ttime:6.163923978805542\n",
      "Run: 4\tembedding model results: 0.6418\ttime:6.099238157272339\n",
      "Run: 0\tembedding model results: 0.6148\ttime:6.129559278488159\n",
      "Run: 1\tembedding model results: 0.6164\ttime:6.414912700653076\n",
      "Run: 2\tembedding model results: 0.6096\ttime:6.047934532165527\n",
      "Run: 3\tembedding model results: 0.6088\ttime:6.205032110214233\n",
      "Run: 4\tembedding model results: 0.6146\ttime:6.059201955795288\n",
      "CPU times: user 23.7 s, sys: 13.1 s, total: 36.8 s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test with 2 neighbors\n",
    "# This run averages all the pair distances\n",
    "avg_results_5_2_5 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                              max_candidate_ids=5, max_neighbors=2, max_neighbor_ids=5, \\\n",
    "                              num_distances=None, cutoff=1, tune=0, skip_nonroot=False, verbose=False, compare=True)\n",
    "# This run takes the minimum of the pair distances\n",
    "min_results_5_2_5  = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                               max_candidate_ids=5, max_neighbors=2, max_neighbor_ids=5, \\\n",
    "                               num_distances=1, cutoff=1, tune=0, skip_nonroot=True, verbose=False)\n",
    "# This run takes the avg of the two lowest pair distances\n",
    "min2_results_5_2_5  = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                                max_candidate_ids=5, max_neighbors=2, max_neighbor_ids=5, \\\n",
    "                                num_distances=2, cutoff=1, tune=0, skip_nonroot=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0wxrb7mrduKf",
    "outputId": "0b7a9999-fb2a-4832-8c77-9ddb4113d84a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2 Neighbors</th>\n",
       "      <th>4 Neighbors</th>\n",
       "      <th>6 Neighbors</th>\n",
       "      <th>8 Neighbors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min distance</th>\n",
       "      <td>0.64404</td>\n",
       "      <td>0.65624</td>\n",
       "      <td>0.65748</td>\n",
       "      <td>0.65764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg 2 min distances</th>\n",
       "      <td>0.61284</td>\n",
       "      <td>0.63708</td>\n",
       "      <td>0.63912</td>\n",
       "      <td>0.63964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg all distances</th>\n",
       "      <td>0.61048</td>\n",
       "      <td>0.61508</td>\n",
       "      <td>0.61700</td>\n",
       "      <td>0.61708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.70220</td>\n",
       "      <td>0.70220</td>\n",
       "      <td>0.70220</td>\n",
       "      <td>0.70220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     2 Neighbors  4 Neighbors  6 Neighbors  8 Neighbors\n",
       "min distance             0.64404      0.65624      0.65748      0.65764\n",
       "avg 2 min distances      0.61284      0.63708      0.63912      0.63964\n",
       "avg all distances        0.61048      0.61508      0.61700      0.61708\n",
       "baseline                 0.70220      0.70220      0.70220      0.70220"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "def process_results(avg_r, min_r, min2_r):\n",
    "    avg_r, base_r = zip(*avg_r)\n",
    "    return [np.average(i) for i in [min_r, min2_r, avg_r, base_r]]\n",
    "\n",
    "neighbor_8 = process_results(avg_results_5_8_5, min_results_5_8_5, min2_results_5_8_5)\n",
    "neighbor_6 = process_results(avg_results_5_6_5, min_results_5_6_5, min2_results_5_6_5)\n",
    "neighbor_4 = process_results(avg_results_5_4_5, min_results_5_4_5, min2_results_5_4_5)\n",
    "neighbor_2 = process_results(avg_results_5_2_5, min_results_5_2_5, min2_results_5_2_5)\n",
    "\n",
    "ind = np.arange(4)\n",
    "labels = ['min distance', 'avg 2 min distances', 'avg all distances', 'baseline']\n",
    "width = 0.2\n",
    "\n",
    "for i, j in enumerate(zip(neighbor_2, neighbor_4, neighbor_6, neighbor_8)):\n",
    "    plt.bar(ind+i*width, j, width, label=labels[i])\n",
    "\n",
    "plt.ylim(0.55, 0.75)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Results: Neighbors vs Distances\")\n",
    "x_lbls='2 Neighbors', '4 Neighbors', '6 Neighbors', '8 Neighbors'\n",
    "plt.ylabel('accuracy score')\n",
    "plt.xticks(ind + 1.5*width, x_lbls)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "pd.DataFrame(zip(neighbor_2, neighbor_4, neighbor_6, neighbor_8), columns=x_lbls, index=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pq-XZN3Njiru"
   },
   "source": [
    "# Initial Results\n",
    "\n",
    "In the graph above, we show the accuracy rates of running our entity linking algorithm on several models over **5 runs** utilizing the same **sequence of random seeds**:\n",
    "\n",
    "We used four methods to choose our candidate_id (represented by the bolded text below)\n",
    "1. Embedding Model: Select the candidate from the product with the lowest distane:\n",
    "    1. **Avg** - Average all the pair distances.\n",
    "    2. **2 min** - Average the two lowest pair distances.\n",
    "    3. **min** - Take the min of the pair distances.\n",
    "4. **Baseline** - ignore neighbors and select the candidate with the highest view-count\n",
    "\n",
    "We also varied the number of neighbor between 2, 4, 6 and 8 for each test set.\n",
    "\n",
    "### Initial Results - Discussion\n",
    "We note that none of the preliminary models could beat the baseline model. The baseline model's performance make intuitive sense, since it selects entities based on the highest views on Wikipedia and we are testing on text from Wikipedia. The baseline sets a high bar for performance and will be challenge for our embedding model to beat.\n",
    "\n",
    "However, we get some important results from this initial test. We can see that the embedding model that selected a candiate based on the pair with the lowest cosine distance in a product (**min**) produced the best results. Averaging all the distances produced the worst results.\n",
    "\n",
    "We also see that the embedding models performed the worst with only 2 neighbors. 4, 6 and 8 neighbors produced very similar results. This means that the pair with the **lowest distance** is within the **first 4 neighbors**.\n",
    "\n",
    "The results also give us some hope that our **min** embedding model has the potential to beat the baseline and will be the starting point for the next stage of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O2UMVVeFduK2",
    "outputId": "ebcfefcd-15b6-474b-d632-11bc08b8e966",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\tembedding model results: 0.6574\ttime:16.279025554656982\n",
      "Run: 1\tembedding model results: 0.6568\ttime:15.432007312774658\n",
      "Run: 2\tembedding model results: 0.6562\ttime:13.788188695907593\n",
      "Run: 3\tembedding model results: 0.6546\ttime:13.940263986587524\n",
      "Run: 4\tembedding model results: 0.6536\ttime:13.502338171005249\n",
      "Run: 0\tembedding model results: 0.6538\ttime:8.21359395980835\n",
      "Run: 1\tembedding model results: 0.6538\ttime:8.343407392501831\n",
      "Run: 2\tembedding model results: 0.6532\ttime:7.927807807922363\n",
      "Run: 3\tembedding model results: 0.6524\ttime:8.075305938720703\n",
      "Run: 4\tembedding model results: 0.6524\ttime:7.902083873748779\n",
      "Run: 0\tembedding model results: 0.6546\ttime:22.71076202392578\n",
      "Run: 1\tembedding model results: 0.6544\ttime:21.992528676986694\n",
      "Run: 2\tembedding model results: 0.6524\ttime:18.281537771224976\n",
      "Run: 3\tembedding model results: 0.6512\ttime:19.32702612876892\n",
      "Run: 4\tembedding model results: 0.6514\ttime:19.10930585861206\n",
      "CPU times: user 24 s, sys: 13.5 s, total: 37.6 s\n",
      "Wall time: 3min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test increasing the number of candidate and neighbor ids\n",
    "# All runs takes the minimum of the pair distances with 4 neighbors\n",
    "min_results_5_4_10 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                          max_candidate_ids=5, max_neighbors=4, max_neighbor_ids=10, \\\n",
    "                          num_distances=1, cutoff=1, tune=0, skip_nonroot=True, verbose=False)\n",
    "min_results_10_4_5 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                          max_candidate_ids=10, max_neighbors=4, max_neighbor_ids=5, \\\n",
    "                          num_distances=1, cutoff=1, tune=0, skip_nonroot=True, verbose=False)\n",
    "min_results_10_4_10 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                          max_candidate_ids=10, max_neighbors=4, max_neighbor_ids=10, \\\n",
    "                          num_distances=1, cutoff=1, tune=0, skip_nonroot=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\tembedding model results: 0.656\ttime:6.289856672286987\n",
      "Run: 1\tembedding model results: 0.6578\ttime:6.475723028182983\n",
      "Run: 2\tembedding model results: 0.6572\ttime:6.172241926193237\n",
      "Run: 3\tembedding model results: 0.6552\ttime:6.303820371627808\n",
      "Run: 4\tembedding model results: 0.6544\ttime:6.2078070640563965\n",
      "Run: 0\tembedding model results: 0.6628\ttime:7.921476602554321\n",
      "Run: 1\tembedding model results: 0.6646\ttime:8.44571566581726\n",
      "Run: 2\tembedding model results: 0.661\ttime:7.8685243129730225\n",
      "Run: 0\tembedding model results: 0.6628\ttime:6.281347274780273\n",
      "Run: 1\tembedding model results: 0.6662\ttime:6.615871906280518\n",
      "Run: 2\tembedding model results: 0.661\ttime:6.201300621032715\n",
      "CPU times: user 17.4 s, sys: 12.7 s, total: 30.2 s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Testing reducing the number of candidate and neighbor ids\n",
    "# All runs takes the minimum of the pair distances with 4 neighbors\n",
    "min_results_5_4_3 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                              max_candidate_ids=5, max_neighbors=4, max_neighbor_ids=3, \\\n",
    "                              num_distances=1, cutoff=1, tune=0, skip_nonroot=True, verbose=False)\n",
    "min_results_3_4_5 = run_model(samples_per_iter=5000, iterations=3, seed=1636, \\\n",
    "                              max_candidate_ids=3, max_neighbors=5, max_neighbor_ids=5, \\\n",
    "                              num_distances=1, cutoff=1, tune=0, skip_nonroot=True, verbose=False)\n",
    "min_results_3_4_3 = run_model(samples_per_iter=5000, iterations=3, seed=1636, \\\n",
    "                              max_candidate_ids=3, max_neighbors=5, max_neighbor_ids=3, \\\n",
    "                              num_distances=1, cutoff=1, tune=0, skip_nonroot=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DGVHTZ4CduK9",
    "outputId": "041bb469-bb33-4754-ace6-3afb6f4889f5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAGECAYAAACPn6xqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdf5xVVb3/8ddbfggKgj+5JqbYNRMhUEa0EhsyDU1FTW9qmT8j66rptR/ce/uaZaWphZaWoRl2tcbfiEr+TDT8LYoKogVGChoGKApKiXy+f+w14+ZwZuagc87Mnnk/H4/zmL3XXnvttfbZzHxYa++9FBGYmZmZWce3XntXwMzMzMwq48DNzMzMrCAcuJmZmZkVhAM3MzMzs4Jw4GZmZmZWEA7czMzMzArCgZtZDUiaJumE9q7H+yHpC5LuaO96VErSAEn3SXpD0k/asR5N331r57Co14mkMyVdWYVyR0l6rsK89ZIWtLB9kqQftF3t1ip/tqT691I3s3XhwM26HEnzJb0labmkv6df6H1qePxjJE1vg3I+JmmFpL5ltj0h6aT3e4y8iLgqIvZpyzLLkfSIpO0lbSfp8fdR1DhgMbBRRJzeRtV7X9ryHKbr+NNtUVZHFRF/iogd2rselYiInSJiWnvXwzo/B27WVR0QEX2A4cDOwH+3c33WWUQ8CCwAPpdPlzQEGAz8fl3Kk9S97Wr33kjqAWwDzAVGAO8ncNsGeCb8lnFrQ8r4b6e1G1981qVFxN+B28kCOAAk7S7pAUmvSXoyP/yResueT8Nvf5X0hZS+xlCRpG0lRWkwJGlH4BLgY6nH77WUvp+kZ1K5CyV9o8ImXAF8qSTtS8CtEbFE0oWSXpT0uqQZkkbl6nKmpOskXSnpdWC8pDclbZrLM0LSPyT1KO0pTO07UdJfJL0q6WJJStu6SfqJpMXpPJ1U7nyUMYR3g606WgncJH1c0qOSlqWfH0/pk4CjgW+l87xWz5Sk3qmOf0v7T5fUO227NvXGLkvDrTvl9puU2npr+r4elvSh3Pa9JT2b9r0IUG5b6TlsKe+HJP1R0pJ0Hq+S1D9t+z/gg8DNqX3fSunNXrtl2j9e0rzUhmckHVxaT0nnp+/2r5L2zW0fJOnetO+dwGYtHKde0gJJp0t6RdLLko7NbV8/HecFSYskXZL7HtYYYpS0i7Le5DfSd3S1SoY/mztOspmkO9P+90raJrdf2WspbZsm6YeS7gfeBLYr086mHtB0bU1K5+4ZYNeSvN9W9u/8DUnPSdqrufNntpaI8MefLvUB5gOfTssDgaeBC9P6VsASYD+y/9jsndY3BzYEXgd2SHm3BHZKy2cCV+aOsS0QQPe0Pg04IS0fA0wvqdPLwKi0vDGwS27ba8AezbRla+Bt4INpfT2yXriD0voXgU2B7sDpwN+BXrk6vw0clPbrDUwFvporfwLw83L1Tu27BehPFkT8AxiTtp0IPJPO78bAXfnzUaYdx6Z2vgmsTMurgDfS8qAy+2wCvAocldp3RFrfNG2fBPyghevg4vS9bAV0Az4OrJ+2HQf0BdYHLgBm5vabBCwFRqbjXgU0pG2bpWvkUKAHcFpqx1rffQV5/53s+luf7Pq7D7ig3HXc2rXbTPsPAz6Q8n4eWAFsmavn28CX07n5KvASoLT9QeCnqW57pu/pymaOU5/a9f3Uzv3S97xx2n4BMCV9n32Bm4Gzc/suSMs9gb8BX0/lHAL8q/E7ruA4k1I990z1vjD3XbR2LU0DXgB2Stt7tPJ75RzgT6ncrYFZuXbsALwIfCD3u+JD7f170Z/ifNq9Av74U+tP+gW7PP0SD+BuoH/a9m3g/0ry307We7MhWRDxOaB3SZ4zeX+B2wvAV8jux1rX9twF/E9a3pvsvq61/rCk7a8Cw3J1vq9k++eB+9NyN7JAb2S5eqf27ZFbvwYYn5b/CHwlt+3TtBC45fL9iaz384PATFKg0Ezeo4BHStIeBI5Jy5NoJnAjC1beajwXrdSpf6p7v1y5l+W27wc8m5a/BDyU2yayQLpc4NZi3jL1OAh4ouQ6zgduzV67FV5HM4GxuXrOzW3bIJ2Df0vfzSpgw9z239Fy4PZW/rsHXgF2T21eQS5wAT4G/DW3b2PAsyewMH9NANNZM3Are5zc99aQ29YHeIcssGrtWpoGfL+V89f0fQDPk/4Tk9bH5drx76len6aZf6f++NPSx0Ol1lUdFBF9yX7Zf4R3h3q2AQ5LQ02vKRvK3IOsJ2IFWWBzIvByGir7SBvV53NkAcDf0hDOx9Zh3/xw6VHA7yLibWgaNpqThn9eA/qx5rDWiyVl3QQMlrQdWRC4LCIeaeHYf88tv0n2xxCynpx82aXHaSJpk3Sul5H1ek0DniPrmXhV0qnN7PoBsh6YvL+R9Ty1ZjOgFzCvTH26STonDSO+TvYHuXGfRhW1OyKC5tveYl5JW0hqSENqrwNX0sKQJC1cu+UyS/qSpJm5vEOaa2NEvJkW+6R6v5r+PTQq/R5KLYmIVbn1xnO2OVlQOCNXj9tSeqkPAAvTeWpUem6bO85a+SNiOVnP6Qeo7Fpq9hpupq75/E1lR8Rc4FSy/zi9kr7jD6xD2dbFOXCzLi0i7iX7n/j5KelFsl6L/rnPhhFxTsp/e0TsTfbH8Fng0rTfCrI/QI3+raXDlqnHoxExFtgCmEzWe1WpG4CtJI0mGz76LWSvUiDrhfkPsuGi/sAycvdRldYlIlamY3+BLAj8v3WoR97LZMOkjbZuLmNELE11+wpZT1Z/sj/eB6Tzf0Ezu75EFqzkfZCsV6Y1i8mGZD9UZtuRwFiyHpF+ZL2nsOZ5a87L5NoqSTTf9tbynk32/Xw0IjYiG/Zu9rujlWs3L93bdSlwEtlwYH+y4bxK27ixpA1zaR+sYL9yFpP1ku2Uq3O/yB4cKnfcrdJ5atTsddWM/PnuQzaU+RKVXUtr/bttwRrfLSXnJyJ+FxF7pGMG8ON1KNu6OAduZtk9NntLGk7Wq3GApM+knpde6QbpgcreC3Zg+oP1T7Lh1ndSGTOBPSV9UFI/Wn5KdREwUFJPAEk9lb3fq1/qKXs9V26rUs/HdcBvgL9FxGNpU1+yIa1/AN0lnQFsVEGRvyUbKjswnY/34hrg65K2UnZD/bcr2Cf/FOnOwIxW8k8FPizpSEndJX2e7GnaW1o7UESsBi4HfirpA+m7/pik9cnO2z/J7g/bAPhRBXVvdCuwk6RDlD2IcQrNB/Gt5e1Ldo29Jmkr4Jsl+y9izZvkm712yxx7Q7KA4R8A6Sb+IZU0MCL+BjwGfC9du3sAB1Syb5myVpMFkBMkbZHqspWkz5TJ/iDZv4uT0vc9luw+w3Wxn6Q90r+9s4CHI+JF3se11IxrgP+WtHE6/yc3bpC0g6RPpWttJVngWvG/dzMHbtblRcQ/yIKV/5d+iY8F/ofsj9qLZH8w10uf08n+d74U+CTwtVTGncDVwFNkAUdLv/D/CMwG/i5pcUo7CpifhsROJOtdAUDZU4Oj1i5mDVeQ/e/9t7m024E/AH8mG6pZSQXDPRFxP7AaeDwi5reWvxmXAneQnY8nyP4wrqLlP1AjgMeVPdX6TkS82ko9lwD7k30nS4BvAftHxOKW9sv5BtmDKY+SfZ8/JvuOf0t2vhaSPWDxUIXlkY59GNnN6UuA7YH732Pe7wG7kPWS3krWs5p3NvCdNMT4jVau3dJjPwP8hCwYWgQMba6ezTgS2I3svH2XNa+7dfVtste/PJSu/7vIhslL6/wvsh7l48nuNf0i2b+zf67DsX6X6ruU7Hr7Qir7/V5Lpb5Hdg39lezfQb7nen2y73wx2XD0FmTfmVlFGp8QMjNrIumPZPfKXdZG5e0LXBIRpcNRZu+ZpIfJrqvftHddzGrFPW5mtgZJu5L19Fz9PsrorezddN3TMN93gRvbqo7WNUn6pKR/S9fV0cBHye6HNOsyqhq4SRqTXi44V9L4Mtu/mZ5qmilplqR3JG2Sts2X9HTa9lhun02UvUDxL+nnxtVsg1lXIukKsqGqUyPijfdTFNlw0atkQ6VzgDPefw2ti9sBeJJs+Ph04NCIeLl9q2RWW1UbKpXUjezemr3J3k30KHBEureiXP4DgNMi4lNpfT5QV3qPgaRzgaURcU4KBjeOiEpufDYzMzMrtGr2uI0ke4Hj8+mm0gayG2ebcwSVza04luxGbNLPg95XLc3MzMwKopqB21as+QTbApp5MaakDYAxwPW55ADuUDa/4rhc+oDGrvH0c4s2rbWZmZlZB9XahM/vR7kXOTY3LnsA2TQ7S3Npn4iIl9K7fe6U9GxE3FfxwbNgbxxA7969R2y99bq+p7HjW716Neut13WfL+nq7QefA7ff7Xf7u277ofOegz//+c+LI6LcDCJVDdwWsOaboweSvf+qnMMpGSaNiJfSz1ck3Ug29HofsEjSlhHxsqQtyeZ8W0tETAQmAtTV1cVjjz1WLluhTZs2jfr6+vauRrvp6u0HnwO33+13++vbuxrtqrOeA0nNTiNXzTD1UWB7SYPSW6oPB6aUqVw/sheZ3pRL21BS38ZlYB+y6VhIZRydlo/O72dmZmbWmVWtxy0iVkk6iezt7d2AyyNitqQT0/ZLUtaDgTtKJiweANyYpqTrTvYi0MZ39ZwDXCPpeOAFsjePm5mZmXV61RwqJSKmkk11k0+7pGR9Etkk3/m054FhzZS5BNirLetpZmZmVgRVDdzMzMza29tvv82CBQtYuXJle1elTfXr1485c+a0dzXaVdHPQa9evRg4cCA9evSoeB8HbmZm1qktWLCAvn37su2225JuwekU3njjDfr27dve1WhXRT4HEcGSJUtYsGABgwYNqni/zvcMrZmZWc7KlSvZdNNNO1XQZsUniU033XSde4IduJmZWafnoM06ovdyXTpwMzMzq4F33nmHnXfemf3337/s9jPPPJMNNtiAV1559/Wkffr0abXc/fbbj9dee63FPPX19ZR7n+mkSZM46aSTWj1GW5k0aRKSuPvuu5vSbrzxRiRx3XXXAXDCCSfwzDNlpzVvtszNN9+cnXfeme23357PfOYzPPDAA03bzzjjDO66665m9588efI6Ha+9+R43MzPrUrYdf2ubljf/nM9WlO/CCy9kxx135PXXX282z2abbcZPfvITfvzjH1d8/KlTp7aeqQoigohY55kLhg4dyu9//3v22it7QURDQwPDhr37IonLLrtsnevy+c9/nosuugiAe+65h0MOOYR77rmHHXfcke9///st7jt58mT2339/Bg8evM7HbQ/ucTMzM6uyBQsWcOutt3LCCSe0mO+4447j6quvZunSpWttu/LKKxk5ciTDhw/nK1/5Cu+88w4A2267LYsXLwbgrLPO4iMf+Qh77703RxxxBOeff37T/tdeey0jR47kwx/+MH/605+a0l988UXGjBnDDjvswPe+972m9J/+9KcMGTKEIUOGcMEFFwAwf/58dtxxR772ta+xyy678OKLL3LMMccwZMgQhg4dyoQJE1o9F6NGjeKRRx7h7bffZvny5cydO5fhw4c3bc/3Dvbp04f//d//ZdiwYey+++4sWrSo1fJHjx7NuHHjmDhxIgDHHHNMU2/e+PHjGTx4MB/96Ef5xje+wQMPPMCUKVP45je/yfDhw5k3bx6XXnopu+66K8OGDeNzn/scb775ZlM5p5xyCh//+MfZbrvtmsoEOPfccxk6dCjDhg1j/PjxAMybN48xY8YwYsQIRo0axbPPPttq3SvhwM3MzKzKTj31VM4999xWe6f69OnDcccdx4UXXrhG+pw5c7j66qu5//77mTlzJt26dePqq69eI89jjz3G9ddfzxNPPMENN9yw1tDoqlWreOSRR7jgggvWCNAeeeQRrrrqKmbOnMm1117LY489xowZM/jNb37Dww8/zEMPPcSll17KE088AcBzzz3Hl770JZ544gkWL17MwoULmTVrFk8//TTHHntsq+dCEp/+9Ke5/fbbuemmmzjwwAObzbtixQp23313nnzySfbcc08uvfTSVssH2GWXXdYKlJYuXcqNN97I7Nmzeeqpp/jOd77Dxz/+cQ488EDOO+88Zs6cyYc+9CEOOeQQHn30UZ588kl23HFHfv3rXzeV8fLLLzN9+nRuueWWpgDtD3/4A5MnT+bhhx/mySef5Fvf+hYA48aN4+c//zkzZszg/PPP52tf+1pFdW+NAzczM7MquuWWW9hiiy0YMWJERflPOeUUrrjiijWGVO+++25mzJjBrrvuyvDhw7n77ruZP3/+GvtNnz6dsWPH0rt3b/r27csBBxywxvZDDjkEgBEjRqyx7957782mm25K7969OeSQQ5g+fTrTp0/n4IMPZsMNN6RPnz4ccsghTb1022yzDbvvvjsA2223Hc8//zwnn3wyt912GxtttFFFbTz88MNpaGigoaGBI444otl8PXv2bLonsLTeLYmItdI22mgjevXqxQknnMANN9zABhtsUHbfWbNmMWrUKIYOHcpVV13F7Nmzm7YddNBBrLfeegwePLip9++uu+7i2GOPbSpvk002Yfny5TzwwAMcdthhTT2kL7/8ckV1b43vcTMzM6ui+++/nylTpjB16lRWrlzJ66+/zhe/+EWuvPLKsvn79+/PkUceyS9+8YumtIjg6KOP5uyzz25Ke+ONN9bYr1ywkrf++usD0K1bN1atWtWUXvpko6QWy9pwww2bljfeeGOefPJJbr/9di6++GKuueYaLr/88hbrATBy5EhmzZpF7969+fCHP9xsvh49ejTVr7TeLXniiSfYcccd10jr3r07jzzyCHfffTcNDQ1cdNFF/PGPf1xr32OOOYbJkyczbNgwJk2axLRp05q2NZ5DePd8R8Ra53D16tX079+fmTNnVlTfdeEeNzMzsyo6++yzWbBgAfPnz6ehoYFPfepTzQZtjf7rv/6LX/3qV02Byl577cV1113X9MTp0qVLeeGFF9bYZ4899uDmm29m5cqVLF++nFtvrewhjDvvvJOlS5fy1ltvMXnyZD7xiU+w5557MnnyZN58801WrFjBjTfeyKhRo9bad/HixaxevZrPfe5znHXWWTz++OMAXHTRRU0PC7R0Xn70ox9VVMd1ce+99zJx4kS+/OUvr5G+fPlyli1bxn777ccFF1zQFFT17dt3jSD4jTfeYMstt+Ttt9/mqquuavV4++yzD5dffnnTvXBLly5lo402YtCgQVx77bVAFtw9+eSTbdI+97iZmZl1MJttthkHH3xw083+gwcP5gc/+AH77LMPq1evpkePHpx77rnstNNOTfvsuuuuHHjggQwbNoxtttmGuro6+vXr1+qx9thjD4466ijmzp3LkUceSV1dHZD1PI0cORLIXtGx8847rzVUuXDhQo499lhWr14N0NQj+Oyzz/KJT3yixePuu+++lZ2MClx99dVMnz6dN998k0GDBnH99dev1eP2xhtvMHbsWFauXElENJ3bww8/nC9/+cv87Gc/47rrruOss85it912Y5tttmHo0KFr9WyWGjNmDDNnzqSuro6ePXuy33778aMf/YirrrqKr371q/zgBz/g7bff5vDDD1/j6dn3Sq11rXYGdXV1Ue79NUU3bdo06uvr27sa7aartx98Dtx+t7+S9s+ZM2etP+KdQbnpnpYvX06fPn1488032XPPPZk4cSK77LJLzeu2//77c8MNN9CzZ8+qHqfIU141Knd9SpoREXXl8rvHzczMrJMYN24czzzzDCtXruToo49ul6ANsgcyrDocuJmZmXUSv/vd79q7ClZlfjjBzMzMrCAcuJmZWafXFe7ntuJ5L9elAzczM+vUevXqxZIlSxy8WYcSESxZsoRevXqt036+x83MzDq1gQMHsmDBAv7xj3+0d1Xa1MqVK9f5j35nU/Rz0KtXLwYOHLhO+zhwMzOzTq1Hjx4MGjSovavR5qZNm8bOO+/c3tVoV13xHHio1MzMzKwgHLiZmZmZFYQDNzMzM7OCcOBmZmZmVhAO3MzMzMwKwoGbmZmZWUE4cDMzMzMrCAduZmZmZgXhwM3MzMysIBy4mZmZmRWEAzczMzOzgnDgZmZmZlYQVQ3cJI2R9JykuZLGl9n+TUkz02eWpHckbSJpa0n3SJojabakr+f2OVPSwtx++1WzDWZmZmYdRfdqFSypG3AxsDewAHhU0pSIeKYxT0ScB5yX8h8AnBYRSyWtD5weEY9L6gvMkHRnbt8JEXF+tepuZmZm1hFVs8dtJDA3Ip6PiH8BDcDYFvIfAfweICJejojH0/IbwBxgqyrW1czMzKzDq2bgthXwYm59Ac0EX5I2AMYA15fZti2wM/BwLvkkSU9JulzSxm1VYTMzM7OOTBFRnYKlw4DPRMQJaf0oYGREnFwm7+eBL0bEASXpfYB7gR9GxA0pbQCwGAjgLGDLiDiuTJnjgHEAAwYMGNHQ0NCWzesQli9fTp8+fdq7Gu2mq7cffA7cfrff7e+67YfOew5Gjx49IyLqym2r2j1uZD1sW+fWBwIvNZP3cNIwaSNJPch64K5qDNoAImJRLs+lwC3lCoyIicBEgLq6uqivr1/3FnRw06ZNozO2q1Jdvf3gc+D2u/1uf317V6NddcVzUM2h0keB7SUNktSTLDibUppJUj/gk8BNuTQBvwbmRMRPS/JvmVs9GJhVhbqbmZmZdThV63GLiFWSTgJuB7oBl0fEbEknpu2XpKwHA3dExIrc7p8AjgKeljQzpf1PREwFzpU0nGyodD7wlWq1wczMzKwjqeZQKSnQmlqSdknJ+iRgUknadEDNlHlUm1bSzMzMrCA8c4KZmZlZQThwMzMzMysIB25mZmZmBeHAzczMzKwgHLiZmZmZFYQDNzMzM7OCcOBmZmZmVhAO3MzMzMwKwoGbmZmZWUE4cDMzMzMrCAduZmZmZgXhwM3MzMysIBy4mZmZmRWEAzczMzOzgnDgZmZmZlYQDtzMzMzMCsKBm5mZmVlBOHAzMzMzKwgHbmZmZmYF4cDNzMzMrCAcuJmZmZkVhAM3MzMzs4Jw4GZmZmZWEA7czMzMzArCgZuZmZlZQThwMzMzMysIB25mZmZmBeHAzczMzKwgHLiZmZmZFYQDNzMzM7OCcOBmZmZmVhAO3MzMzMwKons1C5c0BrgQ6AZcFhHnlGz/JvCFXF12BDaPiKXN7StpE+BqYFtgPvAfEfFqNdthZmZmLbtjt9345+LFNT3m6tNO4+bjj6/pMdffbDP2efjhmh4zr2o9bpK6ARcD+wKDgSMkDc7niYjzImJ4RAwH/hu4NwVtLe07Hrg7IrYH7k7rZmZm1o5qHbS1l/ZuZzWHSkcCcyPi+Yj4F9AAjG0h/xHA7yvYdyxwRVq+AjiozWtuZmZm1gEpIqpTsHQoMCYiTkjrRwG7RcRJZfJuACwA/j31uDW7r6TXIqJ/bt9XI2LjMmWOA8YBDBgwYERDQ0MVWtm+li9fTp8+fdq7Gu2mq7cffA7cfrff7e847V82a1btDzpgACxaVPPD9hsypKrljx49ekZE1JXbVs173FQmrbko8QDg/ohY+h72LSsiJgITAerq6qK+vn5ddi+EadOm0RnbVamu3n7wOXD73X63v769q9Gk1veaQXaP23oTJtT8uPXz5tX8mI2qOVS6ANg6tz4QeKmZvIfz7jBpa/sukrQlQPr5SpvU1szMzKyDq2bg9iiwvaRBknqSBWdTSjNJ6gd8Eripwn2nAEen5aNL9jMzMzPrtKo2VBoRqySdBNxO9kqPyyNitqQT0/ZLUtaDgTsiYkVr+6bN5wDXSDoeeAE4rFptMDMzM+tIqvoet4iYCkwtSbukZH0SMKmSfVP6EmCvtqynmZmZWRF45gQzMzOzgnDgZmZmZlYQDtzMzMzMCsKBm5mZmVlBOHAzMzMzKwgHbmZmZmYF4cDNzMzMrCAcuJmZmZkVhAM3MzMzs4Jw4GZmZmZWEA7czMzMzArCgZuZmZlZQThwMzMzMysIB25mZmZmBeHAzczMzKwgHLiZmZmZFYQDNzMzM7OCcOBmZmZmVhAO3MzMzMwKwoGbmZmZWUE4cDMzMzMrCAduZmZmZgXhwM3MzMysIBy4mZmZmRWEAzczMzOzgnDgZmZmZlYQDtzMzMzMCsKBm5mZmVlBOHAzMzMzKwgHbmZmZmYF4cDNzMzMrCAcuJmZmZkVRFUDN0ljJD0naa6k8c3kqZc0U9JsSfemtB1SWuPndUmnpm1nSlqY27ZfNdtgZmZm1lF0r1bBkroBFwN7AwuARyVNiYhncnn6A78AxkTEC5K2AIiI54DhuXIWAjfmip8QEedXq+5mZmZmHVE1e9xGAnMj4vmI+BfQAIwtyXMkcENEvAAQEa+UKWcvYF5E/K2KdTUzMzPr8BQR1SlYOpSsJ+2EtH4UsFtEnJTLcwHQA9gJ6AtcGBG/LSnncuDxiLgorZ8JHAO8DjwGnB4Rr5Y5/jhgHMCAAQNGNDQ0tHUT293y5cvp06dPe1ej3XT19oPPgdvv9rv9Haf9y2bNqv1BBwyARYtqfth+Q4ZUtfzRo0fPiIi6ctuqNlQKqExaaZTYHRhB1qvWG3hQ0kMR8WcAST2BA4H/zu3zS+CsVNZZwE+A49Y6UMREYCJAXV1d1NfXv5+2dEjTpk2jM7arUl29/eBz4Pa7/W5/fXtXo8nNxx9f82OuPu001pswoebHrZ83r+bHbFTNwG0BsHVufSDwUpk8iyNiBbBC0n3AMODPafu+ZL1tTeF0flnSpcAtVai7mZmZWYdTzXvcHgW2lzQo9ZwdDkwpyXMTMEpSd0kbALsBc3LbjwB+n99B0pa51YOBduibNTMzM6u9qvW4RcQqSScBtwPdgMsjYrakE9P2SyJijqTbgKeA1cBlETELIAVyewNfKSn6XEnDyYZK55fZbmZmZtYpVRS4SdoD2D4ifiNpc6BPRPy1tf0iYiowtSTtkpL184Dzyuz7JrBpmfSjKqmzmZmZWWfT6lCppO8C3+bdBwR6AFdWs1JmZmZmtrZK7nE7mOzJzhUAEfES2as7zMzMzKyGKgnc/hXZy94CQNKG1a2SmZmZmZVTSeB2jaRfAYSyiSQAACAASURBVP0lfRm4C7i0utUyMzMzs1ItPpwgScDVwEfIZirYATgjIu6sQd3MzMzMLKfFwC0iQtLkiBgBOFgzMzMza0eVDJU+JGnXqtfEzMzMzFpUyXvcRgMnSppP9mSpyDrjPlrNipmZmZnZmioJ3Patei3MzMzMrFWtDpVGxN+A/sAB6dM/pZmZmZlZDVUyc8LXgauALdLnSkknV7tiZmZmZramSoZKjwd2i4gVAJJ+DDwI/LyaFTMzMzOzNVXyVKmAd3Lr76Q0MzMzM6uhSnrcfgM8LOnGtH4Q8OvqVamYth1/a82PefrQVRxT4+POP+ezNT2emZmZvavVwC0ifippGrAHWU/bsRHxRLUrZlY0Dt7NzKzaWg3cJO0OzI6Ix9N6X0m7RcTDVa+dmZmZmTWp5B63XwLLc+srUpqZmZmZ1VBFDydERDSuRMRqKrs3zszMzMzaUCWB2/OSTpHUI32+Djxf7YqZmZmZ2ZoqCdxOBD4OLAQWALsB46pZKTMzMzNbWyVPlb4CHF6DupiZmZlZCyqZ8upcSRulYdK7JS2W9MVaVM7MzMzM3lXJUOk+EfE6sD/ZUOmHgW9WtVZmZmZmtpZKArce6ed+wO8jYmkV62NmZmZmzajktR43S3oWeAv4mqTNgZXVrZaZmZmZlark4YTxkn4MvB4R70h6Exhb/apZ0dR6yidP99SxdPUpv7p6+82sNip6kW5EvJpbXkE2e4KZmZmZ1VAl97iZmZmZWQfgwM3MzMysICp5j9v1kj4ryUGemZmZWTuq5B63XwLHAj+TdC0wKSKerW61zMysSPxwhh/QstpotRctIu6KiC8AuwDzgTslPSDpWEk9WtpX0hhJz0maK2l8M3nqJc2UNFvSvbn0+ZKeTtsey6VvIulOSX9JPzeutLFmZmZmRVbR8KekTYFjgBOAJ4ALyQK5O1vYpxtwMbAvMBg4QtLgkjz9gV8AB0bETsBhJcWMjojhEVGXSxsP3B0R2wN3p3UzMzOzTq+Se9xuAP4EbAAcEBEHRsTVEXEy0KeFXUcCcyPi+Yj4F9DA2u9/OxK4ISJegKYJ7VszFrgiLV8BHFTBPmZmZmaFV0mP20URMTgizo6Il/MbSnrCSm0FvJhbX5DS8j4MbCxpmqQZkr6ULx64I6WPy6UPaKxH+rlFBW0wMzMzKzxFRMsZpP8EroqI19L6xsAREfGLVvY7DPhMRJyQ1o8CRqaeusY8FwF1wF5Ab+BB4LMR8WdJH4iIlyRtQTYke3JE3CfptYjonyvj1YhY6z63FOyNAxgwYMCIhoaGVk/G+/H0wmVVLb+cAb1h0Vu1PebQrfo1u63W56Crtx861jlw+93+WutI7Qf/Dlw2a1YNa5IMGACLFtX8sP2GDKlq+aNHj57RXOdYJU+VfjkiLm5ciYhXJX2Z7N60liwAts6tDwReKpNnceNsDJLuA4YBf46Il9LxXpF0I9nQ633AIklbRsTLkrYEyg6vRsREYCJAXV1d1NfXV9DU967WT/ZA9kTRT56uaPKLNjP/C/XNbqv1Oejq7YeOdQ7cfre/1jpS+8G/A28+/vjaVSRZfdpprDdhQs2PWz9vXs2P2aiSodL1JKlxJT100LOC/R4Ftpc0SFJP4HBgSkmem4BRkrpL2gDYDZgjaUNJfdPxNgT2ARpD+SnA0Wn56FSGmZmZWadXSah+O3CNpEvI7js7EbittZ0iYpWkk9L+3YDLI2K2pBPT9ksiYo6k24CngNXAZRExS9J2wI0pXuwO/C4iGo95TqrP8cALrP0kqpmZmVmnVEng9m3gK8BXAQF3AJdVUnhETAWmlqRdUrJ+HnBeSdrzZEOm5cpcQnZPnJmZmVmX0mrgFhGryWZP+GX1q2NmZmZmzWk1cJO0PXA22Ut0ezWmR8R2VayXmZmZmZWo5OGE35D1tq0CRgO/Bf6vmpUyMzMzs7VVErj1joi7yd759reIOBP4VHWrZWZmZmalKnk4YaWk9YC/pKdEF+LZCszMzMxqrpIet1PJ5ik9BRgBfJF336NmZmZmZjXSYo9betnuf0TEN4HlwLE1qZWZmZmZraXFHreIeAcYkZ85wczMzMzaRyX3uD0B3CTpWmBFY2JE3FC1WpmZmZnZWioJ3DYBlrDmk6QBOHAzMzMzq6FKZk7wfW1mZmZmHUAlMyf8hqyHbQ0RcVxVamRmZmZmZVUyVHpLbrkXcDDwUnWqY2ZmZmbNqWSo9Pr8uqTfA3dVrUZmZmZmVlYlL+AttT3wwbauiJmZmZm1rJJ73N5gzXvc/g58u2o1MjMzM7OyKhkq7VuLipiZmZlZy1odKpV0sKR+ufX+kg6qbrXMzMzMrFQl97h9NyKWNa5ExGvAd6tXJTMzMzMrp5LArVyeSl4jYmZmZmZtqJLA7TFJP5X0IUnbSZoAzKh2xczMzMxsTZUEbicD/wKuBq4B3gL+s5qVMjMzM7O1VfJU6QpgfA3qYmZmZmYtqOSp0jsl9c+tbyzp9upWy8zMzMxKVTJUull6khSAiHgV2KJ6VTIzMzOzcioJ3FZLapriStI2rDmTgpmZmZnVQCWv9fhfYLqke9P6nsC46lXJzMzMzMqp5OGE2yTtAuwOCDgtIhZXvWZmZmZmtoZKX6T7DvAK0AsYLImIuK961TIzMzOzUq0GbpJOAL4ODARmkvW8PQh8qrpVMzMzM7O8Sh5O+DqwK/C3iBgN7Az8o6q1MjMzM7O1VBK4rYyIlQCS1o+IZ4EdqlstMzMzMytVSeC2IL2AdzJwp6SbgJcqKVzSGEnPSZorqezsC5LqJc2UNLvxyVVJW0u6R9KclP71XP4zJS1M+8yUtF8ldTEzMzMrukqeKj04LZ4p6R6gH3Bba/tJ6gZcDOwNLAAelTQlIp7J5ekP/AIYExEvSGp8se8q4PSIeFxSX2CGpDtz+06IiPMrbKOZmZlZp1DpU6UARMS9redqMhKYGxHPA0hqAMYCz+TyHAncEBEvpPJfST9fBl5Oy29ImgNsVbKvmZmZWZdSyVDpe7UV8GJufUFKy/swsLGkaZJmSPpSaSGStiV7IOLhXPJJkp6SdLmkjdu22mZmZmYdkyKqM3uVpMOAz0TECWn9KGBkRJycy3MRUAfsBfQme83IZyPiz2l7H+Be4IcRcUNKGwAsJpt26yxgy4g4rszxx5FmeBgwYMCIhoaGqrSz0dMLl1W1/HIG9IZFb9X2mEO36tfstlqfg67efuhY58Dtd/trrSO1H/w7cNmsWTWsSTJgACxaVPPD9hsypKrljx49ekZE1JXbtk5DpetoAbB1bn0gaz/UsABYHBErgBWS7gOGAX+W1AO4HriqMWgDiIimb0jSpcAt5Q4eEROBiQB1dXVRX1//vhvUkmPG31rV8ss5fegqfvJ0Nb/Ctc3/Qn2z22p9Drp6+6FjnQO33+2vtY7UfvDvwJuPP752FUlWn3Ya602YUPPj1s+bV/NjNqrmUOmjwPaSBknqCRwOTCnJcxMwSlJ3SRsAuwFzJAn4NTAnIn6a30HSlrnVg4F2CPHNzMzMaq9qoXpErJJ0EnA70A24PCJmSzoxbb8kIuZIug14ClgNXBYRsyTtARwFPC1pZiryfyJiKnCupOFkQ6Xzga9Uqw1mZmZmHUlV+1hToDW1JO2SkvXzgPNK0qaTTWhfrsyj2riaZmZmZoVQzaFSMzMzM2tDDtzMzMzMCsKBm5mZmVlBOHAzMzMzKwgHbmZmZmYF4cDNzMzMrCAcuJmZmZkVhAM3MzMzs4Jw4GZmZmZWEA7czMzMzArCgZuZmZlZQThwMzMzMysIB25mZmZmBeHAzczMzKwgHLiZmZmZFYQDNzMzM7OCcOBmZmZmVhAO3MzMzMwKwoGbmZmZWUE4cDMzMzMrCAduZmZmZgXhwM3MzMysIBy4mZmZmRWEAzczMzOzgnDgZmZmZlYQDtzMzMzMCsKBm5mZmVlBOHAzMzMzKwgHbmZmZmYF4cDNzMzMrCAcuJmZmZkVhAM3MzMzs4KoauAmaYyk5yTNlTS+mTz1kmZKmi3p3tb2lbSJpDsl/SX93LiabTAzMzPrKKoWuEnqBlwM7AsMBo6QNLgkT3/gF8CBEbETcFgF+44H7o6I7YG707qZmZlZp1fNHreRwNyIeD4i/gU0AGNL8hwJ3BARLwBExCsV7DsWuCItXwEcVMU2mJmZmXUYiojqFCwdCoyJiBPS+lHAbhFxUi7PBUAPYCegL3BhRPy2pX0lvRYR/XNlvBoRaw2XShoHjAMYMGDAiIaGhqq0s9HTC5dVtfxyBvSGRW/V9phDt+rX7LZan4Ou3n7oWOfA7Xf7a60jtR/8O3DZrFk1rEkyYAAsWlTzw/YbMqSq5Y8ePXpGRNSV29a9isdVmbTSKLE7MALYC+gNPCjpoQr3bVFETAQmAtTV1UV9ff267L7Ojhl/a1XLL+f0oav4ydPV/ArXNv8L9c1uq/U56Orth451Dtx+t7/WOlL7wb8Dbz7++NpVJFl92mmsN2FCzY9bP29ezY/ZqJrf+AJg69z6QOClMnkWR8QKYIWk+4Bhrey7SNKWEfGypC2BVzAzMzPrAqp5j9ujwPaSBknqCRwOTCnJcxMwSlJ3SRsAuwFzWtl3CnB0Wj46lWFmZmbW6VWtxy0iVkk6Cbgd6AZcHhGzJZ2Ytl8SEXMk3QY8BawGLouIWQDl9k1FnwNcI+l44AXSk6hmZmZmnV1VB8cjYiowtSTtkpL184DzKtk3pS8huyfOzMzMrEvxzAlmZmZmBeHAzczMzKwgHLiZmZmZFYQDNzMzM7OCcOBmZmZmVhAO3MzMzMwKwoGbmZmZWUE4cDMzMzMrCAduZmZmZgXhwM3MzMysIBy4mZmZmRWEAzczMzOzgnDgZmZmZlYQDtzMzMzMCsKBm5mZmVlBOHAzMzMzKwgHbmZmZmYF4cDNzMzMrCAcuJmZmZkVhAM3MzMzs4Jw4GZmZmZWEA7czMzMzArCgZuZmZlZQThwMzMzMysIB25mZmZmBeHAzczMzKwgHLiZmZmZFYQDNzMzM7OCcOBmZmZmVhAO3MzMzMwKwoGbmZmZWUE4cDMzMzMriKoGbpLGSHpO0lxJ48tsr5e0TNLM9Dkjpe+QS5sp6XVJp6ZtZ0pamNu2XzXbYGZmZtZRdK9WwZK6ARcDewMLgEclTYmIZ0qy/iki9s8nRMRzwPBcOQuBG3NZJkTE+dWqu5mZmVlHVM0et5HA3Ih4PiL+BTQAY99DOXsB8yLib21aOzMzM7OCUURUp2DpUGBMRJyQ1o8CdouIk3J56oHryXrkXgK+ERGzS8q5HHg8Ii5K62cCxwCvA48Bp0fEq2WOPw4YBzBgwIARDQ0NbdzCNT29cFlVyy9nQG9Y9FZtjzl0q37Nbqv1Oejq7YeOdQ7cfre/1jpS+8G/A5fNmlXDmiQDBsCiRTU/bL8hQ6pa/ujRo2dERF25bdUM3A4DPlMSuI2MiJNzeTYCVkfE8nSv2oURsX1ue0+ygG6niFiU0gYAi4EAzgK2jIjjWqpLXV1dPPbYY23bwBLbjr+1quWXc/rQVfzk6aqNdpc1/5zPNrut1uegq7cfOtY5cPvd/lrrSO0H/w68+UMfqmFNMqtPO431Jkyo+XEPmDevquVLajZwq+ZQ6QJg69z6QLIgrElEvB4Ry9PyVKCHpM1yWfYl621blNtnUUS8ExGrgUvJhmTNzMzMOr1qBm6PAttLGpR6zg4HpuQzSPo3SUrLI1N9luSyHAH8vmSfLXOrBwPt0DdrZmZmVntV62ONiFWSTgJuB7oBl0fEbEknpu2XAIcCX5W0CngLODzS2K2kDcieSP1KSdHnShpONlQ6v8x2MzMzs06pqoPjafhzaknaJbnli4CLmtn3TWDTMulHtXE1zczMzArBMyeYmZmZFYQDNzMzM7OCcOBmZmZmVhAO3MzMzMwKwoGbmZmZWUE4cDMzMzMrCAduZmZmZgXhwM3MzMysIBy4mZmZmRWEAzczMzOzgnDgZmZmZlYQDtzMzMzMCsKBm5mZmVlBOHAzMzMzKwgHbmZmZmYF4cDNzMzMrCAcuJmZmZkVhAM3MzMzs4Jw4GZmZmZWEA7czMzMzArCgZuZmZlZQThwMzMzMysIB25mZmZmBeHAzczMzKwgHLiZmZmZFYQDNzMzM7OCcOBmZmZmVhAO3MzMzMwKwoGbmZmZWUE4cDMzMzMrCAduZmZmZgVR1cBN0hhJz0maK2l8me31kpZJmpk+Z+S2zZf0dEp/LJe+iaQ7Jf0l/dy4mm0wMzMz6yiqFrhJ6gZcDOwLDAaOkDS4TNY/RcTw9Pl+ybbRKb0ulzYeuDsitgfuTutmZmZmnV41e9xGAnMj4vmI+BfQAIxtg3LHAlek5SuAg9qgTDMzM7MOr5qB21bAi7n1BSmt1MckPSnpD5J2yqUHcIekGZLG5dIHRMTLAOnnFm1dcTMzM7OOSBFRnYKlw4DPRMQJaf0oYGREnJzLsxGwOiKWS9oPuDANgSLpAxHxkqQtgDuBkyPiPkmvRUT/XBmvRsRa97mlYK8x4NsBeK4qDW1fmwGL27sS7airtx98Dtx+t9/t79o66znYJiI2L7ehexUPugDYOrc+EHgpnyEiXs8tT5X0C0mbRcTiiHgppb8i6Uayodf7gEWStoyIlyVtCbxS7uARMRGY2LZN6lgkPVZy/1+X0tXbDz4Hbr/b7/Z33fZD1zwH1RwqfRTYXtIgST2Bw4Ep+QyS/k2S0vLIVJ8lkjaU1DelbwjsA8xKu00Bjk7LRwM3VbENZmZmZh1G1XrcImKVpJOA24FuwOURMVvSiWn7JcChwFclrQLeAg6PiJA0ALgxxXTdgd9FxG2p6HOAayQdD7wAHFatNpiZmZl1JNUcKiUipgJTS9IuyS1fBFxUZr/ngWHNlLkE2Ktta1pYnXoouAJdvf3gc+D2d21uv3W5c1C1hxPMzMzMrG15yiszMzOzgnDg1sFJ6iXpkfSuu9mSvpfb9jFJl0oamZs27ElJB7dnndtaC9Ofdfr2V/j9byvprdw5uKSlMouogmug052DCtq8qaR7JC2XdFHJviPSvnMl/azxIbCikHS5pFckzcqltTjdYXrnZ09J05RNtdh4LRTiXZ/vs80/lPSipOUl29eXdHW6Dh6WtG1tWtO89G91Vus531PZ9ZJuScsHqsxUm52BA7eO75/ApyJiGDAcGCNp97RtDHAb2RO3dRExPKX9SlJV719sB+WmP+sK7a/k+weYl5s67sT2qGgNtHQNQOc8By21eSXw/4BvlNnvl2Tvsdw+fcZUu6JtbBJr17nZ6Q5TQLIwzdID8IXctVD2lVEd0CTee5tvJntlVqnjgVcj4t+BCcCP27zWHVRETImIc9q7HtXgwK2Di0zj/6J6pE/jjYl7AXdFxJsRsSql9cpt7+w6ffsr+f7bpWIdR1c8B43X/YqImE4WwDVR9n7LjSLiwchuYv4tBZsaMCLuA5aWJLc03eG+vBvAF9L7aXNEPNQ4o1AL+18H7NVBel+7S7pC0lOSrpO0gaQzJD0qaZakiY31lHSKpGdS3oaUtmHqoXxU0hOS1ppOU9IxjT3RkialnucHJD0v6dBcvm+mcp7Kj2h0ZA7cCkBSN0kzyV42fGdEPCxpM+DtiFiW8uwmaTbwNHBiLpDpDNaa/qwrtb+S7x8YlH6B3StpVPvVtmpavQbofOegkjaXsxXZC9AbNTfdYNG0NN1hvucV4DdpmPT/dZBA5b1alzaX0zT1ZPqduAzYtAr1XFc7ABMj4qPA68DXgIsiYteIGAL0BvZPeccDO6e8jT3p/wv8MSJ2BUYD5yl752tLtgT2SOWeAyBpH7Ie6ZFkIxojJO3ZRm2sms4ynNSpRcQ7wHBJ/cnebzcE+ChwRy7Pw8BOknYErpD0h4hYWb7EwvlEfvozSc+SzcTRJdpfwff/MvDBiFgiaQQwWdJO+ZlJOoHWroHOeA5ave6bUS5Q6TS90KWUveB9YHqNFGTDpAuVvcT9euAosl7HTqNMm5vNWiatI1wLL0bE/Wn5SuAU4K+SvgVsAGwCzCYbAn4KuErSZGBy2mcf4EBJjbcJ9AI+2MoxJ0fEauAZZe+KbSxnH+CJtN6HLJC77/00rtrc41YgEfEaMI3sf1plhwYiYg6wAhhS08pVUX76M6Bx+rMu0/5GzX3/EfHP9H5DImIGMA/4cDtVsypauwY64zlYl+u+xAKyAK/RWtMNFtSiNAzcOBzceO/aKGB6Y6aIWJh+vgH8jvL3fhVFRW1uQdPUk+m+336sPRzbHkqDxwB+ARwaEUOBS8mCMYDPAhcDI4AZqR0CPpe7j/GD6Xd/S/6ZW1bu59m5cv49In79PtpVEw7cOjhJm6eeFiT1Bj4NPEfW4zIzpQ9qvBlf0jZk3dDz26XCbUzlpz+bTddpfyXf/+aSuqXl7cj+x9ja/8QLo8JroFOdg0ra3Jw0pPaGpN3TMOGX6BxTAzY33eEY4A+QBSdpOBlJPciGxaryBGONtNrmddj/ULLhxY7Q4/ZBSR9Ly0fwbhC6WFIfsroiaT1g64i4B/gW0J+sV+x24OTGYXBJO7/HetwOHJeOiaStVICnkD1U2vFtSTb0140s0L6GbFjoidw/wD2A8ZLeBlYDX4uIxe1S27a31vRnwD/oOu2v5PvfE/i+sqnj3iG7x68j/K+6rVRyDXS2c1BJm5E0H9gI6CnpIGCfiHgG+CrZU4q9yf7AV/JHvsOQ9HugHthM0gLguzQ/3WE9cEZaXh+4PQVt3cgeXLm0djV/795Hm5F0LnAksEHa97KIOBP4NfB/kuaS9bQdXpPGtG4OcLSkXwF/IXsKemOye5Tnk811Dtl3eKWkfmS9YxMi4jVJZwEXAE+l4G0+794TV7GIuCPdXvNg+re2HPgi7/ZsdkieOaGAJH0HmBsRDe1dl/bg9nft9kPXPAddsc2tkTQQuDQi9m3vutRKV2yzrcmBm5mZmVlB+B43MzMzs4Jw4GZmZmZWEA7czMzMzArCgZuZmZlZQThwMzMzMysIB25mXZiksyXVSzpI0vgaH3t5+vkBSdc1k2eapLpWyjlV0gbvsQ6XSRpcJr1pgup1KOs2SWXnBJW0g7KJriXpgfdS12bK/b6kT7eS58zc1ED59G0ltfnLaZurU7rObmnr45l1NQ7czLq23YCHgU8Cf2qPCkTESxFx6Pso4lSy+Q3fy7FPSC+sfV/SrBabNE63VMYosvP7UbIZENpERJwREXe1VXnronGmilLtWSezrsCBm1kXJOk8SU8BuwIPAicAv5R0Rpm8AyTdKOnJ9Pl4Sp8saYak2ZLG5fIvl/TDlPchpQmd09RkD0p6NL35vDF/U8+PpN6SGiQ9Jelqsjf/N+b7paTH0vG+l9JOAT4A3CPpnpS2TzrO45KubZzOppnz0NSjJ+lYSX+WdC/wiVyewyTNSu1pbvLperJ5ZEvLHyVpJnAu8A3gVuAzkh4rk7c+1ec6Sc9Kuiq9FR5JIyTdm8737Xp3/spJkhqnB9ov7Tdd0s9KercGp7KfT+esUXdJV6TzfV1jz6WkvSQ9IelpSZdLWj+lz5d0hqTpvPsW/9J25Os0prFOwCG5PJ+UNDN9nlCa3svMKhAR/vjjTxf8kE2+/XOgB3B/C/muBk5Ny92Afml5k/SzN9l8kJum9QAOSMvnAt9Jy1OAL6Xl/wSWp+VtgVlp+b+Ay9PyR4FVQF3J8bqRBUkfTevzgc3S8mbAfcCGaf3bwBkttG0aUEc2tdgLwOZAT+B+4KKU52lgq7Tcv5lyfgZ8qoXjPEQ2Zc8kYKdm8tQDy8gmhV+P/9/e3YVIVYdxHP8+oBSxmBTeZe1q6YJebBdhZomF0Bt0FZlEWBdGL6Bd2U1E0EVJUHQhWkFZCQt1EVSLhr1YMKVm5ktLppCFQZSJSC+rVv66+D+Tx9nd2VmplnF+Hxg4c86Z/3nO/+zuPDznf/ZfEupr8/p8AkzL/ZZU+mg9ZV7H84FDQE+u7wfeyeXH8/PnZf8cyTa781otyP1eoiSX9bZm5fpXK9f/W2DVGD9XjTFdkef+eiWmtyvH7QImTfTvg19+tcvLFTezznUlZcLyXqDZ7cIbKHMJIukvScdy/YqI2E1JSqZTvqABTgL1as/nlAQBShWrP5dfG+VYC4ENeaw9wJ7KtjsiYifwBTAHGDY2Dbg619ey0rUMuKzJudXNA7ZIOizpJCVZrasB6yNiOSVpHMkCTk+UfYasYh2XJEoffd0kju2Svpd0inJtuoHZwFxgc57To5TkrqoX+EbSwXzf37B9QNIJlTl8f6LMhQpwSFItlzdQEsXZwEFJ+3P9K5TrUlftm2Z6s50Dee4bKttqwDNZ/Zsq6c8W2zTreJ5k3qzDREQfpSpyCfAzZXxYZFIwX9JQC20sAhbn/r9HxBZKhQXgj/yihjLhe/XvTCtz7A3bJyJ6KNWgqyQdjYj1leOdsSuwWdLSFo4z5nEBJN0fEfOAW4FdEdEn6UglthmUBOjkCHG/RUlgpuat6W5gR0Q8KWmkBOhEZbnedwEMSprfJPZofmojtgvDz1kttPXbGNsb2xu+UnoqIgaAW4CtEbFY0r5xtGvWsVxxM+swknZJ6gP2U6pTHwA3SuobJWl7H3gAyoD0iJgCXAgczaStl1LpGksNuDOX7xpln4/r2yJiLuV2KcAUSsJwLMfMVSfY/gWoj5HaCiyIiMuzjQsiYlYLsW0DFkXExRExmcr4rYiYKWmbpMcoie70hs/eDGwaqVFJtwEvUvpvBbAu+7nVqhWUCt20iJif8UyOiDkN++wDZkREd75f0mLbl9bbBZZSqob7gO56HwJ3Ax+NI95qTD0RMbPSPvBPn+6VtBrYQUluzawFTtzMOlBETKMkXqeAXjV/snIlcH1E7KXc+pxDSVQmZRXpCUrCNJaVwEMR8Rkl8RvJWqAr210FbAeQtJtyi3SQBdj5QgAAAR9JREFUMharVvnMC8DGiPhQ0mHgHqA/29hKC0mBpB8oY8E+Bd4DdlY2P52D9L+kJJa7Gz5+E6MkbmkhJSG6jrNIgLKSdzuwOm9N7wKuadhnCHgQ2JQPAvxIGS83lq+AZdlXFwFrJR0H7gXeyGt+Clh3FnEfB+4DBjKm7yqbH64/8AEMARvH275Zp4rTdzTMzGw88mnLmqSm/2vuf4qlS9Kv+STqGuCApGcnOi4z+3e54mZmdpZywP+EJ21peY5THKRUNJ+f4HjM7D/gipuZnfMi4k2gp2H1I5LenYh4zgURsYbK/7tLz0l6eSLiMesUTtzMzMzM2oRvlZqZmZm1CSduZmZmZm3CiZuZmZlZm3DiZmZmZtYmnLiZmZmZtYm/AZk0WEZsaGqDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min 4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># candidate_ids / # neighbor_ids</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3/3</th>\n",
       "      <td>0.663333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/3</th>\n",
       "      <td>0.656120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/5</th>\n",
       "      <td>0.662800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/5</th>\n",
       "      <td>0.656240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/10</th>\n",
       "      <td>0.655720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10/5</th>\n",
       "      <td>0.653120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10/10</th>\n",
       "      <td>0.652800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.702200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Min 4\n",
       "# candidate_ids / # neighbor_ids          \n",
       "3/3                               0.663333\n",
       "5/3                               0.656120\n",
       "3/5                               0.662800\n",
       "5/5                               0.656240\n",
       "5/10                              0.655720\n",
       "10/5                              0.653120\n",
       "10/10                             0.652800\n",
       "baseline                          0.702200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "min_4 = [np.average(i) for i in [min_results_3_4_3, min_results_5_4_3, min_results_3_4_5, \\\n",
    "                                 min_results_5_4_5, min_results_5_4_10, min_results_10_4_5, min_results_10_4_10]]\n",
    "min_4 += [neighbor_4[3]]\n",
    "\n",
    "ind = np.arange(0, len(min_4), 1)\n",
    "width = 0.9\n",
    "labels = ['3/3', '5/3', '3/5', '5/5', '5/10', '10/5', '10/10', 'baseline']\n",
    "\n",
    "barlist=plt.bar(ind, min_4, width, label='4 Neighbors, Min Distance')\n",
    "barlist[-1].set_color('firebrick')\n",
    "\n",
    "plt.ylim(0.55, 0.75)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Results: Varying # of candidate and neighbor ids\")\n",
    "plt.ylabel('accuracy score')\n",
    "plt.xlabel('# candidate_ids / # neighbor_ids')\n",
    "plt.xticks(ind, labels)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "min_4_df = pd.DataFrame(min_4, columns=['Min 4'], index=labels)\n",
    "min_4_df.index.rename('# candidate_ids / # neighbor_ids', inplace=True)\n",
    "min_4_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbNnqMKmduLL"
   },
   "source": [
    "### Initial Results - Discussion\n",
    "#### Varying # of candidate and neighbor ids\n",
    "It appears varying the number of candidate ids does not impact the accuracy significantly. Constraining the model to the 3 most popular entities increases the score marginally ~0.8%. However the limited number of ids limits the ability of our model to maximize the relationship between embeddings. Thus, we will continue to use 5 or more candidate ids and neighbor ids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis\n",
    "We will now examine cases where our model and the baseline model predict different candidates. By isolating cases where our model outperforms and underperforms the baseline we can gain insight into what distances imply strong relationships between entities.\n",
    "\n",
    "We will use 2 sets of parameters and average the results for each other 5 runs:\n",
    "    1. 5 candidate_ids, 4 neighbors and 10 neighbor_ids\n",
    "    2. 10 candidate_ids, 6 neighbors and 10 neighbor_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\tsamples: 5000\tTime:7.276838064193726\n",
      "Run: 1\tsamples: 5000\tTime:7.480013132095337\n",
      "Run: 2\tsamples: 5000\tTime:7.067780494689941\n",
      "Run: 3\tsamples: 5000\tTime:7.244342565536499\n",
      "Run: 4\tsamples: 5000\tTime:7.111274003982544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">model_dist</th>\n",
       "      <th>count</th>\n",
       "      <td>286.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.000902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.001792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.002284</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.001352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.021253</td>\n",
       "      <td>0.012220</td>\n",
       "      <td>0.017161</td>\n",
       "      <td>0.016411</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>0.019290</td>\n",
       "      <td>0.015865</td>\n",
       "      <td>0.014128</td>\n",
       "      <td>0.014878</td>\n",
       "      <td>0.015962</td>\n",
       "      <td>0.016258</td>\n",
       "      <td>0.009698</td>\n",
       "      <td>0.019618</td>\n",
       "      <td>0.020980</td>\n",
       "      <td>0.014478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">cand_0_dist</th>\n",
       "      <th>count</th>\n",
       "      <td>286.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.015099</td>\n",
       "      <td>0.054266</td>\n",
       "      <td>0.015008</td>\n",
       "      <td>0.016435</td>\n",
       "      <td>0.063556</td>\n",
       "      <td>0.031071</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>0.090391</td>\n",
       "      <td>0.025080</td>\n",
       "      <td>0.030798</td>\n",
       "      <td>0.052867</td>\n",
       "      <td>0.028405</td>\n",
       "      <td>0.021909</td>\n",
       "      <td>0.057429</td>\n",
       "      <td>0.023254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.101725</td>\n",
       "      <td>0.217950</td>\n",
       "      <td>0.108831</td>\n",
       "      <td>0.109060</td>\n",
       "      <td>0.235972</td>\n",
       "      <td>0.167013</td>\n",
       "      <td>0.093121</td>\n",
       "      <td>0.281855</td>\n",
       "      <td>0.147004</td>\n",
       "      <td>0.159683</td>\n",
       "      <td>0.215257</td>\n",
       "      <td>0.158681</td>\n",
       "      <td>0.130998</td>\n",
       "      <td>0.224271</td>\n",
       "      <td>0.141749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.001828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.005053</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.006624</td>\n",
       "      <td>0.006663</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>0.007153</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>0.006175</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.004150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">diff</th>\n",
       "      <th>count</th>\n",
       "      <td>286.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.013131</td>\n",
       "      <td>0.052537</td>\n",
       "      <td>0.014093</td>\n",
       "      <td>0.014650</td>\n",
       "      <td>0.061869</td>\n",
       "      <td>0.029991</td>\n",
       "      <td>0.011253</td>\n",
       "      <td>0.088797</td>\n",
       "      <td>0.023963</td>\n",
       "      <td>0.028974</td>\n",
       "      <td>0.051032</td>\n",
       "      <td>0.027567</td>\n",
       "      <td>0.019962</td>\n",
       "      <td>0.055408</td>\n",
       "      <td>0.022352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.101635</td>\n",
       "      <td>0.217559</td>\n",
       "      <td>0.108875</td>\n",
       "      <td>0.108915</td>\n",
       "      <td>0.235816</td>\n",
       "      <td>0.166430</td>\n",
       "      <td>0.092881</td>\n",
       "      <td>0.281691</td>\n",
       "      <td>0.147024</td>\n",
       "      <td>0.159204</td>\n",
       "      <td>0.214920</td>\n",
       "      <td>0.158783</td>\n",
       "      <td>0.130806</td>\n",
       "      <td>0.224152</td>\n",
       "      <td>0.141645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.000939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.003139</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.004080</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0.002780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.998680</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>0.998574</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.997843</td>\n",
       "      <td>0.999685</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.998513</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.998712</td>\n",
       "      <td>0.999455</td>\n",
       "      <td>0.999460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">diff_pct</th>\n",
       "      <th>count</th>\n",
       "      <td>286.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.446118</td>\n",
       "      <td>0.528143</td>\n",
       "      <td>0.630113</td>\n",
       "      <td>0.439698</td>\n",
       "      <td>0.541468</td>\n",
       "      <td>0.635359</td>\n",
       "      <td>0.420161</td>\n",
       "      <td>0.553349</td>\n",
       "      <td>0.632578</td>\n",
       "      <td>0.462609</td>\n",
       "      <td>0.537289</td>\n",
       "      <td>0.579850</td>\n",
       "      <td>0.436503</td>\n",
       "      <td>0.555241</td>\n",
       "      <td>0.566049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.281614</td>\n",
       "      <td>0.319002</td>\n",
       "      <td>0.321719</td>\n",
       "      <td>0.285011</td>\n",
       "      <td>0.302479</td>\n",
       "      <td>0.315067</td>\n",
       "      <td>0.274058</td>\n",
       "      <td>0.319417</td>\n",
       "      <td>0.314016</td>\n",
       "      <td>0.286802</td>\n",
       "      <td>0.312064</td>\n",
       "      <td>0.310238</td>\n",
       "      <td>0.291657</td>\n",
       "      <td>0.306146</td>\n",
       "      <td>0.357293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.006501</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.002230</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.001007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.217843</td>\n",
       "      <td>0.249386</td>\n",
       "      <td>0.357824</td>\n",
       "      <td>0.182236</td>\n",
       "      <td>0.294156</td>\n",
       "      <td>0.349894</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.263921</td>\n",
       "      <td>0.382047</td>\n",
       "      <td>0.188902</td>\n",
       "      <td>0.253364</td>\n",
       "      <td>0.315845</td>\n",
       "      <td>0.160963</td>\n",
       "      <td>0.293808</td>\n",
       "      <td>0.168659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.413984</td>\n",
       "      <td>0.553830</td>\n",
       "      <td>0.688677</td>\n",
       "      <td>0.437055</td>\n",
       "      <td>0.571576</td>\n",
       "      <td>0.686139</td>\n",
       "      <td>0.398345</td>\n",
       "      <td>0.593071</td>\n",
       "      <td>0.685767</td>\n",
       "      <td>0.445897</td>\n",
       "      <td>0.534443</td>\n",
       "      <td>0.600779</td>\n",
       "      <td>0.425636</td>\n",
       "      <td>0.564476</td>\n",
       "      <td>0.633881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.679146</td>\n",
       "      <td>0.798212</td>\n",
       "      <td>0.933794</td>\n",
       "      <td>0.678937</td>\n",
       "      <td>0.778888</td>\n",
       "      <td>0.950216</td>\n",
       "      <td>0.641453</td>\n",
       "      <td>0.840249</td>\n",
       "      <td>0.927427</td>\n",
       "      <td>0.705248</td>\n",
       "      <td>0.812958</td>\n",
       "      <td>0.872127</td>\n",
       "      <td>0.660380</td>\n",
       "      <td>0.834030</td>\n",
       "      <td>0.920420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.998712</td>\n",
       "      <td>0.999455</td>\n",
       "      <td>0.999460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "result             Baseline Correct  Both Incorrect  Model Correct  \\\n",
       "model_dist  count        286.000000      239.000000      84.000000   \n",
       "            mean           0.001968        0.001729       0.000915   \n",
       "            std            0.002559        0.002177       0.002110   \n",
       "            min            0.000000        0.000000       0.000003   \n",
       "            25%            0.000318        0.000251       0.000046   \n",
       "            50%            0.001478        0.001223       0.000177   \n",
       "            75%            0.002284        0.002002       0.001068   \n",
       "            max            0.021253        0.012220       0.017161   \n",
       "cand_0_dist count        286.000000      239.000000      84.000000   \n",
       "            mean           0.015099        0.054266       0.015008   \n",
       "            std            0.101725        0.217950       0.108831   \n",
       "            min            0.000015        0.000017       0.000012   \n",
       "            25%            0.000819        0.001672       0.000256   \n",
       "            50%            0.002631        0.002720       0.001973   \n",
       "            75%            0.006239        0.005053       0.004123   \n",
       "            max            1.000000        1.000000       1.000000   \n",
       "diff        count        286.000000      239.000000      84.000000   \n",
       "            mean           0.013131        0.052537       0.014093   \n",
       "            std            0.101635        0.217559       0.108875   \n",
       "            min            0.000000        0.000000       0.000000   \n",
       "            25%            0.000129        0.000360       0.000080   \n",
       "            50%            0.000852        0.001481       0.001203   \n",
       "            75%            0.003704        0.003471       0.002890   \n",
       "            max            0.998680        0.999977       0.999663   \n",
       "diff_pct    count        286.000000      239.000000      84.000000   \n",
       "            mean           0.446118        0.528143       0.630113   \n",
       "            std            0.281614        0.319002       0.321719   \n",
       "            min            0.001707        0.001010       0.001796   \n",
       "            25%            0.217843        0.249386       0.357824   \n",
       "            50%            0.413984        0.553830       0.688677   \n",
       "            75%            0.679146        0.798212       0.933794   \n",
       "            max            1.000000        1.000000       0.999663   \n",
       "\n",
       "result             Baseline Correct  Both Incorrect  Model Correct  \\\n",
       "model_dist  count        331.000000      202.000000     105.000000   \n",
       "            mean           0.001786        0.001687       0.001080   \n",
       "            std            0.001988        0.001807       0.002850   \n",
       "            min            0.000000        0.000000       0.000006   \n",
       "            25%            0.000237        0.000279       0.000043   \n",
       "            50%            0.001462        0.001479       0.000113   \n",
       "            75%            0.002185        0.002229       0.001010   \n",
       "            max            0.016411        0.012006       0.019290   \n",
       "cand_0_dist count        331.000000      202.000000     105.000000   \n",
       "            mean           0.016435        0.063556       0.031071   \n",
       "            std            0.109060        0.235972       0.167013   \n",
       "            min            0.000019        0.000019       0.000008   \n",
       "            25%            0.000760        0.001410       0.000196   \n",
       "            50%            0.002611        0.002730       0.001684   \n",
       "            75%            0.006624        0.006663       0.003384   \n",
       "            max            1.000000        1.000000       1.000000   \n",
       "diff        count        331.000000      202.000000     105.000000   \n",
       "            mean           0.014650        0.061869       0.029991   \n",
       "            std            0.108915        0.235816       0.166430   \n",
       "            min            0.000000        0.000000       0.000002   \n",
       "            25%            0.000093        0.000270       0.000065   \n",
       "            50%            0.000867        0.001350       0.001174   \n",
       "            75%            0.003748        0.004821       0.002246   \n",
       "            max            0.998574        0.999625       0.999887   \n",
       "diff_pct    count        331.000000      202.000000     105.000000   \n",
       "            mean           0.439698        0.541468       0.635359   \n",
       "            std            0.285011        0.302479       0.315067   \n",
       "            min            0.000755        0.000036       0.005394   \n",
       "            25%            0.182236        0.294156       0.349894   \n",
       "            50%            0.437055        0.571576       0.686139   \n",
       "            75%            0.678937        0.778888       0.950216   \n",
       "            max            1.000000        1.000000       0.999887   \n",
       "\n",
       "result             Baseline Correct  Both Incorrect  Model Correct  \\\n",
       "model_dist  count        342.000000      195.000000      91.000000   \n",
       "            mean           0.001929        0.001594       0.001117   \n",
       "            std            0.002240        0.002015       0.002164   \n",
       "            min            0.000000        0.000000       0.000000   \n",
       "            25%            0.000292        0.000179       0.000033   \n",
       "            50%            0.001419        0.001189       0.000220   \n",
       "            75%            0.002360        0.002001       0.001460   \n",
       "            max            0.015865        0.014128       0.014878   \n",
       "cand_0_dist count        342.000000      195.000000      91.000000   \n",
       "            mean           0.013183        0.090391       0.025080   \n",
       "            std            0.093121        0.281855       0.147004   \n",
       "            min            0.000018        0.000022       0.000008   \n",
       "            25%            0.000500        0.001309       0.001090   \n",
       "            50%            0.002247        0.002447       0.002066   \n",
       "            75%            0.005869        0.005563       0.004187   \n",
       "            max            1.000000        1.000000       1.000000   \n",
       "diff        count        342.000000      195.000000      91.000000   \n",
       "            mean           0.011253        0.088797       0.023963   \n",
       "            std            0.092881        0.281691       0.147024   \n",
       "            min            0.000000        0.000000       0.000001   \n",
       "            25%            0.000080        0.000292       0.000194   \n",
       "            50%            0.000787        0.001074       0.001214   \n",
       "            75%            0.003139        0.003550       0.002720   \n",
       "            max            0.997843        0.999685       0.999887   \n",
       "diff_pct    count        342.000000      195.000000      91.000000   \n",
       "            mean           0.420161        0.553349       0.632578   \n",
       "            std            0.274058        0.319417       0.314016   \n",
       "            min            0.000187        0.006501       0.002958   \n",
       "            25%            0.169231        0.263921       0.382047   \n",
       "            50%            0.398345        0.593071       0.685767   \n",
       "            75%            0.641453        0.840249       0.927427   \n",
       "            max            1.000000        1.000000       1.000000   \n",
       "\n",
       "result             Baseline Correct  Both Incorrect  Model Correct  \\\n",
       "model_dist  count        304.000000      225.000000      78.000000   \n",
       "            mean           0.001824        0.001835       0.000838   \n",
       "            std            0.002260        0.002544       0.001517   \n",
       "            min            0.000013        0.000000       0.000013   \n",
       "            25%            0.000245        0.000221       0.000052   \n",
       "            50%            0.001448        0.001338       0.000167   \n",
       "            75%            0.002317        0.001935       0.001287   \n",
       "            max            0.015962        0.016258       0.009698   \n",
       "cand_0_dist count        304.000000      225.000000      78.000000   \n",
       "            mean           0.030798        0.052867       0.028405   \n",
       "            std            0.159683        0.215257       0.158681   \n",
       "            min            0.000016        0.000008       0.000019   \n",
       "            25%            0.000650        0.001584       0.000226   \n",
       "            50%            0.002516        0.002957       0.001623   \n",
       "            75%            0.007153        0.005728       0.004064   \n",
       "            max            1.000000        1.000000       1.000000   \n",
       "diff        count        304.000000      225.000000      78.000000   \n",
       "            mean           0.028974        0.051032       0.027567   \n",
       "            std            0.159204        0.214920       0.158783   \n",
       "            min            0.000000        0.000001       0.000000   \n",
       "            25%            0.000115        0.000266       0.000107   \n",
       "            50%            0.001028        0.001580       0.000782   \n",
       "            75%            0.004080        0.003264       0.002090   \n",
       "            max            0.998513        0.999141       0.999887   \n",
       "diff_pct    count        304.000000      225.000000      78.000000   \n",
       "            mean           0.462609        0.537289       0.579850   \n",
       "            std            0.286802        0.312064       0.310238   \n",
       "            min            0.000921        0.002714       0.002230   \n",
       "            25%            0.188902        0.253364       0.315845   \n",
       "            50%            0.445897        0.534443       0.600779   \n",
       "            75%            0.705248        0.812958       0.872127   \n",
       "            max            0.998513        1.000000       0.999887   \n",
       "\n",
       "result             Baseline Correct  Both Incorrect  Model Correct  \n",
       "model_dist  count        342.000000      225.000000      98.000000  \n",
       "            mean           0.001948        0.002020       0.000902  \n",
       "            std            0.002556        0.003031       0.001792  \n",
       "            min            0.000014        0.000005       0.000011  \n",
       "            25%            0.000243        0.000249       0.000053  \n",
       "            50%            0.001371        0.001336       0.000186  \n",
       "            75%            0.002282        0.002223       0.001352  \n",
       "            max            0.019618        0.020980       0.014478  \n",
       "cand_0_dist count        342.000000      225.000000      98.000000  \n",
       "            mean           0.021909        0.057429       0.023254  \n",
       "            std            0.130998        0.224271       0.141749  \n",
       "            min            0.000019        0.000008       0.000018  \n",
       "            25%            0.000818        0.001706       0.000220  \n",
       "            50%            0.002415        0.002957       0.001828  \n",
       "            75%            0.006175        0.005997       0.004150  \n",
       "            max            1.000000        1.000000       1.000000  \n",
       "diff        count        342.000000      225.000000      98.000000  \n",
       "            mean           0.019962        0.055408       0.022352  \n",
       "            std            0.130806        0.224152       0.141645  \n",
       "            min            0.000000        0.000000       0.000000  \n",
       "            25%            0.000069        0.000524       0.000062  \n",
       "            50%            0.001023        0.001556       0.000939  \n",
       "            75%            0.003361        0.003324       0.002780  \n",
       "            max            0.998712        0.999455       0.999460  \n",
       "diff_pct    count        342.000000      225.000000      98.000000  \n",
       "            mean           0.436503        0.555241       0.566049  \n",
       "            std            0.291657        0.306146       0.357293  \n",
       "            min            0.002200        0.002202       0.001007  \n",
       "            25%            0.160963        0.293808       0.168659  \n",
       "            50%            0.425636        0.564476       0.633881  \n",
       "            75%            0.660380        0.834030       0.920420  \n",
       "            max            0.998712        0.999455       0.999460  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.23 s, sys: 5.1 s, total: 13.3 s\n",
      "Wall time: 41.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tuning results\n",
    "analysis_4 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                       max_candidate_ids=5, max_neighbors=4, max_neighbor_ids=5, \\\n",
    "                       num_distances=1, cutoff=1, tune=0, skip_nonroot=True, verbose=True)\n",
    "\n",
    "display(pd.concat(analysis_4,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\tsamples: 5000\tTime:31.145851373672485\n",
      "Run: 1\tsamples: 5000\tTime:33.60737752914429\n",
      "Run: 2\tsamples: 5000\tTime:29.035520792007446\n",
      "Run: 3\tsamples: 5000\tTime:28.38433313369751\n",
      "Run: 4\tsamples: 5000\tTime:27.94204568862915\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">model_dist</th>\n",
       "      <th>count</th>\n",
       "      <td>296.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.000750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.001819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.000779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.021253</td>\n",
       "      <td>0.011655</td>\n",
       "      <td>0.017161</td>\n",
       "      <td>0.016411</td>\n",
       "      <td>0.014987</td>\n",
       "      <td>0.018302</td>\n",
       "      <td>0.011350</td>\n",
       "      <td>0.011373</td>\n",
       "      <td>0.014878</td>\n",
       "      <td>0.012590</td>\n",
       "      <td>0.016258</td>\n",
       "      <td>0.009698</td>\n",
       "      <td>0.019618</td>\n",
       "      <td>0.020980</td>\n",
       "      <td>0.014478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">cand_0_dist</th>\n",
       "      <th>count</th>\n",
       "      <td>296.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.014485</td>\n",
       "      <td>0.051979</td>\n",
       "      <td>0.014341</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>0.060108</td>\n",
       "      <td>0.029381</td>\n",
       "      <td>0.012446</td>\n",
       "      <td>0.083985</td>\n",
       "      <td>0.026210</td>\n",
       "      <td>0.029363</td>\n",
       "      <td>0.045978</td>\n",
       "      <td>0.042731</td>\n",
       "      <td>0.021866</td>\n",
       "      <td>0.053038</td>\n",
       "      <td>0.024991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.100035</td>\n",
       "      <td>0.213804</td>\n",
       "      <td>0.109561</td>\n",
       "      <td>0.107963</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.164070</td>\n",
       "      <td>0.091188</td>\n",
       "      <td>0.272538</td>\n",
       "      <td>0.153033</td>\n",
       "      <td>0.156257</td>\n",
       "      <td>0.201151</td>\n",
       "      <td>0.198152</td>\n",
       "      <td>0.131595</td>\n",
       "      <td>0.216326</td>\n",
       "      <td>0.149574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.000198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.001480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.004650</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>0.002826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">diff</th>\n",
       "      <th>count</th>\n",
       "      <td>296.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.012802</td>\n",
       "      <td>0.050566</td>\n",
       "      <td>0.013554</td>\n",
       "      <td>0.014331</td>\n",
       "      <td>0.058657</td>\n",
       "      <td>0.028666</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.082724</td>\n",
       "      <td>0.025229</td>\n",
       "      <td>0.027760</td>\n",
       "      <td>0.044436</td>\n",
       "      <td>0.041993</td>\n",
       "      <td>0.020224</td>\n",
       "      <td>0.051337</td>\n",
       "      <td>0.024241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.099926</td>\n",
       "      <td>0.213715</td>\n",
       "      <td>0.109598</td>\n",
       "      <td>0.107802</td>\n",
       "      <td>0.230113</td>\n",
       "      <td>0.163646</td>\n",
       "      <td>0.090992</td>\n",
       "      <td>0.272385</td>\n",
       "      <td>0.153033</td>\n",
       "      <td>0.155857</td>\n",
       "      <td>0.200863</td>\n",
       "      <td>0.198151</td>\n",
       "      <td>0.131454</td>\n",
       "      <td>0.216184</td>\n",
       "      <td>0.149512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.001011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.002226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.998680</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999752</td>\n",
       "      <td>0.998574</td>\n",
       "      <td>0.999719</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.997853</td>\n",
       "      <td>0.999685</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>0.999659</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.998712</td>\n",
       "      <td>0.999455</td>\n",
       "      <td>0.999460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">diff_pct</th>\n",
       "      <th>count</th>\n",
       "      <td>296.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.452733</td>\n",
       "      <td>0.531608</td>\n",
       "      <td>0.629388</td>\n",
       "      <td>0.448220</td>\n",
       "      <td>0.538935</td>\n",
       "      <td>0.640586</td>\n",
       "      <td>0.429420</td>\n",
       "      <td>0.573123</td>\n",
       "      <td>0.630923</td>\n",
       "      <td>0.456827</td>\n",
       "      <td>0.531224</td>\n",
       "      <td>0.566617</td>\n",
       "      <td>0.459291</td>\n",
       "      <td>0.547785</td>\n",
       "      <td>0.607349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294040</td>\n",
       "      <td>0.320696</td>\n",
       "      <td>0.323733</td>\n",
       "      <td>0.288508</td>\n",
       "      <td>0.302495</td>\n",
       "      <td>0.311736</td>\n",
       "      <td>0.282444</td>\n",
       "      <td>0.304685</td>\n",
       "      <td>0.325572</td>\n",
       "      <td>0.295222</td>\n",
       "      <td>0.314427</td>\n",
       "      <td>0.316912</td>\n",
       "      <td>0.296851</td>\n",
       "      <td>0.310320</td>\n",
       "      <td>0.342379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>0.023041</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.006501</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.002230</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.007763</td>\n",
       "      <td>0.001007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.198194</td>\n",
       "      <td>0.242477</td>\n",
       "      <td>0.355493</td>\n",
       "      <td>0.181786</td>\n",
       "      <td>0.291714</td>\n",
       "      <td>0.365426</td>\n",
       "      <td>0.168922</td>\n",
       "      <td>0.353118</td>\n",
       "      <td>0.347328</td>\n",
       "      <td>0.182575</td>\n",
       "      <td>0.242820</td>\n",
       "      <td>0.291573</td>\n",
       "      <td>0.184109</td>\n",
       "      <td>0.278113</td>\n",
       "      <td>0.272540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.419046</td>\n",
       "      <td>0.525617</td>\n",
       "      <td>0.694592</td>\n",
       "      <td>0.439440</td>\n",
       "      <td>0.520747</td>\n",
       "      <td>0.711569</td>\n",
       "      <td>0.411916</td>\n",
       "      <td>0.608467</td>\n",
       "      <td>0.692581</td>\n",
       "      <td>0.425646</td>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.592146</td>\n",
       "      <td>0.437055</td>\n",
       "      <td>0.549333</td>\n",
       "      <td>0.729835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.705880</td>\n",
       "      <td>0.833110</td>\n",
       "      <td>0.948143</td>\n",
       "      <td>0.700323</td>\n",
       "      <td>0.806467</td>\n",
       "      <td>0.954716</td>\n",
       "      <td>0.670243</td>\n",
       "      <td>0.853865</td>\n",
       "      <td>0.961206</td>\n",
       "      <td>0.715489</td>\n",
       "      <td>0.805967</td>\n",
       "      <td>0.882612</td>\n",
       "      <td>0.715473</td>\n",
       "      <td>0.833877</td>\n",
       "      <td>0.923936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.998712</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "result             Baseline Correct  Both Incorrect  Model Correct  \\\n",
       "model_dist  count        296.000000      249.000000      83.000000   \n",
       "            mean           0.001683        0.001413       0.000786   \n",
       "            std            0.002299        0.001706       0.002049   \n",
       "            min            0.000000        0.000000       0.000003   \n",
       "            25%            0.000272        0.000241       0.000027   \n",
       "            50%            0.001320        0.001148       0.000112   \n",
       "            75%            0.001947        0.001678       0.000945   \n",
       "            max            0.021253        0.011655       0.017161   \n",
       "cand_0_dist count        296.000000      249.000000      83.000000   \n",
       "            mean           0.014485        0.051979       0.014341   \n",
       "            std            0.100035        0.213804       0.109561   \n",
       "            min            0.000015        0.000017       0.000012   \n",
       "            25%            0.000590        0.001546       0.000193   \n",
       "            50%            0.002265        0.002261       0.001308   \n",
       "            75%            0.006035        0.004599       0.002419   \n",
       "            max            1.000000        1.000000       1.000000   \n",
       "diff        count        296.000000      249.000000      83.000000   \n",
       "            mean           0.012802        0.050566       0.013554   \n",
       "            std            0.099926        0.213715       0.109598   \n",
       "            min            0.000000        0.000000       0.000000   \n",
       "            25%            0.000093        0.000327       0.000069   \n",
       "            50%            0.000708        0.001106       0.000867   \n",
       "            75%            0.003518        0.003305       0.001683   \n",
       "            max            0.998680        0.999977       0.999752   \n",
       "diff_pct    count        296.000000      249.000000      83.000000   \n",
       "            mean           0.452733        0.531608       0.629388   \n",
       "            std            0.294040        0.320696       0.323733   \n",
       "            min            0.001707        0.001010       0.001796   \n",
       "            25%            0.198194        0.242477       0.355493   \n",
       "            50%            0.419046        0.525617       0.694592   \n",
       "            75%            0.705880        0.833110       0.948143   \n",
       "            max            1.000000        1.000000       0.999752   \n",
       "\n",
       "result             Baseline Correct  Both Incorrect  Model Correct  \\\n",
       "model_dist  count        338.000000      213.000000     109.000000   \n",
       "            mean           0.001598        0.001451       0.000715   \n",
       "            std            0.001881        0.001637       0.002022   \n",
       "            min            0.000000        0.000000       0.000000   \n",
       "            25%            0.000243        0.000243       0.000033   \n",
       "            50%            0.001324        0.001275       0.000097   \n",
       "            75%            0.001929        0.001840       0.000612   \n",
       "            max            0.016411        0.014987       0.018302   \n",
       "cand_0_dist count        338.000000      213.000000     109.000000   \n",
       "            mean           0.015929        0.060108       0.029381   \n",
       "            std            0.107963        0.230243       0.164070   \n",
       "            min            0.000019        0.000019       0.000008   \n",
       "            25%            0.000720        0.001359       0.000187   \n",
       "            50%            0.002216        0.002167       0.001356   \n",
       "            75%            0.006249        0.005998       0.002269   \n",
       "            max            1.000000        1.000000       1.000000   \n",
       "diff        count        338.000000      213.000000     109.000000   \n",
       "            mean           0.014331        0.058657       0.028666   \n",
       "            std            0.107802        0.230113       0.163646   \n",
       "            min            0.000000        0.000000       0.000002   \n",
       "            25%            0.000096        0.000286       0.000065   \n",
       "            50%            0.000723        0.000960       0.000798   \n",
       "            75%            0.003506        0.003958       0.001842   \n",
       "            max            0.998574        0.999719       0.999887   \n",
       "diff_pct    count        338.000000      213.000000     109.000000   \n",
       "            mean           0.448220        0.538935       0.640586   \n",
       "            std            0.288508        0.302495       0.311736   \n",
       "            min            0.000211        0.004606       0.023041   \n",
       "            25%            0.181786        0.291714       0.365426   \n",
       "            50%            0.439440        0.520747       0.711569   \n",
       "            75%            0.700323        0.806467       0.954716   \n",
       "            max            1.000000        1.000000       1.000000   \n",
       "\n",
       "result             Baseline Correct  Both Incorrect  Model Correct  \\\n",
       "model_dist  count        357.000000      210.000000      84.000000   \n",
       "            mean           0.001565        0.001261       0.000981   \n",
       "            std            0.001764        0.001381       0.002168   \n",
       "            min            0.000000        0.000000       0.000000   \n",
       "            25%            0.000275        0.000194       0.000023   \n",
       "            50%            0.001306        0.001114       0.000147   \n",
       "            75%            0.001845        0.001696       0.001302   \n",
       "            max            0.011350        0.011373       0.014878   \n",
       "cand_0_dist count        357.000000      210.000000      84.000000   \n",
       "            mean           0.012446        0.083985       0.026210   \n",
       "            std            0.091188        0.272538       0.153033   \n",
       "            min            0.000018        0.000022       0.000008   \n",
       "            25%            0.000458        0.001225       0.000724   \n",
       "            50%            0.001878        0.002109       0.001405   \n",
       "            75%            0.005415        0.005312       0.002902   \n",
       "            max            1.000000        1.000000       1.000000   \n",
       "diff        count        357.000000      210.000000      84.000000   \n",
       "            mean           0.010881        0.082724       0.025229   \n",
       "            std            0.090992        0.272385       0.153033   \n",
       "            min            0.000000        0.000000       0.000001   \n",
       "            25%            0.000077        0.000297       0.000190   \n",
       "            50%            0.000596        0.001061       0.000991   \n",
       "            75%            0.003186        0.003364       0.001778   \n",
       "            max            0.997853        0.999685       0.999887   \n",
       "diff_pct    count        357.000000      210.000000      84.000000   \n",
       "            mean           0.429420        0.573123       0.630923   \n",
       "            std            0.282444        0.304685       0.325572   \n",
       "            min            0.000187        0.006501       0.002958   \n",
       "            25%            0.168922        0.353118       0.347328   \n",
       "            50%            0.411916        0.608467       0.692581   \n",
       "            75%            0.670243        0.853865       0.961206   \n",
       "            max            1.000000        1.000000       1.000000   \n",
       "\n",
       "result             Baseline Correct  Both Incorrect  Model Correct  \\\n",
       "model_dist  count        318.000000      236.000000      74.000000   \n",
       "            mean           0.001603        0.001543       0.000737   \n",
       "            std            0.001831        0.002260       0.001528   \n",
       "            min            0.000000        0.000000       0.000010   \n",
       "            25%            0.000204        0.000199       0.000051   \n",
       "            50%            0.001340        0.001197       0.000115   \n",
       "            75%            0.002019        0.001657       0.000940   \n",
       "            max            0.012590        0.016258       0.009698   \n",
       "cand_0_dist count        318.000000      236.000000      74.000000   \n",
       "            mean           0.029363        0.045978       0.042731   \n",
       "            std            0.156257        0.201151       0.198152   \n",
       "            min            0.000010        0.000008       0.000019   \n",
       "            25%            0.000620        0.001377       0.000158   \n",
       "            50%            0.002126        0.002292       0.001253   \n",
       "            75%            0.006422        0.004650       0.002188   \n",
       "            max            1.000000        1.000000       1.000000   \n",
       "diff        count        318.000000      236.000000      74.000000   \n",
       "            mean           0.027760        0.044436       0.041993   \n",
       "            std            0.155857        0.200863       0.198151   \n",
       "            min            0.000000        0.000001       0.000000   \n",
       "            25%            0.000097        0.000252       0.000067   \n",
       "            50%            0.000755        0.001173       0.000531   \n",
       "            75%            0.003956        0.002958       0.001367   \n",
       "            max            0.998790        0.999659       0.999887   \n",
       "diff_pct    count        318.000000      236.000000      74.000000   \n",
       "            mean           0.456827        0.531224       0.566617   \n",
       "            std            0.295222        0.314427       0.316912   \n",
       "            min            0.000921        0.002285       0.002230   \n",
       "            25%            0.182575        0.242820       0.291573   \n",
       "            50%            0.425646        0.538845       0.592146   \n",
       "            75%            0.715489        0.805967       0.882612   \n",
       "            max            1.000000        1.000000       0.999887   \n",
       "\n",
       "result             Baseline Correct  Both Incorrect  Model Correct  \n",
       "model_dist  count        339.000000      243.000000      88.000000  \n",
       "            mean           0.001642        0.001701       0.000750  \n",
       "            std            0.002306        0.002793       0.001819  \n",
       "            min            0.000014        0.000000       0.000011  \n",
       "            25%            0.000212        0.000239       0.000044  \n",
       "            50%            0.001240        0.001129       0.000128  \n",
       "            75%            0.001800        0.001744       0.000779  \n",
       "            max            0.019618        0.020980       0.014478  \n",
       "cand_0_dist count        339.000000      243.000000      88.000000  \n",
       "            mean           0.021866        0.053038       0.024991  \n",
       "            std            0.131595        0.216326       0.149574  \n",
       "            min            0.000019        0.000008       0.000018  \n",
       "            25%            0.000723        0.001502       0.000198  \n",
       "            50%            0.001975        0.002222       0.001480  \n",
       "            75%            0.006129        0.004962       0.002826  \n",
       "            max            1.000000        1.000000       1.000000  \n",
       "diff        count        339.000000      243.000000      88.000000  \n",
       "            mean           0.020224        0.051337       0.024241  \n",
       "            std            0.131454        0.216184       0.149512  \n",
       "            min            0.000000        0.000001       0.000000  \n",
       "            25%            0.000082        0.000403       0.000066  \n",
       "            50%            0.000801        0.001267       0.001011  \n",
       "            75%            0.003367        0.002909       0.002226  \n",
       "            max            0.998712        0.999455       0.999460  \n",
       "diff_pct    count        339.000000      243.000000      88.000000  \n",
       "            mean           0.459291        0.547785       0.607349  \n",
       "            std            0.296851        0.310320       0.342379  \n",
       "            min            0.004021        0.007763       0.001007  \n",
       "            25%            0.184109        0.278113       0.272540  \n",
       "            50%            0.437055        0.549333       0.729835  \n",
       "            75%            0.715473        0.833877       0.923936  \n",
       "            max            0.998712        1.000000       0.999460  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.38 s, sys: 5 s, total: 13.4 s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tuning results\n",
    "analysis_6 = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                       max_candidate_ids=10, max_neighbors=6, max_neighbor_ids=10, \\\n",
    "                       num_distances=1, cutoff=1, tune=0, skip_nonroot=True, verbose=True)\n",
    "display(pd.concat(analysis_6,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">model_dist</th>\n",
       "      <th>count</th>\n",
       "      <td>321.000000</td>\n",
       "      <td>217.200000</td>\n",
       "      <td>91.200000</td>\n",
       "      <td>329.600000</td>\n",
       "      <td>230.200000</td>\n",
       "      <td>87.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.000794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.001917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.000916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.017822</td>\n",
       "      <td>0.015118</td>\n",
       "      <td>0.015101</td>\n",
       "      <td>0.016244</td>\n",
       "      <td>0.015051</td>\n",
       "      <td>0.014903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">cand_0_dist</th>\n",
       "      <th>count</th>\n",
       "      <td>321.000000</td>\n",
       "      <td>217.200000</td>\n",
       "      <td>91.200000</td>\n",
       "      <td>329.600000</td>\n",
       "      <td>230.200000</td>\n",
       "      <td>87.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.019485</td>\n",
       "      <td>0.063702</td>\n",
       "      <td>0.024564</td>\n",
       "      <td>0.018818</td>\n",
       "      <td>0.059018</td>\n",
       "      <td>0.027531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.118917</td>\n",
       "      <td>0.235061</td>\n",
       "      <td>0.144656</td>\n",
       "      <td>0.117408</td>\n",
       "      <td>0.226812</td>\n",
       "      <td>0.154878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.000292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.001360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.006412</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.002521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">diff</th>\n",
       "      <th>count</th>\n",
       "      <td>321.000000</td>\n",
       "      <td>217.200000</td>\n",
       "      <td>91.200000</td>\n",
       "      <td>329.600000</td>\n",
       "      <td>230.200000</td>\n",
       "      <td>87.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.017594</td>\n",
       "      <td>0.061929</td>\n",
       "      <td>0.023593</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.057544</td>\n",
       "      <td>0.026737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.118688</td>\n",
       "      <td>0.234828</td>\n",
       "      <td>0.144551</td>\n",
       "      <td>0.117206</td>\n",
       "      <td>0.226652</td>\n",
       "      <td>0.154788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.000840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.001779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.998464</td>\n",
       "      <td>0.999577</td>\n",
       "      <td>0.999757</td>\n",
       "      <td>0.998522</td>\n",
       "      <td>0.999699</td>\n",
       "      <td>0.999775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">diff_pct</th>\n",
       "      <th>count</th>\n",
       "      <td>321.000000</td>\n",
       "      <td>217.200000</td>\n",
       "      <td>91.200000</td>\n",
       "      <td>329.600000</td>\n",
       "      <td>230.200000</td>\n",
       "      <td>87.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.441018</td>\n",
       "      <td>0.543098</td>\n",
       "      <td>0.608790</td>\n",
       "      <td>0.449298</td>\n",
       "      <td>0.544535</td>\n",
       "      <td>0.614973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.283828</td>\n",
       "      <td>0.311822</td>\n",
       "      <td>0.323667</td>\n",
       "      <td>0.291413</td>\n",
       "      <td>0.310525</td>\n",
       "      <td>0.324066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>0.006206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.183835</td>\n",
       "      <td>0.270927</td>\n",
       "      <td>0.314854</td>\n",
       "      <td>0.183117</td>\n",
       "      <td>0.281648</td>\n",
       "      <td>0.326472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.424183</td>\n",
       "      <td>0.563479</td>\n",
       "      <td>0.659049</td>\n",
       "      <td>0.426621</td>\n",
       "      <td>0.548602</td>\n",
       "      <td>0.684145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.673033</td>\n",
       "      <td>0.812867</td>\n",
       "      <td>0.920797</td>\n",
       "      <td>0.701482</td>\n",
       "      <td>0.826657</td>\n",
       "      <td>0.934123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999445</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.999742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "result             Baseline Correct  Both Incorrect  Model Correct  \\\n",
       "model_dist  count        321.000000      217.200000      91.200000   \n",
       "            mean           0.001891        0.001773       0.000970   \n",
       "            std            0.002321        0.002315       0.002087   \n",
       "            min            0.000005        0.000001       0.000007   \n",
       "            25%            0.000267        0.000236       0.000045   \n",
       "            50%            0.001436        0.001313       0.000173   \n",
       "            75%            0.002286        0.002078       0.001235   \n",
       "            max            0.017822        0.015118       0.015101   \n",
       "cand_0_dist count        321.000000      217.200000      91.200000   \n",
       "            mean           0.019485        0.063702       0.024564   \n",
       "            std            0.118917        0.235061       0.144656   \n",
       "            min            0.000017        0.000015       0.000013   \n",
       "            25%            0.000709        0.001536       0.000398   \n",
       "            50%            0.002484        0.002762       0.001835   \n",
       "            75%            0.006412        0.005801       0.003982   \n",
       "            max            1.000000        1.000000       1.000000   \n",
       "diff        count        321.000000      217.200000      91.200000   \n",
       "            mean           0.017594        0.061929       0.023593   \n",
       "            std            0.118688        0.234828       0.144551   \n",
       "            min            0.000000        0.000000       0.000001   \n",
       "            25%            0.000097        0.000342       0.000102   \n",
       "            50%            0.000911        0.001408       0.001062   \n",
       "            75%            0.003606        0.003686       0.002545   \n",
       "            max            0.998464        0.999577       0.999757   \n",
       "diff_pct    count        321.000000      217.200000      91.200000   \n",
       "            mean           0.441018        0.543098       0.608790   \n",
       "            std            0.283828        0.311822       0.323667   \n",
       "            min            0.001154        0.002493       0.002677   \n",
       "            25%            0.183835        0.270927       0.314854   \n",
       "            50%            0.424183        0.563479       0.659049   \n",
       "            75%            0.673033        0.812867       0.920797   \n",
       "            max            0.999445        0.999891       0.999779   \n",
       "\n",
       "result             Baseline Correct  Both Incorrect  Model Correct  \n",
       "model_dist  count        329.600000      230.200000      87.600000  \n",
       "            mean           0.001618        0.001474       0.000794  \n",
       "            std            0.002016        0.001955       0.001917  \n",
       "            min            0.000003        0.000000       0.000005  \n",
       "            25%            0.000241        0.000223       0.000036  \n",
       "            50%            0.001306        0.001173       0.000120  \n",
       "            75%            0.001908        0.001723       0.000916  \n",
       "            max            0.016244        0.015051       0.014903  \n",
       "cand_0_dist count        329.600000      230.200000      87.600000  \n",
       "            mean           0.018818        0.059018       0.027531  \n",
       "            std            0.117408        0.226812       0.154878  \n",
       "            min            0.000016        0.000015       0.000013  \n",
       "            25%            0.000622        0.001402       0.000292  \n",
       "            50%            0.002092        0.002210       0.001360  \n",
       "            75%            0.006050        0.005104       0.002521  \n",
       "            max            1.000000        1.000000       1.000000  \n",
       "diff        count        329.600000      230.200000      87.600000  \n",
       "            mean           0.017200        0.057544       0.026737  \n",
       "            std            0.117206        0.226652       0.154788  \n",
       "            min            0.000000        0.000000       0.000001  \n",
       "            25%            0.000089        0.000313       0.000091  \n",
       "            50%            0.000717        0.001113       0.000840  \n",
       "            75%            0.003507        0.003299       0.001779  \n",
       "            max            0.998522        0.999699       0.999775  \n",
       "diff_pct    count        329.600000      230.200000      87.600000  \n",
       "            mean           0.449298        0.544535       0.614973  \n",
       "            std            0.291413        0.310525       0.324066  \n",
       "            min            0.001409        0.004433       0.006206  \n",
       "            25%            0.183117        0.281648       0.326472  \n",
       "            50%            0.426621        0.548602       0.684145  \n",
       "            75%            0.701482        0.826657       0.934123  \n",
       "            max            0.999742        1.000000       0.999820  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average tuning results over 5 runs\n",
    "analysis_avg_df = pd.concat([sum(analysis_4)/len(analysis_4), sum(analysis_6)/len(analysis_6)], axis=1)\n",
    "analysis_avg_df.round(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis - Results\n",
    "Our model and the baseline model recommend different candidates in \\~12.5% (~640/5000) of the total cases.\n",
    "- The embedding model outperforms the baseline in ~14% of those cases.\n",
    "- The baseline model performs better in ~50% of those cases\n",
    "\n",
    "However we see some promise in the variance in distances between when the embedding model is correct compared to the baseline model. Additionally, there may be a relationship between how much lower the distance of the candidate the embedding models selects is compared to the most popular candidate.\n",
    "\n",
    "Key takeaways from our analysis:\n",
    "- Embedding Model is Correct:\n",
    "    1. The median distance is: ~0.00015\n",
    "    2. The median pct diff between the distance of the selected candidate and the most popular candidate: ~67%\n",
    "- Baseline Model is Correct:\n",
    "    1. The median distance is:  ~0.0014\n",
    "    2. The median pct diff between the distance of the selected candidate and the most popular candidate: ~42%\n",
    "\n",
    "# Model Tuning\n",
    "\n",
    "### Tuning Parameters:\n",
    "   - **cutoff:** any distance above the cutoff will be set to 1.\n",
    "   - **tune:** the distance of the candidate our model chooses must be the tune percentage lower than the distance of the candidate with the most view. If not, we will select the candidate with the most view.\n",
    "   \n",
    "We will tune our model using the finding from our analysis and see if we can improve the results. We will use values from the **25% to 75% range** from the **'Model Correct'** columns and the **'model_dist'** and **'diff_pct'** sections to set range we will test for the **cutoff and tune parameters** respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5000\n"
     ]
    }
   ],
   "source": [
    "# helper function to average results while tuning the model\n",
    "def get_tune_result(result):\n",
    "    avg_df = sum(result)/len(result)\n",
    "    count = avg_df.loc['model_dist'].loc['count']\n",
    "    return count\n",
    "\n",
    "# generate the set of samples we will use to tune\n",
    "# this saves us from recreating them for every run to save time\n",
    "formatted_sample_list = run_model(samples_per_iter=5000, iterations=5, seed=1636, \\\n",
    "                                  max_candidate_ids=5, max_neighbors=4, max_neighbor_ids=5, \\\n",
    "                                  samples_only=True)\n",
    "\n",
    "print(len(formatted_sample_list), len(formatted_sample_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Tuning!\n",
      "cutoff values: [0.0001 0.0002 0.0003 0.0004 0.0005 0.0006 0.0007 0.0008 0.0009 0.001\n",
      " 0.0012 0.0014]\n",
      "tune values: [0.4   0.45  0.5   0.55  0.6   0.625 0.65  0.675 0.7   0.725 0.75  0.775\n",
      " 0.8  ]\n",
      "Running with parameters: cutoff=0.0001 tune=0.4\n",
      "Run: 0\tsamples: None\tTime:1.5752084255218506\n",
      "Run: 1\tsamples: None\tTime:1.5681719779968262\n",
      "Run: 2\tsamples: None\tTime:1.4114646911621094\n",
      "Run: 3\tsamples: None\tTime:1.4450125694274902\n",
      "Run: 4\tsamples: None\tTime:1.444901466369629\n",
      "Running with parameters: cutoff=0.0001 tune=0.45\n",
      "Run: 0\tsamples: None\tTime:1.589728832244873\n",
      "Run: 1\tsamples: None\tTime:1.521298885345459\n",
      "Run: 2\tsamples: None\tTime:1.4110209941864014\n",
      "Run: 3\tsamples: None\tTime:1.425912857055664\n",
      "Run: 4\tsamples: None\tTime:1.439518928527832\n",
      "Running with parameters: cutoff=0.0001 tune=0.5\n",
      "Run: 0\tsamples: None\tTime:1.5984807014465332\n",
      "Run: 1\tsamples: None\tTime:1.5510976314544678\n",
      "Run: 2\tsamples: None\tTime:1.4274511337280273\n",
      "Run: 3\tsamples: None\tTime:1.4269928932189941\n",
      "Run: 4\tsamples: None\tTime:1.4163000583648682\n",
      "Running with parameters: cutoff=0.0001 tune=0.55\n",
      "Run: 0\tsamples: None\tTime:1.6045565605163574\n",
      "Run: 1\tsamples: None\tTime:1.5037837028503418\n",
      "Run: 2\tsamples: None\tTime:1.4334735870361328\n",
      "Run: 3\tsamples: None\tTime:1.4191184043884277\n",
      "Run: 4\tsamples: None\tTime:1.4317638874053955\n",
      "Running with parameters: cutoff=0.0001 tune=0.6\n",
      "Run: 0\tsamples: None\tTime:1.6114349365234375\n",
      "Run: 1\tsamples: None\tTime:1.5682182312011719\n",
      "Run: 2\tsamples: None\tTime:1.4304277896881104\n",
      "Run: 3\tsamples: None\tTime:1.45676851272583\n",
      "Run: 4\tsamples: None\tTime:1.448171615600586\n",
      "Running with parameters: cutoff=0.0001 tune=0.625\n",
      "Run: 0\tsamples: None\tTime:1.614189624786377\n",
      "Run: 1\tsamples: None\tTime:1.5170059204101562\n",
      "Run: 2\tsamples: None\tTime:1.4584300518035889\n",
      "Run: 3\tsamples: None\tTime:1.4664108753204346\n",
      "Run: 4\tsamples: None\tTime:1.4361579418182373\n",
      "Running with parameters: cutoff=0.0001 tune=0.65\n",
      "Run: 0\tsamples: None\tTime:1.610079050064087\n",
      "Run: 1\tsamples: None\tTime:1.556084394454956\n",
      "Run: 2\tsamples: None\tTime:1.4332749843597412\n",
      "Run: 3\tsamples: None\tTime:1.4310104846954346\n",
      "Run: 4\tsamples: None\tTime:1.4260590076446533\n",
      "Running with parameters: cutoff=0.0001 tune=0.675\n",
      "Run: 0\tsamples: None\tTime:1.612813949584961\n",
      "Run: 1\tsamples: None\tTime:1.56601881980896\n",
      "Run: 2\tsamples: None\tTime:1.4381871223449707\n",
      "Run: 3\tsamples: None\tTime:1.4761896133422852\n",
      "Run: 4\tsamples: None\tTime:1.420541763305664\n",
      "Running with parameters: cutoff=0.0001 tune=0.7000000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6109881401062012\n",
      "Run: 1\tsamples: None\tTime:1.5408003330230713\n",
      "Run: 2\tsamples: None\tTime:1.4423954486846924\n",
      "Run: 3\tsamples: None\tTime:1.4248178005218506\n",
      "Run: 4\tsamples: None\tTime:1.431736946105957\n",
      "Running with parameters: cutoff=0.0001 tune=0.7250000000000001\n",
      "Run: 0\tsamples: None\tTime:1.616424322128296\n",
      "Run: 1\tsamples: None\tTime:1.5077695846557617\n",
      "Run: 2\tsamples: None\tTime:1.457045078277588\n",
      "Run: 3\tsamples: None\tTime:1.4424827098846436\n",
      "Run: 4\tsamples: None\tTime:1.4052484035491943\n",
      "Running with parameters: cutoff=0.0001 tune=0.7500000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6454460620880127\n",
      "Run: 1\tsamples: None\tTime:1.6092212200164795\n",
      "Run: 2\tsamples: None\tTime:1.4529132843017578\n",
      "Run: 3\tsamples: None\tTime:1.4751880168914795\n",
      "Run: 4\tsamples: None\tTime:1.4206466674804688\n",
      "Running with parameters: cutoff=0.0001 tune=0.7750000000000001\n",
      "Run: 0\tsamples: None\tTime:1.591284990310669\n",
      "Run: 1\tsamples: None\tTime:1.5270051956176758\n",
      "Run: 2\tsamples: None\tTime:1.43646240234375\n",
      "Run: 3\tsamples: None\tTime:1.4643700122833252\n",
      "Run: 4\tsamples: None\tTime:1.4278573989868164\n",
      "Running with parameters: cutoff=0.0001 tune=0.8000000000000002\n",
      "Run: 0\tsamples: None\tTime:1.5862014293670654\n",
      "Run: 1\tsamples: None\tTime:1.4867932796478271\n",
      "Run: 2\tsamples: None\tTime:1.4237895011901855\n",
      "Run: 3\tsamples: None\tTime:1.462968111038208\n",
      "Run: 4\tsamples: None\tTime:1.4307234287261963\n",
      "Running with parameters: cutoff=0.0002 tune=0.4\n",
      "Run: 0\tsamples: None\tTime:1.5565989017486572\n",
      "Run: 1\tsamples: None\tTime:1.5303056240081787\n",
      "Run: 2\tsamples: None\tTime:1.4203696250915527\n",
      "Run: 3\tsamples: None\tTime:1.4498531818389893\n",
      "Run: 4\tsamples: None\tTime:1.4166390895843506\n",
      "Running with parameters: cutoff=0.0002 tune=0.45\n",
      "Run: 0\tsamples: None\tTime:1.585477590560913\n",
      "Run: 1\tsamples: None\tTime:1.4817535877227783\n",
      "Run: 2\tsamples: None\tTime:1.4371566772460938\n",
      "Run: 3\tsamples: None\tTime:1.4271934032440186\n",
      "Run: 4\tsamples: None\tTime:1.434105634689331\n",
      "Running with parameters: cutoff=0.0002 tune=0.5\n",
      "Run: 0\tsamples: None\tTime:1.622755527496338\n",
      "Run: 1\tsamples: None\tTime:1.4858274459838867\n",
      "Run: 2\tsamples: None\tTime:1.4212911128997803\n",
      "Run: 3\tsamples: None\tTime:1.4529550075531006\n",
      "Run: 4\tsamples: None\tTime:1.4259445667266846\n",
      "Running with parameters: cutoff=0.0002 tune=0.55\n",
      "Run: 0\tsamples: None\tTime:1.5635263919830322\n",
      "Run: 1\tsamples: None\tTime:1.5609948635101318\n",
      "Run: 2\tsamples: None\tTime:1.4594011306762695\n",
      "Run: 3\tsamples: None\tTime:1.4643139839172363\n",
      "Run: 4\tsamples: None\tTime:1.405698299407959\n",
      "Running with parameters: cutoff=0.0002 tune=0.6\n",
      "Run: 0\tsamples: None\tTime:1.6012468338012695\n",
      "Run: 1\tsamples: None\tTime:1.484511137008667\n",
      "Run: 2\tsamples: None\tTime:1.4515612125396729\n",
      "Run: 3\tsamples: None\tTime:1.4721031188964844\n",
      "Run: 4\tsamples: None\tTime:1.4445242881774902\n",
      "Running with parameters: cutoff=0.0002 tune=0.625\n",
      "Run: 0\tsamples: None\tTime:1.5837442874908447\n",
      "Run: 1\tsamples: None\tTime:1.4884753227233887\n",
      "Run: 2\tsamples: None\tTime:1.4505465030670166\n",
      "Run: 3\tsamples: None\tTime:1.4484872817993164\n",
      "Run: 4\tsamples: None\tTime:1.430938482284546\n",
      "Running with parameters: cutoff=0.0002 tune=0.65\n",
      "Run: 0\tsamples: None\tTime:1.561751127243042\n",
      "Run: 1\tsamples: None\tTime:1.5143792629241943\n",
      "Run: 2\tsamples: None\tTime:1.4231457710266113\n",
      "Run: 3\tsamples: None\tTime:1.4404404163360596\n",
      "Run: 4\tsamples: None\tTime:1.455406904220581\n",
      "Running with parameters: cutoff=0.0002 tune=0.675\n",
      "Run: 0\tsamples: None\tTime:1.5690438747406006\n",
      "Run: 1\tsamples: None\tTime:1.5552232265472412\n",
      "Run: 2\tsamples: None\tTime:1.3902702331542969\n",
      "Run: 3\tsamples: None\tTime:1.4323773384094238\n",
      "Run: 4\tsamples: None\tTime:1.4346275329589844\n",
      "Running with parameters: cutoff=0.0002 tune=0.7000000000000001\n",
      "Run: 0\tsamples: None\tTime:1.584850549697876\n",
      "Run: 1\tsamples: None\tTime:1.5841364860534668\n",
      "Run: 2\tsamples: None\tTime:1.4473838806152344\n",
      "Run: 3\tsamples: None\tTime:1.4236514568328857\n",
      "Run: 4\tsamples: None\tTime:1.4053926467895508\n",
      "Running with parameters: cutoff=0.0002 tune=0.7250000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6292986869812012\n",
      "Run: 1\tsamples: None\tTime:1.5923411846160889\n",
      "Run: 2\tsamples: None\tTime:1.4742722511291504\n",
      "Run: 3\tsamples: None\tTime:1.4832067489624023\n",
      "Run: 4\tsamples: None\tTime:1.4410648345947266\n",
      "Running with parameters: cutoff=0.0002 tune=0.7500000000000001\n",
      "Run: 0\tsamples: None\tTime:1.5773921012878418\n",
      "Run: 1\tsamples: None\tTime:1.5359675884246826\n",
      "Run: 2\tsamples: None\tTime:1.443354845046997\n",
      "Run: 3\tsamples: None\tTime:1.4606728553771973\n",
      "Run: 4\tsamples: None\tTime:1.4265928268432617\n",
      "Running with parameters: cutoff=0.0002 tune=0.7750000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6139366626739502\n",
      "Run: 1\tsamples: None\tTime:1.5325522422790527\n",
      "Run: 2\tsamples: None\tTime:1.4615099430084229\n",
      "Run: 3\tsamples: None\tTime:1.4549882411956787\n",
      "Run: 4\tsamples: None\tTime:1.4553637504577637\n",
      "Running with parameters: cutoff=0.0002 tune=0.8000000000000002\n",
      "Run: 0\tsamples: None\tTime:1.613987684249878\n",
      "Run: 1\tsamples: None\tTime:1.552849531173706\n",
      "Run: 2\tsamples: None\tTime:1.4264919757843018\n",
      "Run: 3\tsamples: None\tTime:1.4597973823547363\n",
      "Run: 4\tsamples: None\tTime:1.4338150024414062\n",
      "Running with parameters: cutoff=0.00030000000000000003 tune=0.4\n",
      "Run: 0\tsamples: None\tTime:1.5801775455474854\n",
      "Run: 1\tsamples: None\tTime:1.5556917190551758\n",
      "Run: 2\tsamples: None\tTime:1.4394383430480957\n",
      "Run: 3\tsamples: None\tTime:1.4726500511169434\n",
      "Run: 4\tsamples: None\tTime:1.427170991897583\n",
      "Running with parameters: cutoff=0.00030000000000000003 tune=0.45\n",
      "Run: 0\tsamples: None\tTime:1.6173195838928223\n",
      "Run: 1\tsamples: None\tTime:1.5018584728240967\n",
      "Run: 2\tsamples: None\tTime:1.391310453414917\n",
      "Run: 3\tsamples: None\tTime:1.4270048141479492\n",
      "Run: 4\tsamples: None\tTime:1.4215724468231201\n",
      "Running with parameters: cutoff=0.00030000000000000003 tune=0.5\n",
      "Run: 0\tsamples: None\tTime:1.6245887279510498\n",
      "Run: 1\tsamples: None\tTime:1.5254454612731934\n",
      "Run: 2\tsamples: None\tTime:1.422485589981079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 3\tsamples: None\tTime:1.4263885021209717\n",
      "Run: 4\tsamples: None\tTime:1.4265966415405273\n",
      "Running with parameters: cutoff=0.00030000000000000003 tune=0.55\n",
      "Run: 0\tsamples: None\tTime:1.6240451335906982\n",
      "Run: 1\tsamples: None\tTime:1.5549030303955078\n",
      "Run: 2\tsamples: None\tTime:1.4401347637176514\n",
      "Run: 3\tsamples: None\tTime:1.4129655361175537\n",
      "Run: 4\tsamples: None\tTime:1.425795555114746\n",
      "Running with parameters: cutoff=0.00030000000000000003 tune=0.6\n",
      "Run: 0\tsamples: None\tTime:1.6657025814056396\n",
      "Run: 1\tsamples: None\tTime:1.4920148849487305\n",
      "Run: 2\tsamples: None\tTime:1.4333326816558838\n",
      "Run: 3\tsamples: None\tTime:1.401719331741333\n",
      "Run: 4\tsamples: None\tTime:1.419318437576294\n",
      "Running with parameters: cutoff=0.00030000000000000003 tune=0.625\n",
      "Run: 0\tsamples: None\tTime:1.6330511569976807\n",
      "Run: 1\tsamples: None\tTime:1.5686731338500977\n",
      "Run: 2\tsamples: None\tTime:1.4697117805480957\n",
      "Run: 3\tsamples: None\tTime:1.4349501132965088\n",
      "Run: 4\tsamples: None\tTime:1.4141004085540771\n",
      "Running with parameters: cutoff=0.00030000000000000003 tune=0.65\n",
      "Run: 0\tsamples: None\tTime:1.5954129695892334\n",
      "Run: 1\tsamples: None\tTime:1.5260071754455566\n",
      "Run: 2\tsamples: None\tTime:1.4475071430206299\n",
      "Run: 3\tsamples: None\tTime:1.4507732391357422\n",
      "Run: 4\tsamples: None\tTime:1.4171271324157715\n",
      "Running with parameters: cutoff=0.00030000000000000003 tune=0.675\n",
      "Run: 0\tsamples: None\tTime:1.6005525588989258\n",
      "Run: 1\tsamples: None\tTime:1.5508615970611572\n",
      "Run: 2\tsamples: None\tTime:1.4538962841033936\n",
      "Run: 3\tsamples: None\tTime:1.4636473655700684\n",
      "Run: 4\tsamples: None\tTime:1.428316354751587\n",
      "Running with parameters: cutoff=0.00030000000000000003 tune=0.7000000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6110248565673828\n",
      "Run: 1\tsamples: None\tTime:1.5508880615234375\n",
      "Run: 2\tsamples: None\tTime:1.3904900550842285\n",
      "Run: 3\tsamples: None\tTime:1.4226820468902588\n",
      "Run: 4\tsamples: None\tTime:1.4264070987701416\n",
      "Running with parameters: cutoff=0.00030000000000000003 tune=0.7250000000000001\n",
      "Run: 0\tsamples: None\tTime:1.5896885395050049\n",
      "Run: 1\tsamples: None\tTime:1.5001285076141357\n",
      "Run: 2\tsamples: None\tTime:1.4564428329467773\n",
      "Run: 3\tsamples: None\tTime:1.4160606861114502\n",
      "Run: 4\tsamples: None\tTime:1.428368330001831\n",
      "Running with parameters: cutoff=0.00030000000000000003 tune=0.7500000000000001\n",
      "Run: 0\tsamples: None\tTime:1.5964562892913818\n",
      "Run: 1\tsamples: None\tTime:1.5666484832763672\n",
      "Run: 2\tsamples: None\tTime:1.418349027633667\n",
      "Run: 3\tsamples: None\tTime:1.4584460258483887\n",
      "Run: 4\tsamples: None\tTime:1.4294958114624023\n",
      "Running with parameters: cutoff=0.00030000000000000003 tune=0.7750000000000001\n",
      "Run: 0\tsamples: None\tTime:1.5893075466156006\n",
      "Run: 1\tsamples: None\tTime:1.5508034229278564\n",
      "Run: 2\tsamples: None\tTime:1.4037704467773438\n",
      "Run: 3\tsamples: None\tTime:1.416459560394287\n",
      "Run: 4\tsamples: None\tTime:1.450242042541504\n",
      "Running with parameters: cutoff=0.00030000000000000003 tune=0.8000000000000002\n",
      "Run: 0\tsamples: None\tTime:1.5639042854309082\n",
      "Run: 1\tsamples: None\tTime:1.4874050617218018\n",
      "Run: 2\tsamples: None\tTime:1.4578945636749268\n",
      "Run: 3\tsamples: None\tTime:1.443253993988037\n",
      "Run: 4\tsamples: None\tTime:1.4348032474517822\n",
      "Running with parameters: cutoff=0.0004 tune=0.4\n",
      "Run: 0\tsamples: None\tTime:1.5778281688690186\n",
      "Run: 1\tsamples: None\tTime:1.4948368072509766\n",
      "Run: 2\tsamples: None\tTime:1.4097888469696045\n",
      "Run: 3\tsamples: None\tTime:1.4430058002471924\n",
      "Run: 4\tsamples: None\tTime:1.4249653816223145\n",
      "Running with parameters: cutoff=0.0004 tune=0.45\n",
      "Run: 0\tsamples: None\tTime:1.6002781391143799\n",
      "Run: 1\tsamples: None\tTime:1.5411725044250488\n",
      "Run: 2\tsamples: None\tTime:1.4669618606567383\n",
      "Run: 3\tsamples: None\tTime:1.461160659790039\n",
      "Run: 4\tsamples: None\tTime:1.4278478622436523\n",
      "Running with parameters: cutoff=0.0004 tune=0.5\n",
      "Run: 0\tsamples: None\tTime:1.6117079257965088\n",
      "Run: 1\tsamples: None\tTime:1.5653245449066162\n",
      "Run: 2\tsamples: None\tTime:1.4747653007507324\n",
      "Run: 3\tsamples: None\tTime:1.471144437789917\n",
      "Run: 4\tsamples: None\tTime:1.4521393775939941\n",
      "Running with parameters: cutoff=0.0004 tune=0.55\n",
      "Run: 0\tsamples: None\tTime:1.6128454208374023\n",
      "Run: 1\tsamples: None\tTime:1.5566186904907227\n",
      "Run: 2\tsamples: None\tTime:1.4758670330047607\n",
      "Run: 3\tsamples: None\tTime:1.4512975215911865\n",
      "Run: 4\tsamples: None\tTime:1.4291226863861084\n",
      "Running with parameters: cutoff=0.0004 tune=0.6\n",
      "Run: 0\tsamples: None\tTime:1.6027741432189941\n",
      "Run: 1\tsamples: None\tTime:1.5090854167938232\n",
      "Run: 2\tsamples: None\tTime:1.439131259918213\n",
      "Run: 3\tsamples: None\tTime:1.4648098945617676\n",
      "Run: 4\tsamples: None\tTime:1.4361391067504883\n",
      "Running with parameters: cutoff=0.0004 tune=0.625\n",
      "Run: 0\tsamples: None\tTime:1.6029739379882812\n",
      "Run: 1\tsamples: None\tTime:1.5499801635742188\n",
      "Run: 2\tsamples: None\tTime:1.4350149631500244\n",
      "Run: 3\tsamples: None\tTime:1.4315314292907715\n",
      "Run: 4\tsamples: None\tTime:1.4309771060943604\n",
      "Running with parameters: cutoff=0.0004 tune=0.65\n",
      "Run: 0\tsamples: None\tTime:1.5960328578948975\n",
      "Run: 1\tsamples: None\tTime:1.4934594631195068\n",
      "Run: 2\tsamples: None\tTime:1.4377729892730713\n",
      "Run: 3\tsamples: None\tTime:1.4568729400634766\n",
      "Run: 4\tsamples: None\tTime:1.4323790073394775\n",
      "Running with parameters: cutoff=0.0004 tune=0.675\n",
      "Run: 0\tsamples: None\tTime:1.574634313583374\n",
      "Run: 1\tsamples: None\tTime:1.5029020309448242\n",
      "Run: 2\tsamples: None\tTime:1.4168031215667725\n",
      "Run: 3\tsamples: None\tTime:1.431056261062622\n",
      "Run: 4\tsamples: None\tTime:1.4412705898284912\n",
      "Running with parameters: cutoff=0.0004 tune=0.7000000000000001\n",
      "Run: 0\tsamples: None\tTime:1.597641944885254\n",
      "Run: 1\tsamples: None\tTime:1.5092682838439941\n",
      "Run: 2\tsamples: None\tTime:1.4579212665557861\n",
      "Run: 3\tsamples: None\tTime:1.4442496299743652\n",
      "Run: 4\tsamples: None\tTime:1.422602891921997\n",
      "Running with parameters: cutoff=0.0004 tune=0.7250000000000001\n",
      "Run: 0\tsamples: None\tTime:1.617281436920166\n",
      "Run: 1\tsamples: None\tTime:1.548513650894165\n",
      "Run: 2\tsamples: None\tTime:1.4272606372833252\n",
      "Run: 3\tsamples: None\tTime:1.457275390625\n",
      "Run: 4\tsamples: None\tTime:1.43229341506958\n",
      "Running with parameters: cutoff=0.0004 tune=0.7500000000000001\n",
      "Run: 0\tsamples: None\tTime:1.609086513519287\n",
      "Run: 1\tsamples: None\tTime:1.5110447406768799\n",
      "Run: 2\tsamples: None\tTime:1.4601895809173584\n",
      "Run: 3\tsamples: None\tTime:1.4235422611236572\n",
      "Run: 4\tsamples: None\tTime:1.4310243129730225\n",
      "Running with parameters: cutoff=0.0004 tune=0.7750000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6172761917114258\n",
      "Run: 1\tsamples: None\tTime:1.6334402561187744\n",
      "Run: 2\tsamples: None\tTime:1.453705072402954\n",
      "Run: 3\tsamples: None\tTime:1.4727773666381836\n",
      "Run: 4\tsamples: None\tTime:1.4360170364379883\n",
      "Running with parameters: cutoff=0.0004 tune=0.8000000000000002\n",
      "Run: 0\tsamples: None\tTime:1.5756394863128662\n",
      "Run: 1\tsamples: None\tTime:1.577927827835083\n",
      "Run: 2\tsamples: None\tTime:1.3955187797546387\n",
      "Run: 3\tsamples: None\tTime:1.3986430168151855\n",
      "Run: 4\tsamples: None\tTime:1.4095666408538818\n",
      "Running with parameters: cutoff=0.0005 tune=0.4\n",
      "Run: 0\tsamples: None\tTime:1.602738857269287\n",
      "Run: 1\tsamples: None\tTime:1.571714162826538\n",
      "Run: 2\tsamples: None\tTime:1.4215624332427979\n",
      "Run: 3\tsamples: None\tTime:1.4566242694854736\n",
      "Run: 4\tsamples: None\tTime:1.4337677955627441\n",
      "Running with parameters: cutoff=0.0005 tune=0.45\n",
      "Run: 0\tsamples: None\tTime:1.5730485916137695\n",
      "Run: 1\tsamples: None\tTime:1.5776216983795166\n",
      "Run: 2\tsamples: None\tTime:1.4330706596374512\n",
      "Run: 3\tsamples: None\tTime:1.4264163970947266\n",
      "Run: 4\tsamples: None\tTime:1.4258718490600586\n",
      "Running with parameters: cutoff=0.0005 tune=0.5\n",
      "Run: 0\tsamples: None\tTime:1.5929744243621826\n",
      "Run: 1\tsamples: None\tTime:1.5547637939453125\n",
      "Run: 2\tsamples: None\tTime:1.4389255046844482\n",
      "Run: 3\tsamples: None\tTime:1.4289865493774414\n",
      "Run: 4\tsamples: None\tTime:1.4241960048675537\n",
      "Running with parameters: cutoff=0.0005 tune=0.55\n",
      "Run: 0\tsamples: None\tTime:1.5603270530700684\n",
      "Run: 1\tsamples: None\tTime:1.5264952182769775\n",
      "Run: 2\tsamples: None\tTime:1.4214258193969727\n",
      "Run: 3\tsamples: None\tTime:1.4216415882110596\n",
      "Run: 4\tsamples: None\tTime:1.4111394882202148\n",
      "Running with parameters: cutoff=0.0005 tune=0.6\n",
      "Run: 0\tsamples: None\tTime:1.5916528701782227\n",
      "Run: 1\tsamples: None\tTime:1.5505249500274658\n",
      "Run: 2\tsamples: None\tTime:1.4087774753570557\n",
      "Run: 3\tsamples: None\tTime:1.473816156387329\n",
      "Run: 4\tsamples: None\tTime:1.4458339214324951\n",
      "Running with parameters: cutoff=0.0005 tune=0.625\n",
      "Run: 0\tsamples: None\tTime:1.5867469310760498\n",
      "Run: 1\tsamples: None\tTime:1.5875732898712158\n",
      "Run: 2\tsamples: None\tTime:1.4761369228363037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 3\tsamples: None\tTime:1.429429054260254\n",
      "Run: 4\tsamples: None\tTime:1.4393706321716309\n",
      "Running with parameters: cutoff=0.0005 tune=0.65\n",
      "Run: 0\tsamples: None\tTime:1.5905375480651855\n",
      "Run: 1\tsamples: None\tTime:1.523695707321167\n",
      "Run: 2\tsamples: None\tTime:1.4430654048919678\n",
      "Run: 3\tsamples: None\tTime:1.4511640071868896\n",
      "Run: 4\tsamples: None\tTime:1.4367551803588867\n",
      "Running with parameters: cutoff=0.0005 tune=0.675\n",
      "Run: 0\tsamples: None\tTime:1.5959343910217285\n",
      "Run: 1\tsamples: None\tTime:1.5200870037078857\n",
      "Run: 2\tsamples: None\tTime:1.4407565593719482\n",
      "Run: 3\tsamples: None\tTime:1.4368045330047607\n",
      "Run: 4\tsamples: None\tTime:1.4104821681976318\n",
      "Running with parameters: cutoff=0.0005 tune=0.7000000000000001\n",
      "Run: 0\tsamples: None\tTime:1.606363296508789\n",
      "Run: 1\tsamples: None\tTime:1.5418274402618408\n",
      "Run: 2\tsamples: None\tTime:1.4662718772888184\n",
      "Run: 3\tsamples: None\tTime:1.4383363723754883\n",
      "Run: 4\tsamples: None\tTime:1.4218966960906982\n",
      "Running with parameters: cutoff=0.0005 tune=0.7250000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6042747497558594\n",
      "Run: 1\tsamples: None\tTime:1.5583577156066895\n",
      "Run: 2\tsamples: None\tTime:1.425175666809082\n",
      "Run: 3\tsamples: None\tTime:1.4554684162139893\n",
      "Run: 4\tsamples: None\tTime:1.434521198272705\n",
      "Running with parameters: cutoff=0.0005 tune=0.7500000000000001\n",
      "Run: 0\tsamples: None\tTime:1.5916099548339844\n",
      "Run: 1\tsamples: None\tTime:1.5488643646240234\n",
      "Run: 2\tsamples: None\tTime:1.3950912952423096\n",
      "Run: 3\tsamples: None\tTime:1.4824373722076416\n",
      "Run: 4\tsamples: None\tTime:1.4101085662841797\n",
      "Running with parameters: cutoff=0.0005 tune=0.7750000000000001\n",
      "Run: 0\tsamples: None\tTime:1.598360538482666\n",
      "Run: 1\tsamples: None\tTime:1.540585994720459\n",
      "Run: 2\tsamples: None\tTime:1.4465601444244385\n",
      "Run: 3\tsamples: None\tTime:1.4162299633026123\n",
      "Run: 4\tsamples: None\tTime:1.4330155849456787\n",
      "Running with parameters: cutoff=0.0005 tune=0.8000000000000002\n",
      "Run: 0\tsamples: None\tTime:1.5910618305206299\n",
      "Run: 1\tsamples: None\tTime:1.5313665866851807\n",
      "Run: 2\tsamples: None\tTime:1.3821542263031006\n",
      "Run: 3\tsamples: None\tTime:1.4416320323944092\n",
      "Run: 4\tsamples: None\tTime:1.428466796875\n",
      "Running with parameters: cutoff=0.0006000000000000001 tune=0.4\n",
      "Run: 0\tsamples: None\tTime:1.6227607727050781\n",
      "Run: 1\tsamples: None\tTime:1.5927321910858154\n",
      "Run: 2\tsamples: None\tTime:1.4555556774139404\n",
      "Run: 3\tsamples: None\tTime:1.4553954601287842\n",
      "Run: 4\tsamples: None\tTime:1.418839931488037\n",
      "Running with parameters: cutoff=0.0006000000000000001 tune=0.45\n",
      "Run: 0\tsamples: None\tTime:1.623311996459961\n",
      "Run: 1\tsamples: None\tTime:1.5421900749206543\n",
      "Run: 2\tsamples: None\tTime:1.4364523887634277\n",
      "Run: 3\tsamples: None\tTime:1.425283432006836\n",
      "Run: 4\tsamples: None\tTime:1.45827054977417\n",
      "Running with parameters: cutoff=0.0006000000000000001 tune=0.5\n",
      "Run: 0\tsamples: None\tTime:1.5852594375610352\n",
      "Run: 1\tsamples: None\tTime:1.511106014251709\n",
      "Run: 2\tsamples: None\tTime:1.4508907794952393\n",
      "Run: 3\tsamples: None\tTime:1.4717929363250732\n",
      "Run: 4\tsamples: None\tTime:1.421602487564087\n",
      "Running with parameters: cutoff=0.0006000000000000001 tune=0.55\n",
      "Run: 0\tsamples: None\tTime:1.5952258110046387\n",
      "Run: 1\tsamples: None\tTime:1.4939653873443604\n",
      "Run: 2\tsamples: None\tTime:1.4096217155456543\n",
      "Run: 3\tsamples: None\tTime:1.480539083480835\n",
      "Run: 4\tsamples: None\tTime:1.4284825325012207\n",
      "Running with parameters: cutoff=0.0006000000000000001 tune=0.6\n",
      "Run: 0\tsamples: None\tTime:1.6119229793548584\n",
      "Run: 1\tsamples: None\tTime:1.5448863506317139\n",
      "Run: 2\tsamples: None\tTime:1.4296891689300537\n",
      "Run: 3\tsamples: None\tTime:1.4700069427490234\n",
      "Run: 4\tsamples: None\tTime:1.4198405742645264\n",
      "Running with parameters: cutoff=0.0006000000000000001 tune=0.625\n",
      "Run: 0\tsamples: None\tTime:1.5952389240264893\n",
      "Run: 1\tsamples: None\tTime:1.5183534622192383\n",
      "Run: 2\tsamples: None\tTime:1.4281189441680908\n",
      "Run: 3\tsamples: None\tTime:1.4596304893493652\n",
      "Run: 4\tsamples: None\tTime:1.4318170547485352\n",
      "Running with parameters: cutoff=0.0006000000000000001 tune=0.65\n",
      "Run: 0\tsamples: None\tTime:1.6018040180206299\n",
      "Run: 1\tsamples: None\tTime:1.544910192489624\n",
      "Run: 2\tsamples: None\tTime:1.446563482284546\n",
      "Run: 3\tsamples: None\tTime:1.4207184314727783\n",
      "Run: 4\tsamples: None\tTime:1.4181089401245117\n",
      "Running with parameters: cutoff=0.0006000000000000001 tune=0.675\n",
      "Run: 0\tsamples: None\tTime:1.610097885131836\n",
      "Run: 1\tsamples: None\tTime:1.4937522411346436\n",
      "Run: 2\tsamples: None\tTime:1.4210209846496582\n",
      "Run: 3\tsamples: None\tTime:1.4161901473999023\n",
      "Run: 4\tsamples: None\tTime:1.4223802089691162\n",
      "Running with parameters: cutoff=0.0006000000000000001 tune=0.7000000000000001\n",
      "Run: 0\tsamples: None\tTime:1.623189926147461\n",
      "Run: 1\tsamples: None\tTime:1.4953010082244873\n",
      "Run: 2\tsamples: None\tTime:1.4413282871246338\n",
      "Run: 3\tsamples: None\tTime:1.4455437660217285\n",
      "Run: 4\tsamples: None\tTime:1.4138693809509277\n",
      "Running with parameters: cutoff=0.0006000000000000001 tune=0.7250000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6244590282440186\n",
      "Run: 1\tsamples: None\tTime:1.4910845756530762\n",
      "Run: 2\tsamples: None\tTime:1.3952782154083252\n",
      "Run: 3\tsamples: None\tTime:1.437612533569336\n",
      "Run: 4\tsamples: None\tTime:1.43121337890625\n",
      "Running with parameters: cutoff=0.0006000000000000001 tune=0.7500000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6042547225952148\n",
      "Run: 1\tsamples: None\tTime:1.4970080852508545\n",
      "Run: 2\tsamples: None\tTime:1.4114065170288086\n",
      "Run: 3\tsamples: None\tTime:1.44388747215271\n",
      "Run: 4\tsamples: None\tTime:1.4121556282043457\n",
      "Running with parameters: cutoff=0.0006000000000000001 tune=0.7750000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6190731525421143\n",
      "Run: 1\tsamples: None\tTime:1.4932100772857666\n",
      "Run: 2\tsamples: None\tTime:1.4331026077270508\n",
      "Run: 3\tsamples: None\tTime:1.470243215560913\n",
      "Run: 4\tsamples: None\tTime:1.443695068359375\n",
      "Running with parameters: cutoff=0.0006000000000000001 tune=0.8000000000000002\n",
      "Run: 0\tsamples: None\tTime:1.6070098876953125\n",
      "Run: 1\tsamples: None\tTime:1.4998195171356201\n",
      "Run: 2\tsamples: None\tTime:1.4699809551239014\n",
      "Run: 3\tsamples: None\tTime:1.4245235919952393\n",
      "Run: 4\tsamples: None\tTime:1.4103758335113525\n",
      "Running with parameters: cutoff=0.0007000000000000001 tune=0.4\n",
      "Run: 0\tsamples: None\tTime:1.5998992919921875\n",
      "Run: 1\tsamples: None\tTime:1.5373432636260986\n",
      "Run: 2\tsamples: None\tTime:1.4141349792480469\n",
      "Run: 3\tsamples: None\tTime:1.4667294025421143\n",
      "Run: 4\tsamples: None\tTime:1.4352948665618896\n",
      "Running with parameters: cutoff=0.0007000000000000001 tune=0.45\n",
      "Run: 0\tsamples: None\tTime:1.587949514389038\n",
      "Run: 1\tsamples: None\tTime:1.5036613941192627\n",
      "Run: 2\tsamples: None\tTime:1.4315338134765625\n",
      "Run: 3\tsamples: None\tTime:1.4432497024536133\n",
      "Run: 4\tsamples: None\tTime:1.4122681617736816\n",
      "Running with parameters: cutoff=0.0007000000000000001 tune=0.5\n",
      "Run: 0\tsamples: None\tTime:1.6191480159759521\n",
      "Run: 1\tsamples: None\tTime:1.512556791305542\n",
      "Run: 2\tsamples: None\tTime:1.4223167896270752\n",
      "Run: 3\tsamples: None\tTime:1.4189138412475586\n",
      "Run: 4\tsamples: None\tTime:1.413949728012085\n",
      "Running with parameters: cutoff=0.0007000000000000001 tune=0.55\n",
      "Run: 0\tsamples: None\tTime:1.585310697555542\n",
      "Run: 1\tsamples: None\tTime:1.572922706604004\n",
      "Run: 2\tsamples: None\tTime:1.434420108795166\n",
      "Run: 3\tsamples: None\tTime:1.42336106300354\n",
      "Run: 4\tsamples: None\tTime:1.4351766109466553\n",
      "Running with parameters: cutoff=0.0007000000000000001 tune=0.6\n",
      "Run: 0\tsamples: None\tTime:1.5988214015960693\n",
      "Run: 1\tsamples: None\tTime:1.5257267951965332\n",
      "Run: 2\tsamples: None\tTime:1.4390771389007568\n",
      "Run: 3\tsamples: None\tTime:1.4396905899047852\n",
      "Run: 4\tsamples: None\tTime:1.4191982746124268\n",
      "Running with parameters: cutoff=0.0007000000000000001 tune=0.625\n",
      "Run: 0\tsamples: None\tTime:1.6001076698303223\n",
      "Run: 1\tsamples: None\tTime:1.5102887153625488\n",
      "Run: 2\tsamples: None\tTime:1.4176478385925293\n",
      "Run: 3\tsamples: None\tTime:1.4231204986572266\n",
      "Run: 4\tsamples: None\tTime:1.405735969543457\n",
      "Running with parameters: cutoff=0.0007000000000000001 tune=0.65\n",
      "Run: 0\tsamples: None\tTime:1.6026456356048584\n",
      "Run: 1\tsamples: None\tTime:1.481872320175171\n",
      "Run: 2\tsamples: None\tTime:1.403778076171875\n",
      "Run: 3\tsamples: None\tTime:1.4134647846221924\n",
      "Run: 4\tsamples: None\tTime:1.4307634830474854\n",
      "Running with parameters: cutoff=0.0007000000000000001 tune=0.675\n",
      "Run: 0\tsamples: None\tTime:1.563072681427002\n",
      "Run: 1\tsamples: None\tTime:1.5625009536743164\n",
      "Run: 2\tsamples: None\tTime:1.4670300483703613\n",
      "Run: 3\tsamples: None\tTime:1.4266481399536133\n",
      "Run: 4\tsamples: None\tTime:1.4153318405151367\n",
      "Running with parameters: cutoff=0.0007000000000000001 tune=0.7000000000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\tsamples: None\tTime:1.5756309032440186\n",
      "Run: 1\tsamples: None\tTime:1.5198054313659668\n",
      "Run: 2\tsamples: None\tTime:1.439605474472046\n",
      "Run: 3\tsamples: None\tTime:1.4560527801513672\n",
      "Run: 4\tsamples: None\tTime:1.4434781074523926\n",
      "Running with parameters: cutoff=0.0007000000000000001 tune=0.7250000000000001\n",
      "Run: 0\tsamples: None\tTime:1.5908520221710205\n",
      "Run: 1\tsamples: None\tTime:1.5935757160186768\n",
      "Run: 2\tsamples: None\tTime:1.418339729309082\n",
      "Run: 3\tsamples: None\tTime:1.4294278621673584\n",
      "Run: 4\tsamples: None\tTime:1.4251890182495117\n",
      "Running with parameters: cutoff=0.0007000000000000001 tune=0.7500000000000001\n",
      "Run: 0\tsamples: None\tTime:1.582911729812622\n",
      "Run: 1\tsamples: None\tTime:1.545088768005371\n",
      "Run: 2\tsamples: None\tTime:1.445225477218628\n",
      "Run: 3\tsamples: None\tTime:1.4706761837005615\n",
      "Run: 4\tsamples: None\tTime:1.433760404586792\n",
      "Running with parameters: cutoff=0.0007000000000000001 tune=0.7750000000000001\n",
      "Run: 0\tsamples: None\tTime:1.5895037651062012\n",
      "Run: 1\tsamples: None\tTime:1.5920803546905518\n",
      "Run: 2\tsamples: None\tTime:1.403407335281372\n",
      "Run: 3\tsamples: None\tTime:1.4229907989501953\n",
      "Run: 4\tsamples: None\tTime:1.405303955078125\n",
      "Running with parameters: cutoff=0.0007000000000000001 tune=0.8000000000000002\n",
      "Run: 0\tsamples: None\tTime:1.5784456729888916\n",
      "Run: 1\tsamples: None\tTime:1.4796676635742188\n",
      "Run: 2\tsamples: None\tTime:1.4477851390838623\n",
      "Run: 3\tsamples: None\tTime:1.453550100326538\n",
      "Run: 4\tsamples: None\tTime:1.4492888450622559\n",
      "Running with parameters: cutoff=0.0008 tune=0.4\n",
      "Run: 0\tsamples: None\tTime:1.5989367961883545\n",
      "Run: 1\tsamples: None\tTime:1.5493488311767578\n",
      "Run: 2\tsamples: None\tTime:1.4104466438293457\n",
      "Run: 3\tsamples: None\tTime:1.4615142345428467\n",
      "Run: 4\tsamples: None\tTime:1.443091869354248\n",
      "Running with parameters: cutoff=0.0008 tune=0.45\n",
      "Run: 0\tsamples: None\tTime:1.6007251739501953\n",
      "Run: 1\tsamples: None\tTime:1.55631422996521\n",
      "Run: 2\tsamples: None\tTime:1.4338951110839844\n",
      "Run: 3\tsamples: None\tTime:1.4033598899841309\n",
      "Run: 4\tsamples: None\tTime:1.430312156677246\n",
      "Running with parameters: cutoff=0.0008 tune=0.5\n",
      "Run: 0\tsamples: None\tTime:1.6140544414520264\n",
      "Run: 1\tsamples: None\tTime:1.4865026473999023\n",
      "Run: 2\tsamples: None\tTime:1.463334083557129\n",
      "Run: 3\tsamples: None\tTime:1.455864667892456\n",
      "Run: 4\tsamples: None\tTime:1.4062728881835938\n",
      "Running with parameters: cutoff=0.0008 tune=0.55\n",
      "Run: 0\tsamples: None\tTime:1.5698647499084473\n",
      "Run: 1\tsamples: None\tTime:1.570319414138794\n",
      "Run: 2\tsamples: None\tTime:1.4213910102844238\n",
      "Run: 3\tsamples: None\tTime:1.5006723403930664\n",
      "Run: 4\tsamples: None\tTime:1.4333736896514893\n",
      "Running with parameters: cutoff=0.0008 tune=0.6\n",
      "Run: 0\tsamples: None\tTime:1.6118719577789307\n",
      "Run: 1\tsamples: None\tTime:1.5150327682495117\n",
      "Run: 2\tsamples: None\tTime:1.439842700958252\n",
      "Run: 3\tsamples: None\tTime:1.481407880783081\n",
      "Run: 4\tsamples: None\tTime:1.4760408401489258\n",
      "Running with parameters: cutoff=0.0008 tune=0.625\n",
      "Run: 0\tsamples: None\tTime:1.6074717044830322\n",
      "Run: 1\tsamples: None\tTime:1.496941328048706\n",
      "Run: 2\tsamples: None\tTime:1.4623172283172607\n",
      "Run: 3\tsamples: None\tTime:1.4644510746002197\n",
      "Run: 4\tsamples: None\tTime:1.498896598815918\n",
      "Running with parameters: cutoff=0.0008 tune=0.65\n",
      "Run: 0\tsamples: None\tTime:1.6117379665374756\n",
      "Run: 1\tsamples: None\tTime:1.6049222946166992\n",
      "Run: 2\tsamples: None\tTime:1.4560141563415527\n",
      "Run: 3\tsamples: None\tTime:1.5867125988006592\n",
      "Run: 4\tsamples: None\tTime:1.472914457321167\n",
      "Running with parameters: cutoff=0.0008 tune=0.675\n",
      "Run: 0\tsamples: None\tTime:1.6407599449157715\n",
      "Run: 1\tsamples: None\tTime:1.5540976524353027\n",
      "Run: 2\tsamples: None\tTime:1.4316155910491943\n",
      "Run: 3\tsamples: None\tTime:1.5108146667480469\n",
      "Run: 4\tsamples: None\tTime:1.4864106178283691\n",
      "Running with parameters: cutoff=0.0008 tune=0.7000000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6143414974212646\n",
      "Run: 1\tsamples: None\tTime:1.6023213863372803\n",
      "Run: 2\tsamples: None\tTime:1.536252737045288\n",
      "Run: 3\tsamples: None\tTime:1.4659123420715332\n",
      "Run: 4\tsamples: None\tTime:1.4605059623718262\n",
      "Running with parameters: cutoff=0.0008 tune=0.7250000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6252505779266357\n",
      "Run: 1\tsamples: None\tTime:1.6248266696929932\n",
      "Run: 2\tsamples: None\tTime:1.473947286605835\n",
      "Run: 3\tsamples: None\tTime:1.4334611892700195\n",
      "Run: 4\tsamples: None\tTime:1.4415276050567627\n",
      "Running with parameters: cutoff=0.0008 tune=0.7500000000000001\n",
      "Run: 0\tsamples: None\tTime:1.721740484237671\n",
      "Run: 1\tsamples: None\tTime:1.5939867496490479\n",
      "Run: 2\tsamples: None\tTime:1.440474271774292\n",
      "Run: 3\tsamples: None\tTime:1.417407512664795\n",
      "Run: 4\tsamples: None\tTime:1.4265861511230469\n",
      "Running with parameters: cutoff=0.0008 tune=0.7750000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6072909832000732\n",
      "Run: 1\tsamples: None\tTime:1.580495834350586\n",
      "Run: 2\tsamples: None\tTime:1.4242205619812012\n",
      "Run: 3\tsamples: None\tTime:1.4648988246917725\n",
      "Run: 4\tsamples: None\tTime:1.4243831634521484\n",
      "Running with parameters: cutoff=0.0008 tune=0.8000000000000002\n",
      "Run: 0\tsamples: None\tTime:1.623732089996338\n",
      "Run: 1\tsamples: None\tTime:1.544795036315918\n",
      "Run: 2\tsamples: None\tTime:1.4588122367858887\n",
      "Run: 3\tsamples: None\tTime:1.4244771003723145\n",
      "Run: 4\tsamples: None\tTime:1.4466376304626465\n",
      "Running with parameters: cutoff=0.0009000000000000001 tune=0.4\n",
      "Run: 0\tsamples: None\tTime:1.595031499862671\n",
      "Run: 1\tsamples: None\tTime:1.4987685680389404\n",
      "Run: 2\tsamples: None\tTime:1.4314820766448975\n",
      "Run: 3\tsamples: None\tTime:1.438178539276123\n",
      "Run: 4\tsamples: None\tTime:1.4132003784179688\n",
      "Running with parameters: cutoff=0.0009000000000000001 tune=0.45\n",
      "Run: 0\tsamples: None\tTime:1.5997464656829834\n",
      "Run: 1\tsamples: None\tTime:1.5050644874572754\n",
      "Run: 2\tsamples: None\tTime:1.4136834144592285\n",
      "Run: 3\tsamples: None\tTime:1.4201433658599854\n",
      "Run: 4\tsamples: None\tTime:1.430337905883789\n",
      "Running with parameters: cutoff=0.0009000000000000001 tune=0.5\n",
      "Run: 0\tsamples: None\tTime:1.6206977367401123\n",
      "Run: 1\tsamples: None\tTime:1.5016324520111084\n",
      "Run: 2\tsamples: None\tTime:1.4164247512817383\n",
      "Run: 3\tsamples: None\tTime:1.434335470199585\n",
      "Run: 4\tsamples: None\tTime:1.4251024723052979\n",
      "Running with parameters: cutoff=0.0009000000000000001 tune=0.55\n",
      "Run: 0\tsamples: None\tTime:1.5816941261291504\n",
      "Run: 1\tsamples: None\tTime:1.5783019065856934\n",
      "Run: 2\tsamples: None\tTime:1.4523367881774902\n",
      "Run: 3\tsamples: None\tTime:1.4595000743865967\n",
      "Run: 4\tsamples: None\tTime:1.4466493129730225\n",
      "Running with parameters: cutoff=0.0009000000000000001 tune=0.6\n",
      "Run: 0\tsamples: None\tTime:1.5702428817749023\n",
      "Run: 1\tsamples: None\tTime:1.5380079746246338\n",
      "Run: 2\tsamples: None\tTime:1.4317560195922852\n",
      "Run: 3\tsamples: None\tTime:1.4584813117980957\n",
      "Run: 4\tsamples: None\tTime:1.4366519451141357\n",
      "Running with parameters: cutoff=0.0009000000000000001 tune=0.625\n",
      "Run: 0\tsamples: None\tTime:1.5862209796905518\n",
      "Run: 1\tsamples: None\tTime:1.5244314670562744\n",
      "Run: 2\tsamples: None\tTime:1.4565191268920898\n",
      "Run: 3\tsamples: None\tTime:1.4246718883514404\n",
      "Run: 4\tsamples: None\tTime:1.4213948249816895\n",
      "Running with parameters: cutoff=0.0009000000000000001 tune=0.65\n",
      "Run: 0\tsamples: None\tTime:1.6138346195220947\n",
      "Run: 1\tsamples: None\tTime:1.5187437534332275\n",
      "Run: 2\tsamples: None\tTime:1.4640140533447266\n",
      "Run: 3\tsamples: None\tTime:1.478318691253662\n",
      "Run: 4\tsamples: None\tTime:1.4255549907684326\n",
      "Running with parameters: cutoff=0.0009000000000000001 tune=0.675\n",
      "Run: 0\tsamples: None\tTime:1.6064188480377197\n",
      "Run: 1\tsamples: None\tTime:1.5532784461975098\n",
      "Run: 2\tsamples: None\tTime:1.4032166004180908\n",
      "Run: 3\tsamples: None\tTime:1.4017252922058105\n",
      "Run: 4\tsamples: None\tTime:1.4298479557037354\n",
      "Running with parameters: cutoff=0.0009000000000000001 tune=0.7000000000000001\n",
      "Run: 0\tsamples: None\tTime:1.598891258239746\n",
      "Run: 1\tsamples: None\tTime:1.5368568897247314\n",
      "Run: 2\tsamples: None\tTime:1.4477310180664062\n",
      "Run: 3\tsamples: None\tTime:1.473667860031128\n",
      "Run: 4\tsamples: None\tTime:1.4213285446166992\n",
      "Running with parameters: cutoff=0.0009000000000000001 tune=0.7250000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6070618629455566\n",
      "Run: 1\tsamples: None\tTime:1.5543646812438965\n",
      "Run: 2\tsamples: None\tTime:1.4220099449157715\n",
      "Run: 3\tsamples: None\tTime:1.4428858757019043\n",
      "Run: 4\tsamples: None\tTime:1.443279504776001\n",
      "Running with parameters: cutoff=0.0009000000000000001 tune=0.7500000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6131975650787354\n",
      "Run: 1\tsamples: None\tTime:1.544767141342163\n",
      "Run: 2\tsamples: None\tTime:1.438734769821167\n",
      "Run: 3\tsamples: None\tTime:1.4137029647827148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 4\tsamples: None\tTime:1.4146556854248047\n",
      "Running with parameters: cutoff=0.0009000000000000001 tune=0.7750000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6082963943481445\n",
      "Run: 1\tsamples: None\tTime:1.5072238445281982\n",
      "Run: 2\tsamples: None\tTime:1.4089961051940918\n",
      "Run: 3\tsamples: None\tTime:1.4424958229064941\n",
      "Run: 4\tsamples: None\tTime:1.4237351417541504\n",
      "Running with parameters: cutoff=0.0009000000000000001 tune=0.8000000000000002\n",
      "Run: 0\tsamples: None\tTime:1.6027657985687256\n",
      "Run: 1\tsamples: None\tTime:1.5221245288848877\n",
      "Run: 2\tsamples: None\tTime:1.4416189193725586\n",
      "Run: 3\tsamples: None\tTime:1.4593493938446045\n",
      "Run: 4\tsamples: None\tTime:1.427900791168213\n",
      "Running with parameters: cutoff=0.001 tune=0.4\n",
      "Run: 0\tsamples: None\tTime:1.612962245941162\n",
      "Run: 1\tsamples: None\tTime:1.5586390495300293\n",
      "Run: 2\tsamples: None\tTime:1.4272129535675049\n",
      "Run: 3\tsamples: None\tTime:1.4522459506988525\n",
      "Run: 4\tsamples: None\tTime:1.433889627456665\n",
      "Running with parameters: cutoff=0.001 tune=0.45\n",
      "Run: 0\tsamples: None\tTime:1.578117847442627\n",
      "Run: 1\tsamples: None\tTime:1.5311744213104248\n",
      "Run: 2\tsamples: None\tTime:1.4002890586853027\n",
      "Run: 3\tsamples: None\tTime:1.4233825206756592\n",
      "Run: 4\tsamples: None\tTime:1.4353530406951904\n",
      "Running with parameters: cutoff=0.001 tune=0.5\n",
      "Run: 0\tsamples: None\tTime:1.6232080459594727\n",
      "Run: 1\tsamples: None\tTime:1.4893732070922852\n",
      "Run: 2\tsamples: None\tTime:1.4351496696472168\n",
      "Run: 3\tsamples: None\tTime:1.4564166069030762\n",
      "Run: 4\tsamples: None\tTime:1.4255847930908203\n",
      "Running with parameters: cutoff=0.001 tune=0.55\n",
      "Run: 0\tsamples: None\tTime:1.597877025604248\n",
      "Run: 1\tsamples: None\tTime:1.4962010383605957\n",
      "Run: 2\tsamples: None\tTime:1.4384074211120605\n",
      "Run: 3\tsamples: None\tTime:1.4710512161254883\n",
      "Run: 4\tsamples: None\tTime:1.4473497867584229\n",
      "Running with parameters: cutoff=0.001 tune=0.6\n",
      "Run: 0\tsamples: None\tTime:1.6290616989135742\n",
      "Run: 1\tsamples: None\tTime:1.5524098873138428\n",
      "Run: 2\tsamples: None\tTime:1.443542242050171\n",
      "Run: 3\tsamples: None\tTime:1.4796009063720703\n",
      "Run: 4\tsamples: None\tTime:1.4465265274047852\n",
      "Running with parameters: cutoff=0.001 tune=0.625\n",
      "Run: 0\tsamples: None\tTime:1.583467721939087\n",
      "Run: 1\tsamples: None\tTime:1.552703619003296\n",
      "Run: 2\tsamples: None\tTime:1.4677538871765137\n",
      "Run: 3\tsamples: None\tTime:1.4416604042053223\n",
      "Run: 4\tsamples: None\tTime:1.4034233093261719\n",
      "Running with parameters: cutoff=0.001 tune=0.65\n",
      "Run: 0\tsamples: None\tTime:1.6146409511566162\n",
      "Run: 1\tsamples: None\tTime:1.566554069519043\n",
      "Run: 2\tsamples: None\tTime:1.424635410308838\n",
      "Run: 3\tsamples: None\tTime:1.4542794227600098\n",
      "Run: 4\tsamples: None\tTime:1.4576449394226074\n",
      "Running with parameters: cutoff=0.001 tune=0.675\n",
      "Run: 0\tsamples: None\tTime:1.6230909824371338\n",
      "Run: 1\tsamples: None\tTime:1.503662109375\n",
      "Run: 2\tsamples: None\tTime:1.3759009838104248\n",
      "Run: 3\tsamples: None\tTime:1.4327759742736816\n",
      "Run: 4\tsamples: None\tTime:1.454894781112671\n",
      "Running with parameters: cutoff=0.001 tune=0.7000000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6000704765319824\n",
      "Run: 1\tsamples: None\tTime:1.4751965999603271\n",
      "Run: 2\tsamples: None\tTime:1.475846290588379\n",
      "Run: 3\tsamples: None\tTime:1.4758334159851074\n",
      "Run: 4\tsamples: None\tTime:1.4298310279846191\n",
      "Running with parameters: cutoff=0.001 tune=0.7250000000000001\n",
      "Run: 0\tsamples: None\tTime:1.640479564666748\n",
      "Run: 1\tsamples: None\tTime:1.5375664234161377\n",
      "Run: 2\tsamples: None\tTime:1.4733457565307617\n",
      "Run: 3\tsamples: None\tTime:1.4583203792572021\n",
      "Run: 4\tsamples: None\tTime:1.4321978092193604\n",
      "Running with parameters: cutoff=0.001 tune=0.7500000000000001\n",
      "Run: 0\tsamples: None\tTime:1.5916740894317627\n",
      "Run: 1\tsamples: None\tTime:1.5554544925689697\n",
      "Run: 2\tsamples: None\tTime:1.417447805404663\n",
      "Run: 3\tsamples: None\tTime:1.458599328994751\n",
      "Run: 4\tsamples: None\tTime:1.4274046421051025\n",
      "Running with parameters: cutoff=0.001 tune=0.7750000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6200263500213623\n",
      "Run: 1\tsamples: None\tTime:1.525524616241455\n",
      "Run: 2\tsamples: None\tTime:1.4291157722473145\n",
      "Run: 3\tsamples: None\tTime:1.457002878189087\n",
      "Run: 4\tsamples: None\tTime:1.4248838424682617\n",
      "Running with parameters: cutoff=0.001 tune=0.8000000000000002\n",
      "Run: 0\tsamples: None\tTime:1.598151683807373\n",
      "Run: 1\tsamples: None\tTime:1.5405292510986328\n",
      "Run: 2\tsamples: None\tTime:1.4287731647491455\n",
      "Run: 3\tsamples: None\tTime:1.4147279262542725\n",
      "Run: 4\tsamples: None\tTime:1.4295337200164795\n",
      "Running with parameters: cutoff=0.0012000000000000001 tune=0.4\n",
      "Run: 0\tsamples: None\tTime:1.5971925258636475\n",
      "Run: 1\tsamples: None\tTime:1.605156421661377\n",
      "Run: 2\tsamples: None\tTime:1.4564721584320068\n",
      "Run: 3\tsamples: None\tTime:1.467104434967041\n",
      "Run: 4\tsamples: None\tTime:1.4348876476287842\n",
      "Running with parameters: cutoff=0.0012000000000000001 tune=0.45\n",
      "Run: 0\tsamples: None\tTime:1.5761845111846924\n",
      "Run: 1\tsamples: None\tTime:1.5485200881958008\n",
      "Run: 2\tsamples: None\tTime:1.4203433990478516\n",
      "Run: 3\tsamples: None\tTime:1.4265248775482178\n",
      "Run: 4\tsamples: None\tTime:1.4111852645874023\n",
      "Running with parameters: cutoff=0.0012000000000000001 tune=0.5\n",
      "Run: 0\tsamples: None\tTime:1.6266348361968994\n",
      "Run: 1\tsamples: None\tTime:1.51131010055542\n",
      "Run: 2\tsamples: None\tTime:1.4497768878936768\n",
      "Run: 3\tsamples: None\tTime:1.4785892963409424\n",
      "Run: 4\tsamples: None\tTime:1.4341211318969727\n",
      "Running with parameters: cutoff=0.0012000000000000001 tune=0.55\n",
      "Run: 0\tsamples: None\tTime:1.57631254196167\n",
      "Run: 1\tsamples: None\tTime:1.5248737335205078\n",
      "Run: 2\tsamples: None\tTime:1.443171739578247\n",
      "Run: 3\tsamples: None\tTime:1.4340548515319824\n",
      "Run: 4\tsamples: None\tTime:1.422015905380249\n",
      "Running with parameters: cutoff=0.0012000000000000001 tune=0.6\n",
      "Run: 0\tsamples: None\tTime:1.6048130989074707\n",
      "Run: 1\tsamples: None\tTime:1.563889741897583\n",
      "Run: 2\tsamples: None\tTime:1.446594476699829\n",
      "Run: 3\tsamples: None\tTime:1.4386565685272217\n",
      "Run: 4\tsamples: None\tTime:1.4214439392089844\n",
      "Running with parameters: cutoff=0.0012000000000000001 tune=0.625\n",
      "Run: 0\tsamples: None\tTime:1.578559398651123\n",
      "Run: 1\tsamples: None\tTime:1.512162446975708\n",
      "Run: 2\tsamples: None\tTime:1.4331071376800537\n",
      "Run: 3\tsamples: None\tTime:1.4562287330627441\n",
      "Run: 4\tsamples: None\tTime:1.4325921535491943\n",
      "Running with parameters: cutoff=0.0012000000000000001 tune=0.65\n",
      "Run: 0\tsamples: None\tTime:1.5871989727020264\n",
      "Run: 1\tsamples: None\tTime:1.5106525421142578\n",
      "Run: 2\tsamples: None\tTime:1.4539077281951904\n",
      "Run: 3\tsamples: None\tTime:1.448624849319458\n",
      "Run: 4\tsamples: None\tTime:1.4247817993164062\n",
      "Running with parameters: cutoff=0.0012000000000000001 tune=0.675\n",
      "Run: 0\tsamples: None\tTime:1.611743688583374\n",
      "Run: 1\tsamples: None\tTime:1.5487654209136963\n",
      "Run: 2\tsamples: None\tTime:1.4193017482757568\n",
      "Run: 3\tsamples: None\tTime:1.4174749851226807\n",
      "Run: 4\tsamples: None\tTime:1.4091405868530273\n",
      "Running with parameters: cutoff=0.0012000000000000001 tune=0.7000000000000001\n",
      "Run: 0\tsamples: None\tTime:1.5935280323028564\n",
      "Run: 1\tsamples: None\tTime:1.5136339664459229\n",
      "Run: 2\tsamples: None\tTime:1.4241578578948975\n",
      "Run: 3\tsamples: None\tTime:1.4476525783538818\n",
      "Run: 4\tsamples: None\tTime:1.4067025184631348\n",
      "Running with parameters: cutoff=0.0012000000000000001 tune=0.7250000000000001\n",
      "Run: 0\tsamples: None\tTime:1.5724859237670898\n",
      "Run: 1\tsamples: None\tTime:1.600653886795044\n",
      "Run: 2\tsamples: None\tTime:1.4214534759521484\n",
      "Run: 3\tsamples: None\tTime:1.4148454666137695\n",
      "Run: 4\tsamples: None\tTime:1.4382824897766113\n",
      "Running with parameters: cutoff=0.0012000000000000001 tune=0.7500000000000001\n",
      "Run: 0\tsamples: None\tTime:1.5987985134124756\n",
      "Run: 1\tsamples: None\tTime:1.5505688190460205\n",
      "Run: 2\tsamples: None\tTime:1.4485225677490234\n",
      "Run: 3\tsamples: None\tTime:1.4701848030090332\n",
      "Run: 4\tsamples: None\tTime:1.4207372665405273\n",
      "Running with parameters: cutoff=0.0012000000000000001 tune=0.7750000000000001\n",
      "Run: 0\tsamples: None\tTime:1.568101406097412\n",
      "Run: 1\tsamples: None\tTime:1.5444986820220947\n",
      "Run: 2\tsamples: None\tTime:1.4248929023742676\n",
      "Run: 3\tsamples: None\tTime:1.4231722354888916\n",
      "Run: 4\tsamples: None\tTime:1.421929121017456\n",
      "Running with parameters: cutoff=0.0012000000000000001 tune=0.8000000000000002\n",
      "Run: 0\tsamples: None\tTime:1.6046080589294434\n",
      "Run: 1\tsamples: None\tTime:1.5026767253875732\n",
      "Run: 2\tsamples: None\tTime:1.413407325744629\n",
      "Run: 3\tsamples: None\tTime:1.4602203369140625\n",
      "Run: 4\tsamples: None\tTime:1.4312307834625244\n",
      "Running with parameters: cutoff=0.0014000000000000002 tune=0.4\n",
      "Run: 0\tsamples: None\tTime:1.5616023540496826\n",
      "Run: 1\tsamples: None\tTime:1.5407347679138184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 2\tsamples: None\tTime:1.4313251972198486\n",
      "Run: 3\tsamples: None\tTime:1.452225685119629\n",
      "Run: 4\tsamples: None\tTime:1.4084298610687256\n",
      "Running with parameters: cutoff=0.0014000000000000002 tune=0.45\n",
      "Run: 0\tsamples: None\tTime:1.579768419265747\n",
      "Run: 1\tsamples: None\tTime:1.5009303092956543\n",
      "Run: 2\tsamples: None\tTime:1.4083678722381592\n",
      "Run: 3\tsamples: None\tTime:1.4155941009521484\n",
      "Run: 4\tsamples: None\tTime:1.4077110290527344\n",
      "Running with parameters: cutoff=0.0014000000000000002 tune=0.5\n",
      "Run: 0\tsamples: None\tTime:1.5846645832061768\n",
      "Run: 1\tsamples: None\tTime:1.4846765995025635\n",
      "Run: 2\tsamples: None\tTime:1.394995927810669\n",
      "Run: 3\tsamples: None\tTime:1.4192421436309814\n",
      "Run: 4\tsamples: None\tTime:1.4475908279418945\n",
      "Running with parameters: cutoff=0.0014000000000000002 tune=0.55\n",
      "Run: 0\tsamples: None\tTime:1.6133642196655273\n",
      "Run: 1\tsamples: None\tTime:1.5558710098266602\n",
      "Run: 2\tsamples: None\tTime:1.4367988109588623\n",
      "Run: 3\tsamples: None\tTime:1.4314765930175781\n",
      "Run: 4\tsamples: None\tTime:1.4305050373077393\n",
      "Running with parameters: cutoff=0.0014000000000000002 tune=0.6\n",
      "Run: 0\tsamples: None\tTime:1.5569121837615967\n",
      "Run: 1\tsamples: None\tTime:1.5229687690734863\n",
      "Run: 2\tsamples: None\tTime:1.405275821685791\n",
      "Run: 3\tsamples: None\tTime:1.4575302600860596\n",
      "Run: 4\tsamples: None\tTime:1.440779685974121\n",
      "Running with parameters: cutoff=0.0014000000000000002 tune=0.625\n",
      "Run: 0\tsamples: None\tTime:1.6200079917907715\n",
      "Run: 1\tsamples: None\tTime:1.555387258529663\n",
      "Run: 2\tsamples: None\tTime:1.4205145835876465\n",
      "Run: 3\tsamples: None\tTime:1.4574222564697266\n",
      "Run: 4\tsamples: None\tTime:1.4124236106872559\n",
      "Running with parameters: cutoff=0.0014000000000000002 tune=0.65\n",
      "Run: 0\tsamples: None\tTime:1.6500487327575684\n",
      "Run: 1\tsamples: None\tTime:1.5322129726409912\n",
      "Run: 2\tsamples: None\tTime:1.456965446472168\n",
      "Run: 3\tsamples: None\tTime:1.456061601638794\n",
      "Run: 4\tsamples: None\tTime:1.452423095703125\n",
      "Running with parameters: cutoff=0.0014000000000000002 tune=0.675\n",
      "Run: 0\tsamples: None\tTime:1.6088964939117432\n",
      "Run: 1\tsamples: None\tTime:1.562434196472168\n",
      "Run: 2\tsamples: None\tTime:1.424659252166748\n",
      "Run: 3\tsamples: None\tTime:1.4219300746917725\n",
      "Run: 4\tsamples: None\tTime:1.4322147369384766\n",
      "Running with parameters: cutoff=0.0014000000000000002 tune=0.7000000000000001\n",
      "Run: 0\tsamples: None\tTime:1.5776171684265137\n",
      "Run: 1\tsamples: None\tTime:1.5106074810028076\n",
      "Run: 2\tsamples: None\tTime:1.3786652088165283\n",
      "Run: 3\tsamples: None\tTime:1.399702548980713\n",
      "Run: 4\tsamples: None\tTime:1.4320790767669678\n",
      "Running with parameters: cutoff=0.0014000000000000002 tune=0.7250000000000001\n",
      "Run: 0\tsamples: None\tTime:1.5914828777313232\n",
      "Run: 1\tsamples: None\tTime:1.5681774616241455\n",
      "Run: 2\tsamples: None\tTime:1.39927339553833\n",
      "Run: 3\tsamples: None\tTime:1.4226837158203125\n",
      "Run: 4\tsamples: None\tTime:1.4430551528930664\n",
      "Running with parameters: cutoff=0.0014000000000000002 tune=0.7500000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6080050468444824\n",
      "Run: 1\tsamples: None\tTime:1.5061187744140625\n",
      "Run: 2\tsamples: None\tTime:1.4461524486541748\n",
      "Run: 3\tsamples: None\tTime:1.4506828784942627\n",
      "Run: 4\tsamples: None\tTime:1.4294712543487549\n",
      "Running with parameters: cutoff=0.0014000000000000002 tune=0.7750000000000001\n",
      "Run: 0\tsamples: None\tTime:1.6225552558898926\n",
      "Run: 1\tsamples: None\tTime:1.5894911289215088\n",
      "Run: 2\tsamples: None\tTime:1.4013495445251465\n",
      "Run: 3\tsamples: None\tTime:1.4269967079162598\n",
      "Run: 4\tsamples: None\tTime:1.4236130714416504\n",
      "Running with parameters: cutoff=0.0014000000000000002 tune=0.8000000000000002\n",
      "Run: 0\tsamples: None\tTime:1.6326179504394531\n",
      "Run: 1\tsamples: None\tTime:1.573345422744751\n",
      "Run: 2\tsamples: None\tTime:1.449510097503662\n",
      "Run: 3\tsamples: None\tTime:1.4370129108428955\n",
      "Run: 4\tsamples: None\tTime:1.4439458847045898\n"
     ]
    }
   ],
   "source": [
    "cutoff_range = np.append(np.arange(0.0001, 0.001, 0.0001), np.arange(0.001, 0.0016, 0.0002))\n",
    "tune_range = np.append(np.arange(0.4, 0.6, 0.05), np.arange(0.6, 0.825, 0.025))\n",
    "\n",
    "print('Starting Tuning!')\n",
    "print(f'cutoff values: {cutoff_range}')\n",
    "print(f'tune values: {tune_range}')\n",
    "\n",
    "tune_results_list = []\n",
    "for c in cutoff_range:\n",
    "    for i in tune_range:\n",
    "        print(f'Running with parameters: cutoff={c} tune={i}')\n",
    "        tune_results = run_model(samples_per_iter=None, iterations=5, seed=None, \\\n",
    "                                 max_candidate_ids=None, max_neighbors=None, max_neighbor_ids=None, \\\n",
    "                                 num_distances=1, cutoff=c, tune=i, skip_nonroot=True, \\\n",
    "                                 provided_samples=formatted_sample_list, verbose=True)\n",
    "        \n",
    "        tune_results_list.append([c, i, get_tune_result(tune_results)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>result</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>tune</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "      <th>total</th>\n",
       "      <th>pct_model_correct</th>\n",
       "      <th>ratio_model_baseline</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.400</td>\n",
       "      <td>73.2</td>\n",
       "      <td>81.8</td>\n",
       "      <td>54.4</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.259790</td>\n",
       "      <td>0.743169</td>\n",
       "      <td>-18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.450</td>\n",
       "      <td>60.6</td>\n",
       "      <td>77.8</td>\n",
       "      <td>51.4</td>\n",
       "      <td>189.8</td>\n",
       "      <td>0.270811</td>\n",
       "      <td>0.848185</td>\n",
       "      <td>-9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.500</td>\n",
       "      <td>53.6</td>\n",
       "      <td>72.4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.284091</td>\n",
       "      <td>0.932836</td>\n",
       "      <td>-3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.550</td>\n",
       "      <td>48.0</td>\n",
       "      <td>69.8</td>\n",
       "      <td>48.4</td>\n",
       "      <td>166.2</td>\n",
       "      <td>0.291215</td>\n",
       "      <td>1.008333</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.600</td>\n",
       "      <td>41.6</td>\n",
       "      <td>63.8</td>\n",
       "      <td>46.2</td>\n",
       "      <td>151.6</td>\n",
       "      <td>0.304749</td>\n",
       "      <td>1.110577</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.700</td>\n",
       "      <td>9.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.4</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.436735</td>\n",
       "      <td>2.229167</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.725</td>\n",
       "      <td>9.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>47.8</td>\n",
       "      <td>0.435146</td>\n",
       "      <td>2.260870</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.750</td>\n",
       "      <td>9.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>2.152174</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.775</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>19.2</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.800</td>\n",
       "      <td>8.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>0.439815</td>\n",
       "      <td>2.261905</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "result  cutoff   tune  Baseline Correct  Both Incorrect  Model Correct  total  \\\n",
       "count   0.0014  0.400              73.2            81.8           54.4  209.4   \n",
       "count   0.0014  0.450              60.6            77.8           51.4  189.8   \n",
       "count   0.0014  0.500              53.6            72.4           50.0  176.0   \n",
       "count   0.0014  0.550              48.0            69.8           48.4  166.2   \n",
       "count   0.0014  0.600              41.6            63.8           46.2  151.6   \n",
       "...        ...    ...               ...             ...            ...    ...   \n",
       "count   0.0001  0.700               9.6            18.0           21.4   49.0   \n",
       "count   0.0001  0.725               9.2            17.8           20.8   47.8   \n",
       "count   0.0001  0.750               9.2            17.8           19.8   46.8   \n",
       "count   0.0001  0.775               9.0            16.8           19.2   45.0   \n",
       "count   0.0001  0.800               8.4            15.8           19.0   43.2   \n",
       "\n",
       "result  pct_model_correct  ratio_model_baseline  difference  \n",
       "count            0.259790              0.743169       -18.8  \n",
       "count            0.270811              0.848185        -9.2  \n",
       "count            0.284091              0.932836        -3.6  \n",
       "count            0.291215              1.008333         0.4  \n",
       "count            0.304749              1.110577         4.6  \n",
       "...                   ...                   ...         ...  \n",
       "count            0.436735              2.229167        11.8  \n",
       "count            0.435146              2.260870        11.6  \n",
       "count            0.423077              2.152174        10.6  \n",
       "count            0.426667              2.133333        10.2  \n",
       "count            0.439815              2.261905        10.6  \n",
       "\n",
       "[156 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_results_df = pd.DataFrame([i[2] for i in tune_results_list])\n",
    "tune_results_df['cutoff'] = [i[0] for i in tune_results_list]\n",
    "tune_results_df['tune'] = [i[1] for i in tune_results_list]\n",
    "tune_results_df.sort_values(by=['cutoff', 'tune'], ascending=[False, True], inplace=True)\n",
    "tune_results_df['total'] = tune_results_df['Baseline Correct']+tune_results_df['Both Incorrect']+tune_results_df['Model Correct']\n",
    "tune_results_df['pct_model_correct'] = tune_results_df['Model Correct']/tune_results_df['total']\n",
    "tune_results_df['ratio_model_baseline'] = tune_results_df['Model Correct']/tune_results_df['Baseline Correct']\n",
    "tune_results_df['difference'] = tune_results_df['Model Correct']-tune_results_df['Baseline Correct']\n",
    "tune_results_df = tune_results_df[['cutoff', 'tune', 'Baseline Correct', 'Both Incorrect', 'Model Correct', 'total', 'pct_model_correct', 'ratio_model_baseline', 'difference']]\n",
    "tune_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>result</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>tune</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "      <th>total</th>\n",
       "      <th>pct_model_correct</th>\n",
       "      <th>ratio_model_baseline</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.800</td>\n",
       "      <td>8.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>0.439815</td>\n",
       "      <td>2.261905</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.700</td>\n",
       "      <td>9.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.4</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.436735</td>\n",
       "      <td>2.229167</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.725</td>\n",
       "      <td>9.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>47.8</td>\n",
       "      <td>0.435146</td>\n",
       "      <td>2.260870</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.600</td>\n",
       "      <td>12.2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>55.2</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>1.967213</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.650</td>\n",
       "      <td>10.8</td>\n",
       "      <td>18.4</td>\n",
       "      <td>22.4</td>\n",
       "      <td>51.6</td>\n",
       "      <td>0.434109</td>\n",
       "      <td>2.074074</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.550</td>\n",
       "      <td>13.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.432886</td>\n",
       "      <td>1.869565</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.675</td>\n",
       "      <td>10.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>2.076923</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.625</td>\n",
       "      <td>11.6</td>\n",
       "      <td>18.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>53.4</td>\n",
       "      <td>0.430712</td>\n",
       "      <td>1.982759</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.775</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>19.2</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.750</td>\n",
       "      <td>9.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>2.152174</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "result  cutoff   tune  Baseline Correct  Both Incorrect  Model Correct  total  \\\n",
       "count   0.0001  0.800               8.4            15.8           19.0   43.2   \n",
       "count   0.0001  0.700               9.6            18.0           21.4   49.0   \n",
       "count   0.0001  0.725               9.2            17.8           20.8   47.8   \n",
       "count   0.0001  0.600              12.2            19.0           24.0   55.2   \n",
       "count   0.0001  0.650              10.8            18.4           22.4   51.6   \n",
       "count   0.0001  0.550              13.8            20.0           25.8   59.6   \n",
       "count   0.0001  0.675              10.4            18.0           21.6   50.0   \n",
       "count   0.0001  0.625              11.6            18.8           23.0   53.4   \n",
       "count   0.0001  0.775               9.0            16.8           19.2   45.0   \n",
       "count   0.0001  0.750               9.2            17.8           19.8   46.8   \n",
       "\n",
       "result  pct_model_correct  ratio_model_baseline  difference  \n",
       "count            0.439815              2.261905        10.6  \n",
       "count            0.436735              2.229167        11.8  \n",
       "count            0.435146              2.260870        11.6  \n",
       "count            0.434783              1.967213        11.8  \n",
       "count            0.434109              2.074074        11.6  \n",
       "count            0.432886              1.869565        12.0  \n",
       "count            0.432000              2.076923        11.2  \n",
       "count            0.430712              1.982759        11.4  \n",
       "count            0.426667              2.133333        10.2  \n",
       "count            0.423077              2.152174        10.6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>result</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>tune</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "      <th>total</th>\n",
       "      <th>pct_model_correct</th>\n",
       "      <th>ratio_model_baseline</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.725</td>\n",
       "      <td>18.6</td>\n",
       "      <td>44.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>99.2</td>\n",
       "      <td>0.368952</td>\n",
       "      <td>1.967742</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.800</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>32.6</td>\n",
       "      <td>85.2</td>\n",
       "      <td>0.382629</td>\n",
       "      <td>2.173333</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.725</td>\n",
       "      <td>18.4</td>\n",
       "      <td>43.4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>97.8</td>\n",
       "      <td>0.368098</td>\n",
       "      <td>1.956522</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.800</td>\n",
       "      <td>14.8</td>\n",
       "      <td>37.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>84.2</td>\n",
       "      <td>0.382423</td>\n",
       "      <td>2.175676</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.725</td>\n",
       "      <td>19.8</td>\n",
       "      <td>45.6</td>\n",
       "      <td>37.2</td>\n",
       "      <td>102.6</td>\n",
       "      <td>0.362573</td>\n",
       "      <td>1.878788</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.650</td>\n",
       "      <td>22.4</td>\n",
       "      <td>47.2</td>\n",
       "      <td>39.8</td>\n",
       "      <td>109.4</td>\n",
       "      <td>0.363803</td>\n",
       "      <td>1.776786</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.700</td>\n",
       "      <td>20.4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.365049</td>\n",
       "      <td>1.843137</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.600</td>\n",
       "      <td>24.8</td>\n",
       "      <td>48.4</td>\n",
       "      <td>42.0</td>\n",
       "      <td>115.2</td>\n",
       "      <td>0.364583</td>\n",
       "      <td>1.693548</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.800</td>\n",
       "      <td>15.6</td>\n",
       "      <td>38.8</td>\n",
       "      <td>32.8</td>\n",
       "      <td>87.2</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>2.102564</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.750</td>\n",
       "      <td>18.0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>96.2</td>\n",
       "      <td>0.363825</td>\n",
       "      <td>1.944444</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "result  cutoff   tune  Baseline Correct  Both Incorrect  Model Correct  total  \\\n",
       "count   0.0008  0.725              18.6            44.0           36.6   99.2   \n",
       "count   0.0008  0.800              15.0            37.6           32.6   85.2   \n",
       "count   0.0007  0.725              18.4            43.4           36.0   97.8   \n",
       "count   0.0007  0.800              14.8            37.2           32.2   84.2   \n",
       "count   0.0009  0.725              19.8            45.6           37.2  102.6   \n",
       "count   0.0008  0.650              22.4            47.2           39.8  109.4   \n",
       "count   0.0008  0.700              20.4            45.0           37.6  103.0   \n",
       "count   0.0008  0.600              24.8            48.4           42.0  115.2   \n",
       "count   0.0009  0.800              15.6            38.8           32.8   87.2   \n",
       "count   0.0008  0.750              18.0            43.2           35.0   96.2   \n",
       "\n",
       "result  pct_model_correct  ratio_model_baseline  difference  \n",
       "count            0.368952              1.967742        18.0  \n",
       "count            0.382629              2.173333        17.6  \n",
       "count            0.368098              1.956522        17.6  \n",
       "count            0.382423              2.175676        17.4  \n",
       "count            0.362573              1.878788        17.4  \n",
       "count            0.363803              1.776786        17.4  \n",
       "count            0.365049              1.843137        17.2  \n",
       "count            0.364583              1.693548        17.2  \n",
       "count            0.376147              2.102564        17.2  \n",
       "count            0.363825              1.944444        17.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>result</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>tune</th>\n",
       "      <th>Baseline Correct</th>\n",
       "      <th>Both Incorrect</th>\n",
       "      <th>Model Correct</th>\n",
       "      <th>total</th>\n",
       "      <th>pct_model_correct</th>\n",
       "      <th>ratio_model_baseline</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.800</td>\n",
       "      <td>8.4</td>\n",
       "      <td>15.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>0.439815</td>\n",
       "      <td>2.261905</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.725</td>\n",
       "      <td>9.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>47.8</td>\n",
       "      <td>0.435146</td>\n",
       "      <td>2.260870</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.800</td>\n",
       "      <td>11.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>26.2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>0.413249</td>\n",
       "      <td>2.258621</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.700</td>\n",
       "      <td>9.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.4</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.436735</td>\n",
       "      <td>2.229167</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.800</td>\n",
       "      <td>14.8</td>\n",
       "      <td>37.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>84.2</td>\n",
       "      <td>0.382423</td>\n",
       "      <td>2.175676</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.800</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>32.6</td>\n",
       "      <td>85.2</td>\n",
       "      <td>0.382629</td>\n",
       "      <td>2.173333</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.725</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>70.4</td>\n",
       "      <td>0.400568</td>\n",
       "      <td>2.169231</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.750</td>\n",
       "      <td>9.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>2.152174</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.775</td>\n",
       "      <td>12.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.403030</td>\n",
       "      <td>2.145161</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.800</td>\n",
       "      <td>14.2</td>\n",
       "      <td>34.8</td>\n",
       "      <td>30.4</td>\n",
       "      <td>79.4</td>\n",
       "      <td>0.382872</td>\n",
       "      <td>2.140845</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "result  cutoff   tune  Baseline Correct  Both Incorrect  Model Correct  total  \\\n",
       "count   0.0001  0.800               8.4            15.8           19.0   43.2   \n",
       "count   0.0001  0.725               9.2            17.8           20.8   47.8   \n",
       "count   0.0002  0.800              11.6            25.6           26.2   63.4   \n",
       "count   0.0001  0.700               9.6            18.0           21.4   49.0   \n",
       "count   0.0007  0.800              14.8            37.2           32.2   84.2   \n",
       "count   0.0008  0.800              15.0            37.6           32.6   85.2   \n",
       "count   0.0002  0.725              13.0            29.2           28.2   70.4   \n",
       "count   0.0001  0.750               9.2            17.8           19.8   46.8   \n",
       "count   0.0002  0.775              12.4            27.0           26.6   66.0   \n",
       "count   0.0004  0.800              14.2            34.8           30.4   79.4   \n",
       "\n",
       "result  pct_model_correct  ratio_model_baseline  difference  \n",
       "count            0.439815              2.261905        10.6  \n",
       "count            0.435146              2.260870        11.6  \n",
       "count            0.413249              2.258621        14.6  \n",
       "count            0.436735              2.229167        11.8  \n",
       "count            0.382423              2.175676        17.4  \n",
       "count            0.382629              2.173333        17.6  \n",
       "count            0.400568              2.169231        15.2  \n",
       "count            0.423077              2.152174        10.6  \n",
       "count            0.403030              2.145161        14.2  \n",
       "count            0.382872              2.140845        16.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sort our tuned models by ratio and difference between 'Model Correct' and 'Baseline Correct'\n",
    "display(tune_results_df.sort_values(by=['pct_model_correct'], ascending=[False])[:10])\n",
    "display(tune_results_df.sort_values(by=['difference', 'ratio_model_baseline'], ascending=[False, False])[:10])\n",
    "display(tune_results_df.sort_values(by=['ratio_model_baseline', 'difference'], ascending=[False, False])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/156 sets of parameters outperformed the baseline\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(tune_results_df[tune_results_df.difference>0])}/{len(tune_results_df)} \\\n",
    "sets of parameters outperformed the baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning - Results\n",
    "### The Embedding Model Works!\n",
    "\n",
    "Our tuning shows our model **outperforming the baseline!** We now have a table of parameters where our model outperforms the baseline.\n",
    "\n",
    "Now we will run **five optimized models** based on the top results from the table above and use the parameter set with the highest accuracy score for our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\tembedding model results: 0.699\ttime:1.6105647087097168\n",
      "Run: 1\tembedding model results: 0.7054\ttime:1.5345933437347412\n",
      "Run: 2\tembedding model results: 0.7094\ttime:1.4549684524536133\n",
      "Run: 3\tembedding model results: 0.7028\ttime:1.4472508430480957\n",
      "Run: 4\tembedding model results: 0.705\ttime:1.4509289264678955\n",
      "Run: 0\tembedding model results: 0.7008\ttime:1.584244966506958\n",
      "Run: 1\tembedding model results: 0.7076\ttime:1.616020679473877\n",
      "Run: 2\tembedding model results: 0.711\ttime:1.4264001846313477\n",
      "Run: 3\tembedding model results: 0.7022\ttime:1.4595158100128174\n",
      "Run: 4\tembedding model results: 0.7074\ttime:1.4472405910491943\n",
      "Run: 0\tembedding model results: 0.6992\ttime:1.6456859111785889\n",
      "Run: 1\tembedding model results: 0.7056\ttime:1.564849853515625\n",
      "Run: 2\tembedding model results: 0.7096\ttime:1.4378962516784668\n",
      "Run: 3\tembedding model results: 0.7026\ttime:1.458756446838379\n",
      "Run: 4\tembedding model results: 0.7056\ttime:1.4320368766784668\n",
      "Run: 0\tembedding model results: 0.7002\ttime:1.633317470550537\n",
      "Run: 1\tembedding model results: 0.7078\ttime:1.5859322547912598\n",
      "Run: 2\tembedding model results: 0.7112\ttime:1.3899915218353271\n",
      "Run: 3\tembedding model results: 0.7028\ttime:1.4673306941986084\n",
      "Run: 4\tembedding model results: 0.7066\ttime:1.4448966979980469\n",
      "Run: 0\tembedding model results: 0.6994\ttime:1.5791184902191162\n",
      "Run: 1\tembedding model results: 0.707\ttime:1.5459609031677246\n",
      "Run: 2\tembedding model results: 0.7102\ttime:1.442122459411621\n",
      "Run: 3\tembedding model results: 0.7028\ttime:1.458517074584961\n",
      "Run: 4\tembedding model results: 0.7062\ttime:1.4562153816223145\n"
     ]
    }
   ],
   "source": [
    "optimized_params = [(0.0001, 0.8), (0.0008, 0.725), (0.0001, 0.725), (0.0008, 0.8), (0.0002, 0.8)]\n",
    "optimized_results = []\n",
    "\n",
    "for c, t in optimized_params:\n",
    "    optimized_results.append(run_model(samples_per_iter=None, iterations=5, seed=None, \\\n",
    "                                       max_candidate_ids=None, max_neighbors=None, max_neighbor_ids=None, \\\n",
    "                                       num_distances=1, cutoff=c, tune=t, skip_nonroot=True, \\\n",
    "                                       provided_samples=formatted_sample_list, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># candidate_ids / # neighbor_ids</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.70220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg all distances</th>\n",
       "      <td>0.61508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min distance</th>\n",
       "      <td>0.65624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg 2 min distances</th>\n",
       "      <td>0.63708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params c=0.0001 t=0.8</th>\n",
       "      <td>0.70432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params c=0.0008 t=0.725</th>\n",
       "      <td>0.70580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params c=0.0001 t=0.725</th>\n",
       "      <td>0.70452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params c=0.0008 t=0.8</th>\n",
       "      <td>0.70572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params c=0.0002 t=0.8</th>\n",
       "      <td>0.70512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Accuracy\n",
       "# candidate_ids / # neighbor_ids          \n",
       "baseline                           0.70220\n",
       "avg all distances                  0.61508\n",
       "min distance                       0.65624\n",
       "avg 2 min distances                0.63708\n",
       "params c=0.0001 t=0.8              0.70432\n",
       "params c=0.0008 t=0.725            0.70580\n",
       "params c=0.0001 t=0.725            0.70452\n",
       "params c=0.0008 t=0.8              0.70572\n",
       "params c=0.0002 t=0.8              0.70512"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "avg_result, base_result = zip(*avg_results_5_4_5)\n",
    "neighbor_4_opti = [base_result, avg_result, min_results_5_4_5, min2_results_5_4_5] + optimized_results\n",
    "neighbor_4_opti = [np.average(i) for i in neighbor_4_opti]\n",
    "                        \n",
    "ind = np.arange(0, len(neighbor_4_opti), 1)\n",
    "width = 0.9\n",
    "labels = ['baseline', 'avg all distances', 'min distance', 'avg 2 min distances']\n",
    "labels += [f'params c={c} t={t}' for c, t in optimized_params]\n",
    "\n",
    "barlist=plt.bar(ind, neighbor_4_opti, width, label='4 Neighbors')\n",
    "barlist[0].set_color('firebrick')\n",
    "\n",
    "plt.ylim(0.6, 0.75)\n",
    "plt.title(\"Results: 5 candidate_ids, 4 neighbors, 4 neighbor_ids\")\n",
    "plt.ylabel('accuracy score')\n",
    "plt.xlabel('model type')\n",
    "plt.xticks(ind, labels, rotation=90)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "min_4_df = pd.DataFrame(neighbor_4_opti, columns=['Accuracy'], index=labels)\n",
    "min_4_df.index.rename('# candidate_ids / # neighbor_ids', inplace=True)\n",
    "min_4_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model\n",
    "\n",
    "### Settings\n",
    "\n",
    "Here are the parameters of our **final model** based on the best performing optimized embedding model above.\n",
    "\n",
    "| Parameter         | Value  |\n",
    "|-------------------|--------|\n",
    "| max_candidate_ids | 5      |\n",
    "| max_neighbors     | 4      |\n",
    "| max_neighbor_ids  | 5      |\n",
    "| num_distances     | 1      |\n",
    "| cutoff            | 0.0008 |\n",
    "| tune              | 0.725  |\n",
    "\n",
    "## Final Model - Test\n",
    "Up to this point we've been using same sequence of random seeds for all our tests. We will not use seeds for our final test run.\n",
    "\n",
    "For our final sequence of tests we will run our final model with **10 sets of 5000 random samples**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\tembedding model results: 0.7002\tbaseline results: 0.694\ttime:7.796745777130127\n",
      "Run: 1\tembedding model results: 0.71\tbaseline results: 0.7086\ttime:7.898545503616333\n",
      "Run: 2\tembedding model results: 0.7038\tbaseline results: 0.702\ttime:7.326197385787964\n",
      "Run: 3\tembedding model results: 0.7002\tbaseline results: 0.695\ttime:7.938142538070679\n",
      "Run: 4\tembedding model results: 0.7004\tbaseline results: 0.696\ttime:7.1620399951934814\n",
      "Run: 5\tembedding model results: 0.7052\tbaseline results: 0.7014\ttime:7.432491302490234\n",
      "Run: 6\tembedding model results: 0.7048\tbaseline results: 0.7034\ttime:7.214053392410278\n",
      "Run: 7\tembedding model results: 0.7122\tbaseline results: 0.7072\ttime:7.678871154785156\n",
      "Run: 8\tembedding model results: 0.7052\tbaseline results: 0.7018\ttime:7.390840768814087\n",
      "Run: 9\tembedding model results: 0.7038\tbaseline results: 0.701\ttime:7.306101560592651\n",
      "CPU times: user 16.3 s, sys: 5.05 s, total: 21.4 s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_test_results = run_model(samples_per_iter=5000, iterations=10, seed=None, \\\n",
    "                               max_candidate_ids=5, max_neighbors=4, max_neighbor_ids=5, \\\n",
    "                               num_distances=1, cutoff=0.0008, tune=0.725, skip_nonroot=True, \\\n",
    "                               verbose=False, compare=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "final_model_results, baseline_results = zip(*final_test_results)\n",
    "\n",
    "ind = np.arange(len(final_model_results))\n",
    "width = 0.4\n",
    "\n",
    "plt.bar(ind, final_model_results, width, label='Optimized Embedding Model')\n",
    "plt.bar(ind+width, baseline_results, width, label='Baseline Model')\n",
    "\n",
    "plt.ylim(0.66, 0.72)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Final Test: Optimized Embedding Model Vs Baseline Model\")\n",
    "x_lbls='2 Neighbors', '4 Neighbors', '6 Neighbors', '8 Neighbors'\n",
    "plt.ylabel('accuracy score')\n",
    "plt.xticks(ind)\n",
    "plt.xlabel('test # (random seeds)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model - Test\n",
    "The final model outperforms the baseline in all 10 test runs. This provides conclusive evidence that our final model is superior to the baseline model.\n",
    "\n",
    "# Conclusion\n",
    "We can claim success in our hypothesis that the neighbors around an entity can help predict it's true id. While the score may not be substantially higher than the baseline, it is an improvement using an entirely different metric to select the true_id for an entity.\n",
    "\n",
    "We believe our model will demonstrate greater success on non-wikipedia text compared to the baseline model. The baseline model utilizing the highest view was always a challenge to beat with our model. Since the views are genereated from Wikipedia traffic and our dataset was also created from Wikipedia.\n",
    "\n",
    "Overall this project was challenging as there was a significant amount of data-pre-processing required before we could even start testing our model. Generating a set of embeddings required us to weight over 1000 properties and create a way to condense a graph by 87% while maintaining relationships between entities.\n",
    "\n",
    "The initial results of the embedding model were not promising as it was outperformed by the baseline by at least 5% in all 18 initial test cases. However, after analyzing when our model was correct compared to the baseline, we realized that our model was successfully identifying relationships between an entity and its neighbors but it was also identifying weak relationships that should be ignored. We were able to tune the embedding model to maximize the relationship between the entity and its neighbor when it was sufficiently strong. This resulted in our optimized embedding model beating the baseline in all 10 tests runs with 5000 randomized samples each.\n",
    "\n",
    "In the end, we accomplished our objective of utilizing graph embeddings to disambiguate an entity through its relationship with its neighboring entities.\n",
    "\n",
    "## Future Work\n",
    "We believe there is still room for improvement with the embedding model. We were only able to generate embedding for ~13% of the graph due to system constraints. We may be able to improve the relationship between entities if we are able to generate embeddings based on the entire 141M statements in the original graph. There may also be some additional fine-tuning possible for the cutoff and tune parameters."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "emb_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
